{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db80738f-a3ee-4dd9-b7f2-ee3cb9eed4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dbffb6e-d362-4b9e-b2cb-2d50a3107f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure timestamp callback for Jupyter cells\n",
    "from IPython import get_ipython\n",
    "\n",
    "def setup_timestamp_callback():\n",
    "    \"\"\"Setup a timestamp callback for Jupyter cells without clearing existing callbacks.\"\"\"\n",
    "    ip = get_ipython()\n",
    "    if ip is not None:\n",
    "        # Define timestamp function\n",
    "        def print_timestamp(*args, **kwargs):\n",
    "            \"\"\"Print timestamp after cell execution.\"\"\"\n",
    "            print(f\"Cell executed at: {datetime.now()}\")\n",
    "        \n",
    "        # Check if our callback is already registered\n",
    "        callbacks = ip.events.callbacks.get('post_run_cell', [])\n",
    "        for cb in callbacks:\n",
    "            if hasattr(cb, '__name__') and cb.__name__ == 'print_timestamp':\n",
    "                # Already registered\n",
    "                return\n",
    "                \n",
    "        # Register new callback if not already present\n",
    "        ip.events.register('post_run_cell', print_timestamp)\n",
    "        print(\"Timestamp printing activated.\")\n",
    "    else:\n",
    "        print(\"Not running in IPython/Jupyter environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "446db3e8-a2ad-430a-a436-8793631755be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp printing activated.\n",
      "Cell executed at: 2025-05-17 16:06:05.258151\n"
     ]
    }
   ],
   "source": [
    "# Setup timestamp callback\n",
    "setup_timestamp_callback()\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f97f85d-b1ad-406c-a618-8e3787663f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf354715-27cc-43dd-9d50-3b2afa1649af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Cell executed at: 2025-05-17 16:06:05.871305\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_excel(\"data/ISBSG2016R1.1-Formatted4CSVAgileOnly.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b94562c2-2e17-4b49-9296-f95506bf93a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-05-17 16:06:05.902238\n"
     ]
    }
   ],
   "source": [
    "# clean up columns like lowercase, strip spaces, remove trailing punctuation\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_category(val):\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    # Lowercase, strip spaces, remove trailing punctuation\n",
    "    val = val.strip().lower()\n",
    "    val = re.sub(r'\\s+', ' ', val)  # collapse multiple spaces\n",
    "    val = val.rstrip(';,.')\n",
    "    # Remove duplicate semicolons and extra spaces between separated values\n",
    "    val = re.sub(r';\\s*;', ';', val)\n",
    "    val = re.sub(r';\\s+', '; ', val)\n",
    "    return val\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].map(clean_category)\n",
    "\n",
    "# Clean column names: lowercase, replace spaces with underscores, strip\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.strip()                # remove leading/trailing spaces\n",
    "    .str.lower()                # make lowercase\n",
    "    .str.replace(' ', '_')      # replace spaces with underscores\n",
    "    .str.replace('-', '_')      # optional: replace hyphens with underscores\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db0f80c-9086-49c3-ba44-f1e49252b9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current columns: ['isbsg_project_id', 'external_eef_data_quality_rating', 'project_prf_year_of_project', 'external_eef_industry_sector', 'external_eef_organisation_type', 'project_prf_application_group', 'project_prf_application_type', 'project_prf_development_type', 'tech_tf_development_platform', 'tech_tf_language_type', 'tech_tf_primary_programming_language', 'project_prf_functional_size', 'project_prf_relative_size', 'project_prf_normalised_work_effort', 'project_prf_normalised_level_1_pdr_ufp', 'project_prf_normalised_pdr_ufp', 'project_prf_defect_density', 'project_prf_speed_of_delivery', 'project_prf_manpower_delivery_rate', 'project_prf_project_elapsed_time', 'project_prf_team_size_group', 'project_prf_max_team_size', 'project_prf_case_tool_used', 'process_pmf_development_methodologies', 'process_pmf_prototyping_used', 'process_pmf_docs', 'tech_tf_architecture', 'tech_tf_client_server', 'tech_tf_client_roles', 'tech_tf_server_roles', 'tech_tf_type_of_server', 'tech_tf_web_development', 'tech_tf_dbms_used', 'tech_tf_tools_used', 'people_prf_project_user_involvement', 'people_prf_ba_team_experience_less_than_1_yr', 'people_prf_ba_team_experience_1_to_3_yr', 'people_prf_ba_team_experience_great_than_3_yr', 'people_prf_it_experience_less_than_1_yr', 'people_prf_it_experience_1_to_3_yr', 'people_prf_it_experience_great_than_3_yr', 'people_prf_it_experience_less_than_3_yr', 'people_prf_it_experience_3_to_9_yr', 'people_prf_it_experience_great_than_9_yr', 'people_prf_project_manage_experience', 'people_prf_project_manage_changes', 'people_prf_personnel_changes', 'project_prf_total_project_cost', 'project_prf_cost_currency', 'project_prf_currency_multiple']\n",
      "Cell executed at: 2025-05-17 16:06:05.911290\n"
     ]
    }
   ],
   "source": [
    "print(\"Current columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4993f9d-7c47-48a7-bbd1-ec34ebc3e360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-05-17 16:06:05.923442\n"
     ]
    }
   ],
   "source": [
    "# Clean and standardise a semicolon-seperated categorical string\n",
    "\n",
    "def clean_and_sort_semicolon(val):\n",
    "    \"\"\"Clean and standardize a semicolon-separated categorical string.\"\"\"\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    # Split, strip, lower, remove trailing punctuation\n",
    "    parts = [p.strip().lower().rstrip(';,.') for p in val.split(';') if p.strip()]\n",
    "    # Remove duplicates, sort\n",
    "    parts = sorted(set(parts))\n",
    "    return '; '.join(parts)\n",
    "\n",
    "cols_with_semicolons = [\n",
    "    'project_prf_application_group',\n",
    "    'external_eef_organisation_type',\n",
    "    'process_pmf_development_methodologies',\n",
    "    'project_prf_application_type',\n",
    "    'tech_tf_client_roles',\n",
    "    'tech_tf_server_roles',\n",
    "    'tech_tf_type_of_server'\n",
    "]\n",
    "for col in cols_with_semicolons:\n",
    "    df[col] = df[col].map(clean_and_sort_semicolon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eae09e58-4a1e-4db6-87c4-517ab5e6720e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-05-17 16:06:05.934305\n"
     ]
    }
   ],
   "source": [
    "# Standardise some columns with mixed cases\n",
    "\n",
    "def standardize_value(val):\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    val = val.strip().lower()\n",
    "    if val in ['stand alone', 'stand-alone']:\n",
    "        return 'stand-alone'\n",
    "    if val == 'client server':\n",
    "        return 'client-server'\n",
    "    # Remove question mark from web dev\n",
    "    if val.replace('?', '').strip() == 'web':\n",
    "        return 'web'\n",
    "    # You can add more cases as needed\n",
    "    return val\n",
    "\n",
    "df['tech_tf_architecture'] = df['tech_tf_architecture'].map(standardize_value)\n",
    "df['tech_tf_web_development'] = df['tech_tf_web_development'].map(standardize_value)\n",
    "df['tech_tf_language_type'] = df['tech_tf_language_type'].str.upper().str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c47b6d00-a16f-469e-9773-0ff331b09711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and sorted unique values written to 'temp/cleaned_unique_multilabels.txt'\n",
      "Cell executed at: 2025-05-17 16:06:05.952878\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned Unique Multilables for some categorical columns\n",
    "\n",
    "import os\n",
    "\n",
    "output_file = \"temp/cleaned_unique_multilabels.txt\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for col in cols_with_semicolons:\n",
    "        if col in df.columns:\n",
    "            uniques = sorted(df[col].dropna().unique())\n",
    "            f.write(f\"Column: {col}\\n\")\n",
    "            for val in uniques:\n",
    "                f.write(f\"    {repr(val)}\\n\")\n",
    "            f.write(\"\\n\" + \"-\"*40 + \"\\n\\n\")\n",
    "print(f\"Cleaned and sorted unique values written to '{output_file}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7df771d2-518d-4d0c-976d-c3216ebf6370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values for categorical columns saved to 'temp/categorical_unique_values.txt'\n",
      "Cell executed at: 2025-05-17 16:21:01.366309\n"
     ]
    }
   ],
   "source": [
    "# Save categorical unique values for all categorical columns\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "with open('temp/categorical_unique_values.txt', 'w') as f:\n",
    "    for col in cat_cols:\n",
    "        f.write(f\"Column: {col} (n_unique = {df[col].nunique()})\\n\")\n",
    "        f.write(f\"{df[col].unique()}\\n\")\n",
    "        f.write('-' * 40 + '\\n')\n",
    "\n",
    "print(\"Unique values for categorical columns saved to 'temp/categorical_unique_values.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5557575a-aabc-4146-b30c-ab5f6a49b691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole cleaned DataFrame written to 'data/ISBSG2016R1.1-Formatted4CSVAgileOnly_cleaned.csv'\n",
      "Cell executed at: 2025-05-17 16:06:05.970032\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"data/ISBSG2016R1.1-Formatted4CSVAgileOnly_cleaned.csv\", index=False)\n",
    "print(\"Whole cleaned DataFrame written to 'data/ISBSG2016R1.1-Formatted4CSVAgileOnly_cleaned.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc36f39b-4c0c-4941-b9e1-f22b6c14c0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode of Functional Size for each Relative Size:\n",
      "project_prf_relative_size\n",
      "l      1687.000000\n",
      "m1      190.500000\n",
      "m2      616.272727\n",
      "s        56.000000\n",
      "xs       15.500000\n",
      "xxs       5.166667\n",
      "Name: project_prf_functional_size, dtype: float64\n",
      "Cell executed at: 2025-05-17 20:11:14.735004\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Relative Size' and get mode of 'Functional Size' for each group\n",
    "mean_of_modes = df.groupby('project_prf_relative_size')['project_prf_functional_size'].agg(lambda x: x.mode().mean())\n",
    "\n",
    "print(\"Mode of Functional Size for each Relative Size:\")\n",
    "print(mean_of_modes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aacf94-3ef7-41da-ae7e-fae61b6e0e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
