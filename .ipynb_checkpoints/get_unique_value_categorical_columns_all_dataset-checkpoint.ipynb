{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e7795e-2a7a-4a33-b741-e6cb1e55684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a30b9b-f803-4261-a18d-c95980369988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp printing activated.\n",
      "Cell executed at: 2025-05-18 12:47:01.470737\n"
     ]
    }
   ],
   "source": [
    "# Configure timestamp callback for Jupyter cells\n",
    "from IPython import get_ipython\n",
    "\n",
    "def setup_timestamp_callback():\n",
    "    \"\"\"Setup a timestamp callback for Jupyter cells without clearing existing callbacks.\"\"\"\n",
    "    ip = get_ipython()\n",
    "    if ip is not None:\n",
    "        # Define timestamp function\n",
    "        def print_timestamp(*args, **kwargs):\n",
    "            \"\"\"Print timestamp after cell execution.\"\"\"\n",
    "            print(f\"Cell executed at: {datetime.now()}\")\n",
    "        \n",
    "        # Check if our callback is already registered\n",
    "        callbacks = ip.events.callbacks.get('post_run_cell', [])\n",
    "        for cb in callbacks:\n",
    "            if hasattr(cb, '__name__') and cb.__name__ == 'print_timestamp':\n",
    "                # Already registered\n",
    "                return\n",
    "                \n",
    "        # Register new callback if not already present\n",
    "        ip.events.register('post_run_cell', print_timestamp)\n",
    "        print(\"Timestamp printing activated.\")\n",
    "    else:\n",
    "        print(\"Not running in IPython/Jupyter environment.\")\n",
    "\n",
    "# Setup timestamp callback\n",
    "setup_timestamp_callback()\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc45b413-775a-45b7-8d16-c0ef95c83cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Cell executed at: 2025-05-18 12:47:04.060707\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_excel(\"data/ISBSG2016R1.1 - FormattedForCSV.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eb1617d-2715-4890-8d46-d81457477b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-05-18 12:50:32.768663\n"
     ]
    }
   ],
   "source": [
    "# clean up columns like lowercase, strip spaces, remove trailing punctuation\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_category(val):\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    # Lowercase, strip spaces, remove trailing punctuation\n",
    "    val = val.strip().lower()\n",
    "    val = re.sub(r'\\s+', ' ', val)  # collapse multiple spaces\n",
    "    val = val.rstrip(';,.')\n",
    "    # Remove duplicate semicolons and extra spaces between separated values\n",
    "    val = re.sub(r';\\s*;', ';', val)\n",
    "    val = re.sub(r';\\s+', '; ', val)\n",
    "    return val\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].map(clean_category)\n",
    "\n",
    "# Clean column names: lowercase, replace spaces with underscores, strip\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.strip()                # remove leading/trailing spaces\n",
    "    .str.lower()                # make lowercase\n",
    "    .str.replace(' ', '_')      # replace spaces with underscores\n",
    "    .str.replace('-', '_')      # optional: replace hyphens with underscores\n",
    "    .str.replace('__', '_')      \n",
    "    .str.replace('(', '')     \n",
    "    .str.replace(')', '')      \n",
    "    .str.replace('<', 'less_than_')     \n",
    "    .str.replace('>', 'great_than_')\n",
    "    .str.replace('?', '')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81e678e4-1c43-40dc-a912-55b4cdc52d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current columns: ['isbsg_project_id', 'external_eef_data_quality_rating', 'project_prf_year_of_project', 'external_eef_industry_sector', 'external_eef_organisation_type', 'project_prf_application_group', 'project_prf_application_type', 'project_prf_development_type', 'tech_tf_development_platform', 'tech_tf_language_type', 'tech_tf_primary_programming_language', 'project_prf_functional_size', 'project_prf_relative_size', 'project_prf_normalised_work_effort_level_1', 'project_prf_normalised_work_effort', 'project_prf_normalised_level_1_pdr_ufp', 'project_prf_normalised_pdr_ufp', 'project_prf_defect_density', 'project_prf_speed_of_delivery', 'project_prf_manpower_delivery_rate', 'project_prf_project_elapsed_time', 'project_prf_team_size_group', 'project_prf_max_team_size', '_case_tool_used', 'process_pmf_development_methodologies', 'process_pmf_prototyping_used', 'process_pmf_docs', 'tech_tf_architecture', 'tech_tf_client_server', 'tech_tf_client_roles', 'tech_tf_server_roles', 'tech_tf_type_of_server', 'tech_tf_web_development', 'tech_tf_dbms_used', 'tech_tf_tools_used', 'people_prf_project_user_involvement', 'people_prf_ba_team_experience_less_than_1_yr', 'people_prf_ba_team_experience_1_to_3_yr', 'people_prf_ba_team_experience_great_than_3_yr', 'people_prf_it_experience_less_than_1_yr', 'people_prf_it_experience_1_to_3_yr', 'people_prf_it_experience_great_than_3_yr', 'people_prf_it_experience_less_than_3_yr', 'people_prf_it_experience_3_to_9_yr', 'people_prf_it_experience_great_than_9_yr', 'people_prf_project_manage_experience', 'people_prf_project_manage_changes', 'people_prf_personnel_changes', 'project_prf_total_project_cost', 'project_prf_cost_currency', 'project_prf_currency_multiple']\n",
      "Cell executed at: 2025-05-18 12:50:33.964266\n"
     ]
    }
   ],
   "source": [
    "print(\"Current columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19db0f42-f7e1-4aaf-beb2-38303b2627ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-05-18 12:50:45.058863\n"
     ]
    }
   ],
   "source": [
    "# Clean and standardise a semicolon-seperated categorical string\n",
    "\n",
    "def clean_and_sort_semicolon(val):\n",
    "    \"\"\"Clean and standardize a semicolon-separated categorical string.\"\"\"\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    # Split, strip, lower, remove trailing punctuation\n",
    "    parts = [p.strip().lower().rstrip(';,.') for p in val.split(';') if p.strip()]\n",
    "    # Remove duplicates, sort\n",
    "    parts = sorted(set(parts))\n",
    "    return '; '.join(parts)\n",
    "\n",
    "cols_with_semicolons = [\n",
    "    'project_prf_application_group',\n",
    "    'external_eef_organisation_type',\n",
    "    'process_pmf_development_methodologies',\n",
    "    'project_prf_application_type',\n",
    "    'tech_tf_client_roles',\n",
    "    'tech_tf_server_roles',\n",
    "    'tech_tf_type_of_server'\n",
    "]\n",
    "for col in cols_with_semicolons:\n",
    "    df[col] = df[col].map(clean_and_sort_semicolon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "268f3861-a909-4941-933d-ce553bc35da6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tech_tf_architecture'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\streamlit-env-agile\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3790\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._engine.get_loc(casted_key)\n\u001b[32m   3792\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:152\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:181\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'tech_tf_architecture'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# You can add more cases as needed\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m val\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mtech_tf_architecture\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mtech_tf_architecture\u001b[39m\u001b[33m'\u001b[39m].map(standardize_value)\n\u001b[32m     18\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mtech_tf_web_development\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mtech_tf_web_development\u001b[39m\u001b[33m'\u001b[39m].map(standardize_value)\n\u001b[32m     19\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mtech_tf_language_type\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mtech_tf_language_type\u001b[39m\u001b[33m'\u001b[39m].str.upper().str.strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\streamlit-env-agile\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3891\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   3892\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m3893\u001b[39m indexer = \u001b[38;5;28mself\u001b[39m.columns.get_loc(key)\n\u001b[32m   3894\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   3895\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\streamlit-env-agile\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3793\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3794\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3795\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3796\u001b[39m     ):\n\u001b[32m   3797\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3798\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3799\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3800\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3801\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3802\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3803\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'tech_tf_architecture'"
     ]
    }
   ],
   "source": [
    "# Standardise some columns with mixed cases\n",
    "\n",
    "def standardize_value(val):\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    val = val.strip().lower()\n",
    "    if val in ['stand alone', 'stand-alone']:\n",
    "        return 'stand-alone'\n",
    "    if val == 'client server':\n",
    "        return 'client-server'\n",
    "    # Remove question mark from web dev\n",
    "    if val.replace('?', '').strip() == 'web':\n",
    "        return 'web'\n",
    "    # You can add more cases as needed\n",
    "    return val\n",
    "\n",
    "df['tech_tf_architecture'] = df['tech_tf_architecture'].map(standardize_value)\n",
    "df['tech_tf_web_development'] = df['tech_tf_web_development'].map(standardize_value)\n",
    "df['tech_tf_language_type'] = df['tech_tf_language_type'].str.upper().str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a9c17-1557-490a-acef-12190a59742d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea001aed-6c12-440d-ae68-ae3d948a4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save categorical unique values for all categorical columns\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "with open('temp/all_categorical_unique_values.txt', 'w') as f:\n",
    "    for col in cat_cols:\n",
    "        f.write(f\"Column: {col} (n_unique = {df[col].nunique()})\\n\")\n",
    "        f.write(f\"{df[col].unique()}\\n\")\n",
    "        f.write('-' * 40 + '\\n')\n",
    "\n",
    "print(\"Unique values for categorical columns saved to 'temp/all_categorical_unique_values.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31086bd0-d2c5-4a61-bd38-4358f4303656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd70455-798a-49a2-b564-2765c63cdcc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
