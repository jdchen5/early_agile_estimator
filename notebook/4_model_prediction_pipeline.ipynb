{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a76e7ba-b60f-4e20-8bad-96153c1e5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Prediction Pipeline - Using Three Trained Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e224d572-ce5f-4b10-b268-56fb1f6174c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "from typing import Dict, List, Optional, Union, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbde0bb4-adea-4572-8e69-077d242f899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Try to import PyCaret for model loading\n",
    "try:\n",
    "    from pycaret.regression import load_model as pycaret_load_model, predict_model\n",
    "    PYCARET_AVAILABLE = True\n",
    "    logging.info(\"PyCaret is available for model loading\")\n",
    "except ImportError:\n",
    "    PYCARET_AVAILABLE = False\n",
    "    logging.warning(\"PyCaret not available, falling back to pickle loading\")\n",
    "\n",
    "# Configure logging with timestamps\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dfee12a-ae8f-459e-a504-2bc390ee00b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Define paths (adjust these to match your folder structure)\n",
    "MODELS_DIR= \"../models\"\n",
    "DATA_FOLDER = \"../data\"\n",
    "LOGS_FOLDER = \"../logs\"\n",
    "FEATURE_COLS_FILE = 'pycaret_processed_features_before_model_training.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38602b0c-b97c-469b-aa87-b1fe6f6af49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def ensure_directories():\n",
    "    \"\"\"Ensure all required directories exist.\"\"\"\n",
    "    for directory in [MODELS_DIR, DATA_FOLDER, LOGS_FOLDER]:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            logging.info(f\"Created directory: {directory}\")\n",
    "\n",
    "def list_available_models() -> List[str]:\n",
    "    \"\"\"\n",
    "    List all available models in the models directory.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: Names of available trained models (without extension)\n",
    "    \"\"\"\n",
    "    ensure_directories()\n",
    "    \n",
    "    # Get all .pkl files except scaler.pkl\n",
    "    model_files = []\n",
    "    for f in os.listdir(MODELS_DIR):\n",
    "        if f.endswith('.pkl') and not ('scaler' in f.lower()):\n",
    "            model_name = os.path.splitext(f)[0]\n",
    "            model_files.append(model_name)\n",
    "    \n",
    "    logging.info(f\"Found {len(model_files)} available models: {model_files}\")\n",
    "    return model_files\n",
    "\n",
    "def check_required_models() -> Dict[str, bool]:\n",
    "    \"\"\"\n",
    "    Check for existing models in the models directory.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, bool]: Dictionary with model status (True if found)\n",
    "    \"\"\"\n",
    "    ensure_directories()\n",
    "    \n",
    "    # Get all model files\n",
    "    existing_files = os.listdir(MODELS_DIR)\n",
    "    existing_models = [f for f in existing_files if f.endswith('.pkl')]\n",
    "    \n",
    "    # Check for at least one model and optionally a scaler\n",
    "    has_models = any(f for f in existing_models if not f.startswith('scaler'))\n",
    "    has_scaler = any(f for f in existing_models if f.startswith('scaler'))\n",
    "    \n",
    "    model_status = {\n",
    "        \"models_available\": has_models,\n",
    "        \"scaler_available\": has_scaler,\n",
    "        \"found_models\": [os.path.splitext(f)[0] for f in existing_models if not ('scaler' in f.lower())]\n",
    "    }\n",
    "    \n",
    "    if has_models:\n",
    "        logging.info(f\"Found models in '{MODELS_DIR}': {[f for f in existing_models if not ('scaler' in f.lower())]}\")\n",
    "    else:\n",
    "        logging.warning(f\"No trained models found in '{MODELS_DIR}'\")\n",
    "        logging.info(\"Please train and save models via PyCaret in your Jupyter notebook before using this app.\")\n",
    "    \n",
    "    return model_status\n",
    "\n",
    "def load_single_model(model_name: str) -> Optional[Any]:\n",
    "    \"\"\"\n",
    "    Load a model from the models directory, supporting both PyCaret and pickle formats.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Name of the model to load (without extension)\n",
    "        \n",
    "    Returns:\n",
    "        Optional[Any]: Loaded model object or None if not found/error\n",
    "    \"\"\"\n",
    "    model_path = os.path.join(MODELS_DIR, model_name)\n",
    "    model_path_with_ext = os.path.join(MODELS_DIR, f'{model_name}.pkl')\n",
    "    \n",
    "    # First, try PyCaret's load_model (without extension)\n",
    "    if PYCARET_AVAILABLE:\n",
    "        try:\n",
    "            model = pycaret_load_model(model_path)\n",
    "            logging.info(f\"Successfully loaded PyCaret model: {model_name}\")\n",
    "            logging.info(f\"Model type: {type(model)}\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"PyCaret load failed for '{model_name}': {str(e)}\")\n",
    "    \n",
    "    # Fall back to pickle loading (with extension)\n",
    "    if os.path.exists(model_path_with_ext):\n",
    "        try:\n",
    "            with open(model_path_with_ext, 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "            \n",
    "            logging.info(f\"Successfully loaded pickle model: {model_name}\")\n",
    "            logging.info(f\"Loaded object type: {type(model)}\")\n",
    "            \n",
    "            # For PyCaret models saved with pickle, they might be wrapped\n",
    "            if hasattr(model, 'predict') or hasattr(model, '_predict'):\n",
    "                return model\n",
    "            else:\n",
    "                logging.error(f\"Loaded object '{model_name}' does not have prediction capability\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading model '{model_name}' with pickle: {str(e)}\")\n",
    "    \n",
    "    logging.error(f\"Model file '{model_name}' not found in either format\")\n",
    "    return None\n",
    "\n",
    "def load_scaler() -> Optional[Any]:\n",
    "    \"\"\"\n",
    "    Load the scaler if available in the models directory.\n",
    "    \n",
    "    Returns:\n",
    "        Optional[Any]: Loaded scaler object or None if not found/error\n",
    "    \"\"\"\n",
    "    ensure_directories()\n",
    "    scaler_files = [f for f in os.listdir(MODELS_DIR) \n",
    "                   if 'scaler' in f.lower() and f.endswith('.pkl')]\n",
    "    \n",
    "    if not scaler_files:\n",
    "        logging.info(\"No scaler found. Proceeding without scaling.\")\n",
    "        return None\n",
    "    \n",
    "    # Use the first scaler found\n",
    "    scaler_path = os.path.join(MODELS_DIR, scaler_files[0])\n",
    "    \n",
    "    try:\n",
    "        with open(scaler_path, 'rb') as f:\n",
    "            scaler = pickle.load(f)\n",
    "        \n",
    "        logging.info(f\"Successfully loaded scaler: {scaler_files[0]}\")\n",
    "        logging.info(f\"Scaler type: {type(scaler)}\")\n",
    "        return scaler\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading scaler '{scaler_files[0]}': {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_expected_feature_names_from_csv() -> List[str]:\n",
    "    \"\"\"\n",
    "    Get the expected feature names from the saved CSV file.\n",
    "    \"\"\"\n",
    "    feature_cols_path = os.path.join(DATA_FOLDER, FEATURE_COLS_FILE)\n",
    "    \n",
    "    if os.path.exists(feature_cols_path):\n",
    "        try:\n",
    "            # Try to read as single column\n",
    "            feature_names = pd.read_csv(feature_cols_path, header=None)[0].tolist()\n",
    "            logging.info(f\"Loaded {len(feature_names)} feature names from CSV\")\n",
    "            return feature_names\n",
    "        except:\n",
    "            try:\n",
    "                # Try to read with headers\n",
    "                df = pd.read_csv(feature_cols_path)\n",
    "                feature_names = df.columns.tolist()\n",
    "                logging.info(f\"Loaded {len(feature_names)} feature names from CSV headers\")\n",
    "                return feature_names\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error reading feature names from CSV: {str(e)}\")\n",
    "    \n",
    "    # Fallback to default feature names\n",
    "    logging.warning(\"Using default feature names as fallback\")\n",
    "    return [\n",
    "        'project_prf_year_of_project',\n",
    "        'project_prf_functional_size', \n",
    "        'project_prf_max_team_size',\n",
    "        'process_pmf_docs',\n",
    "        'tech_tf_tools_used',\n",
    "        'people_prf_personnel_changes'\n",
    "    ]\n",
    "\n",
    "def prepare_features_for_pycaret(features_dict: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare a prediction DataFrame with the exact columns expected by the model pipeline.\n",
    "    Missing columns will be filled with 0.\n",
    "\n",
    "    Args:\n",
    "        features_dict (dict): Input features as {column_name: value}\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with all expected columns, ready for prediction.\n",
    "    \"\"\"\n",
    "    feature_names = get_expected_feature_names_from_csv()\n",
    "    \n",
    "    # Fill in missing columns with 0\n",
    "    full_features = {col: features_dict.get(col, 0) for col in feature_names}\n",
    "    return pd.DataFrame([full_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ee257c3-7e45-4a40-b3e9-c6e27c20c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENHANCED MODEL LOADING AND MANAGEMENT\n",
    "# =============================================================================\n",
    "\n",
    "def load_all_models() -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Load all available models from the models directory.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Dict]: Dictionary with model information and loaded objects\n",
    "    \"\"\"\n",
    "    print(\"Loading all available models...\")\n",
    "    \n",
    "    available_models = list_available_models()\n",
    "    loaded_models = {}\n",
    "    \n",
    "    for model_name in available_models:\n",
    "        try:\n",
    "            model = load_single_model(model_name)\n",
    "            if model is not None:\n",
    "                loaded_models[model_name] = {\n",
    "                    'model': model,\n",
    "                    'name': model_name,\n",
    "                    'type': type(model).__name__\n",
    "                }\n",
    "                print(f\"‚úì Loaded: {model_name}\")\n",
    "            else:\n",
    "                print(f\"‚úó Failed to load: {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Error loading {model_name}: {str(e)}\")\n",
    "    \n",
    "    # Load scaler if available\n",
    "    scaler = load_scaler()\n",
    "    if scaler:\n",
    "        loaded_models['scaler'] = {\n",
    "            'model': scaler,\n",
    "            'name': 'scaler',\n",
    "            'type': type(scaler).__name__\n",
    "        }\n",
    "    \n",
    "    print(f\"\\nSuccessfully loaded {len([k for k in loaded_models.keys() if k != 'scaler'])} models\")\n",
    "    return loaded_models\n",
    "\n",
    "# =============================================================================\n",
    "# ENHANCED PREDICTION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def predict_with_single_model(\n",
    "    features_dict: dict, \n",
    "    model_name: str, \n",
    "    loaded_models: Dict,\n",
    "    use_scaler: bool = True\n",
    ") -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Make a prediction using a specific model with enhanced error handling.\n",
    "    \n",
    "    Args:\n",
    "        features_dict (dict): Input features as dictionary\n",
    "        model_name (str): Name of the model to use\n",
    "        loaded_models (Dict): Dictionary of loaded models\n",
    "        use_scaler (bool): Whether to apply scaling if available\n",
    "        \n",
    "    Returns:\n",
    "        Optional[float]: Predicted value or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Debug logging\n",
    "        logging.info(f\"Starting prediction with model '{model_name}'\")\n",
    "        logging.info(f\"Input features: {features_dict}\")\n",
    "        \n",
    "        # Check if model is loaded\n",
    "        if model_name not in loaded_models:\n",
    "            logging.error(f\"Model '{model_name}' not found in loaded models\")\n",
    "            return None\n",
    "        \n",
    "        model = loaded_models[model_name]['model']\n",
    "        logging.info(f\"Using model type: {type(model)}\")\n",
    "\n",
    "        # Prepare features DataFrame using CSV-defined columns\n",
    "        features_df = prepare_features_for_pycaret(features_dict)\n",
    "        logging.info(f\"Features DataFrame columns: {list(features_df.columns)}\")\n",
    "        logging.info(f\"Features DataFrame shape: {features_df.shape}\")\n",
    "        \n",
    "        # Apply scaler if requested and available\n",
    "        if use_scaler and 'scaler' in loaded_models:\n",
    "            scaler = loaded_models['scaler']['model']\n",
    "            if hasattr(scaler, 'transform'):\n",
    "                try:\n",
    "                    # Only scale numerical columns that the scaler was trained on\n",
    "                    numerical_cols = features_df.select_dtypes(include=[np.number]).columns\n",
    "                    if len(numerical_cols) > 0:\n",
    "                        features_df[numerical_cols] = scaler.transform(features_df[numerical_cols])\n",
    "                        logging.info(\"Applied scaler to numerical features.\")\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Scaler could not be applied: {str(e)}\")\n",
    "        \n",
    "        # Try PyCaret prediction first\n",
    "        if PYCARET_AVAILABLE:\n",
    "            try:\n",
    "                logging.info(\"Attempting PyCaret prediction...\")\n",
    "                predictions = predict_model(model, data=features_df)\n",
    "                \n",
    "                # Look for prediction in various possible column names\n",
    "                possible_columns = ['prediction_label', 'Label', 'pred', 'prediction', 'target']\n",
    "                prediction_value = None\n",
    "                \n",
    "                for col in possible_columns:\n",
    "                    if col in predictions.columns:\n",
    "                        prediction_value = float(predictions[col].iloc[0])\n",
    "                        logging.info(f\"Found prediction in column '{col}': {prediction_value}\")\n",
    "                        break\n",
    "                \n",
    "                if prediction_value is None:\n",
    "                    # Use the last column as fallback\n",
    "                    prediction_value = float(predictions.iloc[0, -1])\n",
    "                    logging.info(f\"Used last column for prediction: {prediction_value}\")\n",
    "                \n",
    "                # Validate prediction value\n",
    "                if np.isnan(prediction_value) or np.isinf(prediction_value):\n",
    "                    logging.error(f\"Invalid prediction value: {prediction_value}\")\n",
    "                    return None\n",
    "                \n",
    "                return max(0.1, prediction_value)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.warning(f\"PyCaret prediction failed: {str(e)}\")\n",
    "                import traceback\n",
    "                logging.warning(traceback.format_exc())\n",
    "\n",
    "        # Fallback: standard sklearn prediction\n",
    "        if hasattr(model, 'predict'):\n",
    "            try:\n",
    "                prediction = model.predict(features_df)\n",
    "                \n",
    "                if isinstance(prediction, np.ndarray):\n",
    "                    prediction_value = float(prediction.flat[0])\n",
    "                elif isinstance(prediction, (list, tuple)):\n",
    "                    prediction_value = float(prediction[0])\n",
    "                else:\n",
    "                    prediction_value = float(prediction)\n",
    "                \n",
    "                # Validate prediction value\n",
    "                if np.isnan(prediction_value) or np.isinf(prediction_value):\n",
    "                    logging.error(f\"Invalid prediction value: {prediction_value}\")\n",
    "                    return None\n",
    "                \n",
    "                return max(0.1, prediction_value)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Standard prediction failed: {str(e)}\")\n",
    "                import traceback\n",
    "                logging.error(traceback.format_exc())\n",
    "\n",
    "        logging.error(f\"No valid prediction method found for model '{model_name}'\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error making prediction with model '{model_name}': {str(e)}\")\n",
    "        import traceback\n",
    "        logging.error(f\"Full traceback: {traceback.format_exc()}\")\n",
    "        return None\n",
    "\n",
    "def make_predictions_all_models(\n",
    "    features_dict: dict, \n",
    "    loaded_models: Dict,\n",
    "    use_scaler: bool = True\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Make predictions using all loaded models.\n",
    "    \n",
    "    Args:\n",
    "        features_dict (dict): Input features as dictionary\n",
    "        loaded_models (Dict): Dictionary of loaded models\n",
    "        use_scaler (bool): Whether to apply scaling if available\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, float]: Dictionary with model names and predictions\n",
    "    \"\"\"\n",
    "    predictions = {}\n",
    "    \n",
    "    # Filter out scaler from models\n",
    "    model_names = [name for name in loaded_models.keys() if name != 'standard_scaler']\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        if model_name in results_df.columns:\n",
    "            predictions = results_df[model_name].dropna()\n",
    "            if len(predictions) > 0:\n",
    "                print(f\"\\n{model_name}:\")\n",
    "                print(f\"  Mean: {predictions.mean():.3f}\")\n",
    "                print(f\"  Std:  {predictions.std():.3f}\")\n",
    "                print(f\"  Range: [{predictions.min():.3f}, {predictions.max():.3f}]\")\n",
    "    \n",
    "    if 'ensemble_prediction' in results_df.columns:\n",
    "        ensemble_preds = results_df['ensemble_prediction'].dropna()\n",
    "        if len(ensemble_preds) > 0:\n",
    "            print(f\"\\nEnsemble Prediction:\")\n",
    "            print(f\"  Mean: {ensemble_preds.mean():.3f}\")\n",
    "            print(f\"  Std:  {ensemble_preds.std():.3f}\")\n",
    "    \n",
    "    return results_df, loaded_models, importance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ce7d3b2-1264-4883-b7a4-ede6aa7eb5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXAMPLE USAGE AND DEMONSTRATIONS\n",
    "# =============================================================================\n",
    "\n",
    "def demo_single_prediction():\n",
    "    \"\"\"Demonstrate single prediction functionality.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DEMO: Single Prediction\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Load models\n",
    "    loaded_models = load_all_models()\n",
    "    if not loaded_models:\n",
    "        print(\"‚ùå No models available for demo\")\n",
    "        return\n",
    "    \n",
    "    # Sample features\n",
    "    sample_features = {\n",
    "        'project_prf_year_of_project': 2023,\n",
    "        'project_prf_functional_size': 150.5,\n",
    "        'project_prf_max_team_size': 8,\n",
    "        'process_pmf_docs': 1,\n",
    "        'tech_tf_tools_used': 2,\n",
    "        'people_prf_personnel_changes': 0\n",
    "    }\n",
    "    \n",
    "    # Make predictions with all models\n",
    "    predictions = make_predictions_all_models(sample_features, loaded_models)\n",
    "    \n",
    "    print(f\"\\nSample Input: {sample_features}\")\n",
    "    print(f\"Predictions: {predictions}\")\n",
    "    \n",
    "    # Plot predictions comparison\n",
    "    plot_predictions_comparison(predictions)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def demo_what_if_analysis():\n",
    "    \"\"\"Demonstrate what-if analysis functionality.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DEMO: What-If Analysis\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Load models\n",
    "    loaded_models = load_all_models()\n",
    "    if not loaded_models:\n",
    "        print(\"‚ùå No models available for demo\")\n",
    "        return\n",
    "    \n",
    "    # Base features\n",
    "    base_features = {\n",
    "        'project_prf_year_of_project': 2023,\n",
    "        'project_prf_functional_size': 150.5,\n",
    "        'project_prf_max_team_size': 8,\n",
    "        'process_pmf_docs': 1,\n",
    "        'tech_tf_tools_used': 2,\n",
    "        'people_prf_personnel_changes': 0\n",
    "    }\n",
    "    \n",
    "    # Vary functional size\n",
    "    model_name = list(loaded_models.keys())[0]  # Use first available model\n",
    "    if model_name == 'scaler':\n",
    "        model_name = list(loaded_models.keys())[1] if len(loaded_models) > 1 else None\n",
    "    \n",
    "    if model_name:\n",
    "        size_values = [50, 100, 150, 200, 250, 300]\n",
    "        what_if_results = analyze_what_if(\n",
    "            base_features, model_name, loaded_models,\n",
    "            'project_prf_functional_size', size_values\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nWhat-If Analysis Results for 'project_prf_functional_size':\")\n",
    "        for size, pred in zip(what_if_results[\"param_values\"], what_if_results[\"predictions\"]):\n",
    "            print(f\"  Size {size}: Prediction {pred:.3f}\")\n",
    "        \n",
    "        # Plot what-if analysis\n",
    "        plot_what_if_analysis(what_if_results, 'project_prf_functional_size')\n",
    "        \n",
    "        return what_if_results\n",
    "    else:\n",
    "        print(\"‚ùå No suitable model found for what-if analysis\")\n",
    "        return None\n",
    "\n",
    "def demo_feature_importance():\n",
    "    \"\"\"Demonstrate feature importance analysis.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DEMO: Feature Importance Analysis\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Load models\n",
    "    loaded_models = load_all_models()\n",
    "    if not loaded_models:\n",
    "        print(\"‚ùå No models available for demo\")\n",
    "        return\n",
    "    \n",
    "    # Analyze feature importance\n",
    "    importance_results = analyze_feature_importance_all_models(loaded_models)\n",
    "    \n",
    "    if importance_results:\n",
    "        feature_names = get_expected_feature_names_from_csv()\n",
    "        \n",
    "        print(\"\\nFeature Importance Summary:\")\n",
    "        for model_name, importance in importance_results.items():\n",
    "            if len(importance) == len(feature_names):\n",
    "                print(f\"\\n{model_name}:\")\n",
    "                for feature, imp in zip(feature_names, importance):\n",
    "                    print(f\"  {feature}: {imp:.4f}\")\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plot_feature_importance(importance_results)\n",
    "        \n",
    "        return importance_results\n",
    "    else:\n",
    "        print(\"‚ùå No feature importance available from loaded models\")\n",
    "        return None\n",
    "\n",
    "def create_interactive_prediction_interface():\n",
    "    \"\"\"Create an interactive interface for making predictions.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"INTERACTIVE PREDICTION INTERFACE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Load models\n",
    "    loaded_models = load_all_models()\n",
    "    if not loaded_models:\n",
    "        print(\"‚ùå No models available\")\n",
    "        return\n",
    "    \n",
    "    feature_names = get_expected_feature_names_from_csv()\n",
    "    \n",
    "    print(\"\\nEnter values for the following features:\")\n",
    "    print(\"(Press Enter to use default values)\")\n",
    "    \n",
    "    # Default values\n",
    "    default_values = {\n",
    "        'project_prf_year_of_project': 2023,\n",
    "        'project_prf_functional_size': 150.0,\n",
    "        'project_prf_max_team_size': 8,\n",
    "        'process_pmf_docs': 1,\n",
    "        'tech_tf_tools_used': 2,\n",
    "        'people_prf_personnel_changes': 0\n",
    "    }\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    for feature in feature_names:\n",
    "        default_val = default_values.get(feature, 0)\n",
    "        try:\n",
    "            user_input = input(f\"{feature} (default: {default_val}): \").strip()\n",
    "            if user_input:\n",
    "                features[feature] = float(user_input)\n",
    "            else:\n",
    "                features[feature] = default_val\n",
    "        except ValueError:\n",
    "            print(f\"Invalid input, using default value: {default_val}\")\n",
    "            features[feature] = default_val\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nOperation cancelled by user\")\n",
    "            return\n",
    "    \n",
    "    print(f\"\\nInput Features: {features}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = make_predictions_all_models(features, loaded_models)\n",
    "    \n",
    "    print(\"\\nPrediction Results:\")\n",
    "    for model_name, prediction in predictions.items():\n",
    "        if prediction is not None:\n",
    "            print(f\"  {model_name}: {prediction:.3f}\")\n",
    "        else:\n",
    "            print(f\"  {model_name}: Failed\")\n",
    "    \n",
    "    # Calculate ensemble\n",
    "    valid_predictions = [v for v in predictions.values() if v is not None]\n",
    "    if valid_predictions:\n",
    "        ensemble_pred = np.mean(valid_predictions)\n",
    "        ensemble_std = np.std(valid_predictions) if len(valid_predictions) > 1 else 0\n",
    "        print(f\"\\nEnsemble Prediction: {ensemble_pred:.3f} ¬± {ensemble_std:.3f}\")\n",
    "    \n",
    "    # Plot results\n",
    "    plot_predictions_comparison(predictions)\n",
    "    \n",
    "    return features, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acdcdcdc-c7d7-48cd-aa20-8d78936a5706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BATCH PROCESSING UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "def process_csv_file(csv_path: str, output_path: str = None):\n",
    "    \"\"\"\n",
    "    Process a CSV file with batch predictions.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to input CSV file\n",
    "        output_path (str): Path to save results (optional)\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìÅ Processing CSV file: {csv_path}\")\n",
    "    \n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"‚ùå File not found: {csv_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Load models\n",
    "    loaded_models = load_all_models()\n",
    "    if not loaded_models:\n",
    "        print(\"‚ùå No models available\")\n",
    "        return None\n",
    "    \n",
    "    # Load data\n",
    "    try:\n",
    "        data = pd.read_csv(csv_path)\n",
    "        print(f\"‚úì Loaded data: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading CSV: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Process predictions\n",
    "    results_df = batch_predict_dataframe(data, loaded_models)\n",
    "    \n",
    "    # Save results\n",
    "    if output_path is None:\n",
    "        output_path = csv_path.replace('.csv', '_predictions.csv')\n",
    "    \n",
    "    try:\n",
    "        results_df.to_csv(output_path, index=False)\n",
    "        print(f\"‚úì Results saved to: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving results: {str(e)}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def compare_model_performance(results_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Compare performance metrics across models.\n",
    "    \n",
    "    Args:\n",
    "        results_df (pd.DataFrame): DataFrame with predictions from multiple models\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Get model columns (exclude original features and ensemble)\n",
    "    feature_names = get_expected_feature_names_from_csv()\n",
    "    model_columns = [col for col in results_df.columns \n",
    "                    if col not in feature_names \n",
    "                    and col not in ['ensemble_prediction', 'prediction_std']]\n",
    "    \n",
    "    if not model_columns:\n",
    "        print(\"‚ùå No model predictions found in results\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nPrediction Statistics:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for model_col in model_columns:\n",
    "        if model_col in results_df.columns:\n",
    "            predictions = results_df[model_col].dropna()\n",
    "            if len(predictions) > 0:\n",
    "                print(f\"\\n{model_col}:\")\n",
    "                print(f\"  Count: {len(predictions)}\")\n",
    "                print(f\"  Mean:  {predictions.mean():.3f}\")\n",
    "                print(f\"  Std:   {predictions.std():.3f}\")\n",
    "                print(f\"  Min:   {predictions.min():.3f}\")\n",
    "                print(f\"  Max:   {predictions.max():.3f}\")\n",
    "                print(f\"  Median: {predictions.median():.3f}\")\n",
    "    \n",
    "    # Correlation analysis\n",
    "    try:\n",
    "        model_data = results_df[model_columns].dropna()\n",
    "        if len(model_data) > 1 and len(model_columns) > 1:\n",
    "            print(\"\\nModel Correlation Matrix:\")\n",
    "            print(\"-\" * 30)\n",
    "            correlation_matrix = model_data.corr()\n",
    "            print(correlation_matrix.round(3))\n",
    "            \n",
    "            # Plot correlation heatmap if matplotlib is available\n",
    "            try:\n",
    "                import matplotlib.pyplot as plt\n",
    "                import seaborn as sns\n",
    "                \n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "                plt.title('Model Prediction Correlations')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "            except ImportError:\n",
    "                pass\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error in correlation analysis: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd969244-de9f-47f3-880b-7948fce241d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Enhanced Model Prediction Pipeline - Jupyter Notebook Ready!\n",
      "============================================================\n",
      "Setting up notebook environment...\n",
      "\n",
      "Checking required packages:\n",
      "‚úì pandas\n",
      "‚úì numpy\n",
      "‚ùå scikit-learn - REQUIRED\n",
      "\n",
      "Checking optional packages:\n",
      "‚úì matplotlib\n",
      "‚úì seaborn\n",
      "‚úì plotly\n",
      "\n",
      "üìÅ Directory structure:\n",
      "‚úì ../models/\n",
      "‚úì ../data/\n",
      "‚úì ../logs/\n",
      "\n",
      "üéØ Notebook environment setup complete!\n",
      "\n",
      "============================================================\n",
      "üöÄ QUICK START GUIDE\n",
      "============================================================\n",
      "\n",
      "üìã USAGE INSTRUCTIONS:\n",
      "\n",
      "1. SETUP:\n",
      "   - Ensure your trained models are saved in the 'models/' directory\n",
      "   - Models should be saved as .pkl files (PyCaret or pickle format)\n",
      "   - Feature names should be saved in 'data/pycaret_processed_features_before_model_training.csv'\n",
      "\n",
      "2. BASIC USAGE:\n",
      "   # Run complete analysis\n",
      "   results = run_complete_analysis()\n",
      "\n",
      "   # Single prediction\n",
      "   predictions = demo_single_prediction()\n",
      "\n",
      "   # Interactive interface\n",
      "   create_interactive_prediction_interface()\n",
      "\n",
      "3. BATCH PROCESSING:\n",
      "   # Process CSV file\n",
      "   results_df = process_csv_file('your_data.csv')\n",
      "\n",
      "   # Custom data\n",
      "   results_df, models, importance = run_enhanced_prediction_pipeline(\n",
      "       data_path='your_data.csv'\n",
      "   )\n",
      "\n",
      "4. ANALYSIS:\n",
      "   # What-if analysis\n",
      "   what_if_results = demo_what_if_analysis()\n",
      "\n",
      "   # Feature importance\n",
      "   importance_results = demo_feature_importance()\n",
      "\n",
      "5. FILES GENERATED:\n",
      "   - enhanced_predictions.csv (prediction results)\n",
      "   - feature_importance.csv (feature importance data)\n",
      "   - Various plots and visualizations\n",
      "\n",
      "üí° TIP: Start with setup_notebook_environment() to check your setup!\n",
      "    \n",
      "\n",
      "‚úÖ Found 6 trained models!\n",
      "You can now run the analysis pipeline.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MAIN EXECUTION AND JUPYTER NOTEBOOK INTERFACE\n",
    "# =============================================================================\n",
    "\n",
    "def run_complete_analysis():\n",
    "    \"\"\"Run a complete analysis pipeline with all demonstrations.\"\"\"\n",
    "    print(\"üöÄ STARTING COMPLETE PREDICTION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # 1. Run main pipeline\n",
    "        print(\"\\n1Ô∏è‚É£ Running Enhanced Prediction Pipeline...\")\n",
    "        results_df, loaded_models, importance_results = run_enhanced_prediction_pipeline()\n",
    "        \n",
    "        if results_df is None:\n",
    "            print(\"‚ùå Pipeline failed to complete\")\n",
    "            return\n",
    "        \n",
    "        # 2. Demo single prediction\n",
    "        print(\"\\n2Ô∏è‚É£ Single Prediction Demo...\")\n",
    "        demo_predictions = demo_single_prediction()\n",
    "        \n",
    "        # 3. Demo what-if analysis\n",
    "        print(\"\\n3Ô∏è‚É£ What-If Analysis Demo...\")\n",
    "        what_if_results = demo_what_if_analysis()\n",
    "        \n",
    "        # 4. Demo feature importance\n",
    "        print(\"\\n4Ô∏è‚É£ Feature Importance Demo...\")\n",
    "        feature_importance = demo_feature_importance()\n",
    "        \n",
    "        # 5. Model performance comparison\n",
    "        print(\"\\n5Ô∏è‚É£ Model Performance Comparison...\")\n",
    "        compare_model_performance(results_df)\n",
    "        \n",
    "        print(\"\\n‚úÖ COMPLETE ANALYSIS FINISHED SUCCESSFULLY!\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return {\n",
    "            'results_df': results_df,\n",
    "            'loaded_models': loaded_models,\n",
    "            'importance_results': importance_results,\n",
    "            'demo_predictions': demo_predictions,\n",
    "            'what_if_results': what_if_results,\n",
    "            'feature_importance': feature_importance\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in complete analysis: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# =============================================================================\n",
    "# JUPYTER NOTEBOOK HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def setup_notebook_environment():\n",
    "    \"\"\"Setup the notebook environment with necessary imports and configurations.\"\"\"\n",
    "    print(\"Setting up notebook environment...\")\n",
    "    \n",
    "    # Check for required packages\n",
    "    required_packages = ['pandas', 'numpy', 'scikit-learn']\n",
    "    optional_packages = ['matplotlib', 'seaborn', 'plotly']\n",
    "    \n",
    "    print(\"\\nChecking required packages:\")\n",
    "    for package in required_packages:\n",
    "        try:\n",
    "            __import__(package)\n",
    "            print(f\"‚úì {package}\")\n",
    "        except ImportError:\n",
    "            print(f\"‚ùå {package} - REQUIRED\")\n",
    "    \n",
    "    print(\"\\nChecking optional packages:\")\n",
    "    for package in optional_packages:\n",
    "        try:\n",
    "            __import__(package)\n",
    "            print(f\"‚úì {package}\")\n",
    "        except ImportError:\n",
    "            print(f\"‚ö†Ô∏è {package} - Optional (for visualization)\")\n",
    "    \n",
    "    # Setup directories\n",
    "    ensure_directories()\n",
    "    \n",
    "    print(\"\\nüìÅ Directory structure:\")\n",
    "    for directory in [MODELS_DIR, DATA_FOLDER, LOGS_FOLDER]:\n",
    "        status = \"‚úì\" if os.path.exists(directory) else \"‚ùå\"\n",
    "        print(f\"{status} {directory}/\")\n",
    "    \n",
    "    print(\"\\nüéØ Notebook environment setup complete!\")\n",
    "\n",
    "def quick_start_guide():\n",
    "    \"\"\"Display a quick start guide for users.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üöÄ QUICK START GUIDE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\"\"\n",
    "üìã USAGE INSTRUCTIONS:\n",
    "\n",
    "1. SETUP:\n",
    "   - Ensure your trained models are saved in the 'models/' directory\n",
    "   - Models should be saved as .pkl files (PyCaret or pickle format)\n",
    "   - Feature names should be saved in 'data/pycaret_processed_features_before_model_training.csv'\n",
    "\n",
    "2. BASIC USAGE:\n",
    "   # Run complete analysis\n",
    "   results = run_complete_analysis()\n",
    "   \n",
    "   # Single prediction\n",
    "   predictions = demo_single_prediction()\n",
    "   \n",
    "   # Interactive interface\n",
    "   create_interactive_prediction_interface()\n",
    "\n",
    "3. BATCH PROCESSING:\n",
    "   # Process CSV file\n",
    "   results_df = process_csv_file('your_data.csv')\n",
    "   \n",
    "   # Custom data\n",
    "   results_df, models, importance = run_enhanced_prediction_pipeline(\n",
    "       data_path='your_data.csv'\n",
    "   )\n",
    "\n",
    "4. ANALYSIS:\n",
    "   # What-if analysis\n",
    "   what_if_results = demo_what_if_analysis()\n",
    "   \n",
    "   # Feature importance\n",
    "   importance_results = demo_feature_importance()\n",
    "\n",
    "5. FILES GENERATED:\n",
    "   - enhanced_predictions.csv (prediction results)\n",
    "   - feature_importance.csv (feature importance data)\n",
    "   - Various plots and visualizations\n",
    "\n",
    "üí° TIP: Start with setup_notebook_environment() to check your setup!\n",
    "    \"\"\")\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION BLOCK FOR JUPYTER NOTEBOOKS\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # This block runs when the script is executed directly\n",
    "    print(\"üéØ Enhanced Model Prediction Pipeline - Jupyter Notebook Ready!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Setup environment\n",
    "    setup_notebook_environment()\n",
    "    \n",
    "    # Display quick start guide\n",
    "    quick_start_guide()\n",
    "    \n",
    "    # Check for models\n",
    "    model_status = check_required_models()\n",
    "    \n",
    "    if model_status[\"models_available\"]:\n",
    "        print(f\"\\n‚úÖ Found {len(model_status['found_models'])} trained models!\")\n",
    "        print(\"You can now run the analysis pipeline.\")\n",
    "        \n",
    "        # Uncomment the line below to run complete analysis automatically\n",
    "        # run_complete_analysis()\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No trained models found.\")\n",
    "        print(\"Please train and save your models first using PyCaret.\")\n",
    "        print(\"Then run: run_complete_analysis()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e49c3d8f-85f1-4910-b463-1f1533745e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Copy the cell examples above to get started quickly in your Jupyter notebook!\n",
      "üéâ Setup complete! Happy predicting!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìù Copy the cell examples above to get started quickly in your Jupyter notebook!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müéâ Setup complete! Happy predicting!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMaking predictions with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(model_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m models...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m predictions = {}\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_names:\n",
      "\u001b[31mNameError\u001b[39m: name 'model_names' is not defined"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# NOTEBOOK CELL EXECUTION HELPERS\n",
    "# =============================================================================\n",
    "\n",
    "# For easy copy-paste into notebook cells:\n",
    "\n",
    "\"\"\"\n",
    "# CELL 1: Setup and Check Environment\n",
    "setup_notebook_environment()\n",
    "\n",
    "# CELL 2: Quick Start Guide\n",
    "quick_start_guide()\n",
    "\n",
    "# CELL 3: Run Complete Analysis (if models are available)\n",
    "results = run_complete_analysis()\n",
    "\n",
    "# CELL 4: Single Prediction Demo\n",
    "predictions = demo_single_prediction()\n",
    "\n",
    "# CELL 5: Interactive Prediction Interface\n",
    "create_interactive_prediction_interface()\n",
    "\n",
    "# CELL 6: Process your own CSV file\n",
    "# results_df = process_csv_file('path/to/your/data.csv')\n",
    "\n",
    "# CELL 7: What-If Analysis\n",
    "what_if_results = demo_what_if_analysis()\n",
    "\n",
    "# CELL 8: Feature Importance Analysis\n",
    "importance_results = demo_feature_importance()\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìù Copy the cell examples above to get started quickly in your Jupyter notebook!\")\n",
    "print(\"üéâ Setup complete! Happy predicting!\")\n",
    "\n",
    "print(f\"\\nMaking predictions with {len(model_names)} models...\")\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    try:\n",
    "        prediction = predict_with_single_model(\n",
    "            features_dict, model_name, loaded_models, use_scaler\n",
    "        )\n",
    "\n",
    "        if prediction is not None:\n",
    "            predictions[model_name] = prediction\n",
    "            print(f\"‚úì {model_name}: {prediction:.3f}\")\n",
    "        else:\n",
    "            print(f\"‚úó {model_name}: Prediction failed\")\n",
    "            predictions[model_name] = None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó {model_name}: Error - {str(e)}\")\n",
    "        predictions[model_name] = None\n",
    "\n",
    "return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65232a82-6316-4278-b391-158f84a11c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENHANCED BATCH PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "def prepare_new_data(new_data_path=None, sample_data=None):\n",
    "    \"\"\"\n",
    "    Prepare new data for prediction with enhanced flexibility.\n",
    "    \n",
    "    Parameters:\n",
    "    - new_data_path: path to CSV file with new data\n",
    "    - sample_data: pandas DataFrame with new data\n",
    "    \n",
    "    Returns:\n",
    "    - prepared_data: DataFrame ready for prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    if new_data_path:\n",
    "        # Load new data from CSV\n",
    "        new_data = pd.read_csv(new_data_path)\n",
    "        print(f\"Loaded new data from {new_data_path}: {new_data.shape}\")\n",
    "    elif sample_data is not None:\n",
    "        new_data = sample_data.copy()\n",
    "        print(f\"Using provided sample data: {new_data.shape}\")\n",
    "    else:\n",
    "        # Create sample data for demonstration\n",
    "        print(\"Creating sample data for demonstration...\")\n",
    "        new_data = pd.DataFrame({\n",
    "            'project_prf_year_of_project': [2023, 2024, 2022, 2023],\n",
    "            'project_prf_functional_size': [150.5, 200.0, 89.3, 175.2],\n",
    "            'project_prf_used_methodology': ['Agile', 'Waterfall', 'Agile', 'Hybrid'],\n",
    "            'technology_prf_development_platform': ['Web', 'Desktop', 'Mobile', 'Web'],\n",
    "            'technology_prf_language_type': ['4GL', '3GL', '4GL', '3GL'],\n",
    "            'project_prf_development_type': ['New', 'Enhancement', 'New', 'Enhancement'],\n",
    "            'technology_prf_database_used': ['Yes', 'Yes', 'No', 'Yes'],\n",
    "            'project_prf_max_team_size': [8, 12, 5, 10]\n",
    "        })\n",
    "        print(f\"Created sample data: {new_data.shape}\")\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "def batch_predict_dataframe(data_df: pd.DataFrame, loaded_models: Dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Make predictions for a batch of samples in a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data_df (pd.DataFrame): DataFrame with samples to predict\n",
    "        loaded_models (Dict): Dictionary of loaded models\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with original data and predictions\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing batch predictions for {len(data_df)} samples...\")\n",
    "    \n",
    "    results = []\n",
    "    model_names = [name for name in loaded_models.keys() if name != 'scaler']\n",
    "    \n",
    "    for idx, row in data_df.iterrows():\n",
    "        row_dict = row.to_dict()\n",
    "        predictions = make_predictions_all_models(row_dict, loaded_models, use_scaler=True)\n",
    "        \n",
    "        # Combine original data with predictions\n",
    "        result_row = row_dict.copy()\n",
    "        result_row.update(predictions)\n",
    "        \n",
    "        # Calculate ensemble prediction\n",
    "        valid_predictions = [v for v in predictions.values() if v is not None]\n",
    "        if valid_predictions:\n",
    "            result_row['ensemble_prediction'] = np.mean(valid_predictions)\n",
    "            result_row['prediction_std'] = np.std(valid_predictions) if len(valid_predictions) > 1 else 0\n",
    "        else:\n",
    "            result_row['ensemble_prediction'] = None\n",
    "            result_row['prediction_std'] = None\n",
    "        \n",
    "        results.append(result_row)\n",
    "        \n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"Processed {idx + 1}/{len(data_df)} samples...\")\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(f\"Batch prediction completed for {len(results_df)} samples\")\n",
    "    \n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42aa444-b62b-4a61-b1eb-d5a5e747b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE IMPORTANCE AND ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def get_feature_importance(model_name: str, loaded_models: Dict) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Get feature importance for a given model if available.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Name of the model to analyze\n",
    "        loaded_models (Dict): Dictionary of loaded models\n",
    "        \n",
    "    Returns:\n",
    "        Optional[np.ndarray]: Feature importance values or None if not available\n",
    "    \"\"\"\n",
    "    if model_name not in loaded_models:\n",
    "        logging.error(f\"Model '{model_name}' not found in loaded models\")\n",
    "        return None\n",
    "    \n",
    "    model = loaded_models[model_name]['model']\n",
    "    \n",
    "    try:\n",
    "        # For PyCaret models, try to access the underlying estimator\n",
    "        if hasattr(model, 'named_steps'):\n",
    "            # Pipeline case\n",
    "            estimator = None\n",
    "            for step_name, step in model.named_steps.items():\n",
    "                if hasattr(step, 'feature_importances_') or hasattr(step, 'coef_'):\n",
    "                    estimator = step\n",
    "                    break\n",
    "        elif hasattr(model, '_final_estimator'):\n",
    "            estimator = model._final_estimator\n",
    "        else:\n",
    "            estimator = model\n",
    "        \n",
    "        # Check for feature importances\n",
    "        if hasattr(estimator, 'feature_importances_'):\n",
    "            importances = estimator.feature_importances_\n",
    "            logging.info(f\"Retrieved feature importance from '{model_name}' (feature_importances_)\")\n",
    "            return importances\n",
    "        \n",
    "        # For linear models, use coefficients\n",
    "        elif hasattr(estimator, 'coef_'):\n",
    "            importances = np.abs(estimator.coef_)\n",
    "            if importances.ndim > 1:\n",
    "                importances = importances.flatten()\n",
    "            logging.info(f\"Retrieved feature importance from '{model_name}' (coefficients)\")\n",
    "            return importances\n",
    "        \n",
    "        logging.warning(f\"Model '{model_name}' does not support feature importance\")\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error getting feature importance for '{model_name}': {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_feature_importance_all_models(loaded_models: Dict) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Get feature importance for all models that support it.\n",
    "    \n",
    "    Args:\n",
    "        loaded_models (Dict): Dictionary of loaded models\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, np.ndarray]: Dictionary with model names and feature importances\n",
    "    \"\"\"\n",
    "    importance_results = {}\n",
    "    model_names = [name for name in loaded_models.keys() if name != 'scaler']\n",
    "    \n",
    "    print(\"\\nAnalyzing feature importance for all models...\")\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        importance = get_feature_importance(model_name, loaded_models)\n",
    "        if importance is not None:\n",
    "            importance_results[model_name] = importance\n",
    "            print(f\"‚úì {model_name}: Feature importance extracted\")\n",
    "        else:\n",
    "            print(f\"‚úó {model_name}: No feature importance available\")\n",
    "    \n",
    "    return importance_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fdff01-a18a-4afe-a689-3ef374fbd51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# WHAT-IF ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_what_if(\n",
    "    base_features_dict: dict,\n",
    "    model_name: str,\n",
    "    loaded_models: Dict,\n",
    "    param_name: str,\n",
    "    param_values: List[float],\n",
    "    use_scaler: bool = True\n",
    ") -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Perform what-if analysis by varying one parameter and observing predictions.\n",
    "    \n",
    "    Args:\n",
    "        base_features_dict (dict): Base feature values as dictionary\n",
    "        model_name (str): Name of the model to use\n",
    "        loaded_models (Dict): Dictionary of loaded models\n",
    "        param_name (str): Name of the parameter to vary\n",
    "        param_values (List[float]): Values to use for the parameter\n",
    "        use_scaler (bool): Whether to apply scaling if available\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, List]: Dictionary with parameter values and predictions\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"param_values\": [],\n",
    "        \"predictions\": []\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nPerforming what-if analysis for '{param_name}' with model '{model_name}'...\")\n",
    "    \n",
    "    for value in param_values:\n",
    "        try:\n",
    "            # Create a copy of features and modify the specified parameter\n",
    "            modified_features = base_features_dict.copy()\n",
    "            modified_features[param_name] = value\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction = predict_with_single_model(\n",
    "                modified_features, model_name, loaded_models, use_scaler\n",
    "            )\n",
    "            \n",
    "            if prediction is not None:\n",
    "                results[\"param_values\"].append(value)\n",
    "                results[\"predictions\"].append(prediction)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in what-if analysis for value {value}: {str(e)}\")\n",
    "    \n",
    "    print(f\"What-if analysis completed: {len(results['predictions'])} data points\")\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3438a7e1-a83d-40a6-9199-8a15c8451399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def plot_predictions_comparison(predictions_dict: Dict[str, float]):\n",
    "    \"\"\"Plot comparison of predictions from different models.\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        # Filter out None values\n",
    "        valid_predictions = {k: v for k, v in predictions_dict.items() if v is not None}\n",
    "        \n",
    "        if not valid_predictions:\n",
    "            print(\"No valid predictions to plot\")\n",
    "            return\n",
    "        \n",
    "        models = list(valid_predictions.keys())\n",
    "        values = list(valid_predictions.values())\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(models, values, color='skyblue', alpha=0.7)\n",
    "        plt.title('Model Predictions Comparison')\n",
    "        plt.xlabel('Models')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, values):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                    f'{value:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"Matplotlib not available for plotting\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting predictions: {str(e)}\")\n",
    "\n",
    "def plot_feature_importance(importance_results: Dict[str, np.ndarray]):\n",
    "    \"\"\"Plot feature importance for all models.\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        if not importance_results:\n",
    "            print(\"No feature importance data to plot\")\n",
    "            return\n",
    "        \n",
    "        feature_names = get_expected_feature_names_from_csv()\n",
    "        \n",
    "        fig, axes = plt.subplots(len(importance_results), 1, \n",
    "                               figsize=(12, 4 * len(importance_results)))\n",
    "        \n",
    "        if len(importance_results) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for idx, (model_name, importance) in enumerate(importance_results.items()):\n",
    "            if len(importance) == len(feature_names):\n",
    "                axes[idx].bar(feature_names, importance, alpha=0.7)\n",
    "                axes[idx].set_title(f'Feature Importance - {model_name}')\n",
    "                axes[idx].set_xlabel('Features')\n",
    "                axes[idx].set_ylabel('Importance')\n",
    "                axes[idx].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"Matplotlib not available for plotting\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting feature importance: {str(e)}\")\n",
    "\n",
    "def plot_what_if_analysis(what_if_results: Dict[str, List], param_name: str):\n",
    "    \"\"\"Plot what-if analysis results.\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        if not what_if_results[\"param_values\"]:\n",
    "            print(\"No what-if analysis data to plot\")\n",
    "            return\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(what_if_results[\"param_values\"], what_if_results[\"predictions\"], \n",
    "                'o-', linewidth=2, markersize=8, color='darkblue')\n",
    "        plt.title(f'What-If Analysis: Impact of {param_name}')\n",
    "        plt.xlabel(param_name)\n",
    "        plt.ylabel('Predicted Value')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"Matplotlib not available for plotting\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting what-if analysis: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51df2c8-5b13-4f29-a5cc-206b51096c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MAIN EXECUTION PIPELINE\n",
    "# =============================================================================\n",
    "\n",
    "def run_enhanced_prediction_pipeline(\n",
    "    data_path=None, \n",
    "    sample_data=None, \n",
    "    use_scaler=True,\n",
    "    save_results=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete enhanced prediction pipeline with all features.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"STARTING ENHANCED PREDICTION PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Check and load models\n",
    "    model_status = check_required_models()\n",
    "    if not model_status[\"models_available\"]:\n",
    "        print(\"‚ùå No models found! Please train and save models first.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Step 2: Load all models\n",
    "    loaded_models = load_all_models()\n",
    "    if not loaded_models:\n",
    "        print(\"‚ùå Failed to load any models!\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Step 3: Prepare data\n",
    "    new_data = prepare_new_data(data_path, sample_data)\n",
    "    \n",
    "    # Step 4: Batch predictions\n",
    "    results_df = batch_predict_dataframe(new_data, loaded_models)\n",
    "    \n",
    "    # Step 5: Feature importance analysis\n",
    "    importance_results = analyze_feature_importance_all_models(loaded_models)\n",
    "    \n",
    "    # Step 6: Save results if requested\n",
    "    if save_results:\n",
    "        ensure_directories()\n",
    "        \n",
    "        # Save predictions\n",
    "        predictions_path = os.path.join(DATA_FOLDER, 'enhanced_predictions.csv')\n",
    "        results_df.to_csv(predictions_path, index=False)\n",
    "        print(f\"\\nüìÅ Predictions saved to: {predictions_path}\")\n",
    "        \n",
    "        # Save feature importance if available\n",
    "        if importance_results:\n",
    "            importance_path = os.path.join(DATA_FOLDER, 'feature_importance.csv')\n",
    "            feature_names = get_expected_feature_names_from_csv()\n",
    "            \n",
    "            importance_df_data = {}\n",
    "            for model_name, importance in importance_results.items():\n",
    "                if len(importance) == len(feature_names):\n",
    "                    importance_df_data[model_name] = importance\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Feature importance length mismatch for {model_name}\")\n",
    "            \n",
    "            if importance_df_data:\n",
    "                importance_df = pd.DataFrame(importance_df_data, index=feature_names)\n",
    "                importance_df.to_csv(importance_path)\n",
    "                print(f\"üìÅ Feature importance saved to: {importance_path}\")\n",
    "    \n",
    "    # Step 7: Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ENHANCED PREDICTION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    model_names = [name for name in loaded_models.keys() if name != 'scaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e33b97-6f61-424b-bba6-93d1fd547360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8bd828-3448-42e1-95a9-8394e8e07e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74445cc9-2d25-48a9-ab3d-676892cd0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENHANCED BATCH PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "def prepare_new_data(new_data_path=None, sample_data=None):\n",
    "    \"\"\"\n",
    "    Prepare new data for prediction with enhanced flexibility.\n",
    "    \n",
    "    Parameters:\n",
    "    - new_data_path: path to CSV file with new data\n",
    "    - sample_data: pandas DataFrame with new data\n",
    "    \n",
    "    Returns:\n",
    "    - prepared_data: DataFrame ready for prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    if new_data_path:\n",
    "        # Load new data from CSV\n",
    "        new_data = pd.read_csv(new_data_path)\n",
    "        print(f\"Loaded new data from {new_data_path}: {new_data.shape}\")\n",
    "    elif sample_data is not None:\n",
    "        new_data = sample_data.copy()\n",
    "        print(f\"Using provided sample data: {new_data.shape}\")\n",
    "    else:\n",
    "        # Create sample data for demonstration\n",
    "        print(\"Creating sample data for demonstration...\")\n",
    "        new_data = pd.DataFrame({\n",
    "            'project_prf_year_of_project': [2023, 2024, 2022, 2023],\n",
    "            'project_prf_functional_size': [150.5, 200.0, 89.3, 175.2],\n",
    "            'project_prf_used_methodology': ['Agile', 'Waterfall', 'Agile', 'Hybrid'],\n",
    "            'technology_prf_development_platform': ['Web', 'Desktop', 'Mobile', 'Web'],\n",
    "            'technology_prf_language_type': ['4GL', '3GL', '4GL', '3GL'],\n",
    "            'project_prf_development_type': ['New', 'Enhancement', 'New', 'Enhancement'],\n",
    "            'technology_prf_database_used': ['Yes', 'Yes', 'No', 'Yes'],\n",
    "            'project_prf_max_team_size': [8, 12, 5, 10]\n",
    "        })\n",
    "        print(f\"Created sample data: {new_data.shape}\")\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abd4b62-dbaa-4bae-b28b-e6f99e8d18a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict_dataframe(data_df: pd.DataFrame, loaded_models: Dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Make predictions for a batch of samples in a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data_df (pd.DataFrame): DataFrame with samples to predict\n",
    "        loaded_models (Dict): Dictionary of loaded models\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with original data and predictions\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing batch predictions for {len(data_df)} samples...\")\n",
    "    \n",
    "    results = []\n",
    "    model_names = [name for name in loaded_models.keys() if name != 'scaler']\n",
    "    \n",
    "    for idx, row in data_df.iterrows():\n",
    "        row_dict = row.to_dict()\n",
    "        predictions = make_predictions_all_models(row_dict, loaded_models, use_scaler=True)\n",
    "        \n",
    "        # Combine original data with predictions\n",
    "        result_row = row_dict.copy()\n",
    "        result_row.update(predictions)\n",
    "        \n",
    "        # Calculate ensemble prediction\n",
    "        valid_predictions = [v for v in predictions.values() if v is not None]\n",
    "        if valid_predictions:\n",
    "            result_row['ensemble_prediction'] = np.mean(valid_predictions)\n",
    "            result_row['prediction_std'] = np.std(valid_predictions) if len(valid_predictions) > 1 else 0\n",
    "        else:\n",
    "            result_row['ensemble_prediction'] = None\n",
    "            result_row['prediction_std'] = None\n",
    "        \n",
    "        results.append(result_row)\n",
    "        \n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"Processed {idx + 1}/{len(data_df)} samples...\")\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(f\"Batch prediction completed for {len(results_df)} samples\")\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f064091-97cd-45b4-a741-e5764a7f05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE IMPORTANCE AND ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def get_feature_importance(model_name: str, loaded_models: Dict) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Get feature importance for a given model if available.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Name of the model to analyze\n",
    "        loaded_models (Dict): Dictionary of loaded models\n",
    "        \n",
    "    Returns:\n",
    "        Optional[np.ndarray]: Feature importance values or None if not available\n",
    "    \"\"\"\n",
    "    if model_name not in loaded_models:\n",
    "        logging.error(f\"Model '{model_name}' not found in loaded models\")\n",
    "        return None\n",
    "    \n",
    "    model = loaded_models[model_name]['model']\n",
    "    \n",
    "    try:\n",
    "        # For PyCaret models, try to access the underlying estimator\n",
    "        if hasattr(model, 'named_steps'):\n",
    "            # Pipeline case\n",
    "            estimator = None\n",
    "            for step_name, step in model.named_steps.items():\n",
    "                if hasattr(step, 'feature_importances_') or hasattr(step, 'coef_'):\n",
    "                    estimator = step\n",
    "                    break\n",
    "        elif hasattr(model, '_final_estimator'):\n",
    "            estimator = model._final_estimator\n",
    "        else:\n",
    "            estimator = model\n",
    "        \n",
    "        # Check for feature importances\n",
    "        if hasattr(estimator, 'feature_importances_'):\n",
    "            importances = estimator.feature_importances_\n",
    "            logging.info(f\"Retrieved feature importance from '{model_name}' (feature_importances_)\")\n",
    "            return importances\n",
    "        \n",
    "        # For linear models, use coefficients\n",
    "        elif hasattr(estimator, 'coef_'):\n",
    "            importances = np.abs(estimator.coef_)\n",
    "            if importances.ndim > 1:\n",
    "                importances = importances.flatten()\n",
    "            logging.info(f\"Retrieved feature importance from '{model_name}' (coefficients)\")\n",
    "            return importances\n",
    "        \n",
    "        logging.warning(f\"Model '{model_name}' does not support feature importance\")\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error getting feature importance for '{model_name}': {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_feature_importance_all_models(loaded_models: Dict) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Get feature importance for all models that support it.\n",
    "    \n",
    "    Args:\n",
    "        loaded_models (Dict): Dictionary of loaded models\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, np.ndarray]: Dictionary with model names and feature importances\n",
    "    \"\"\"\n",
    "    importance_results = {}\n",
    "    model_names = [name for name in loaded_models.keys() if name != 'scaler']\n",
    "    \n",
    "    print(\"\\nAnalyzing feature importance for all models...\")\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        importance = get_feature_importance(model_name, loaded_models)\n",
    "        if importance is not None:\n",
    "            importance_results[model_name] = importance\n",
    "            print(f\"‚úì {model_name}: Feature importance extracted\")\n",
    "        else:\n",
    "            print(f\"‚úó {model_name}: No feature importance available\")\n",
    "    \n",
    "    return importance_results\n",
    "\n",
    "# =============================================================================\n",
    "# WHAT-IF ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_what_if(\n",
    "    base_features_dict: dict,\n",
    "    model_name: str,\n",
    "    loaded_models: Dict,\n",
    "    param_name: str,\n",
    "    param_values: List[float],\n",
    "    use_scaler: bool = True\n",
    ") -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Perform what-if analysis by varying one parameter and observing predictions.\n",
    "    \n",
    "    Args:\n",
    "        base_features_dict (dict): Base feature values as dictionary\n",
    "        model_name (str): Name of the model to use\n",
    "        loaded_models (Dict): Dictionary of loaded models\n",
    "        param_name (str): Name of the parameter to vary\n",
    "        param_values (List[float]): Values to use for the parameter\n",
    "        use_scaler (bool): Whether to apply scaling if available\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, List]: Dictionary with parameter values and predictions\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"param_values\": [],\n",
    "        \"predictions\": []\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nPerforming what-if analysis for '{param_name}' with model '{model_name}'...\")\n",
    "    \n",
    "    for value in param_values:\n",
    "        try:\n",
    "            # Create a copy of features and modify the specified parameter\n",
    "            modified_features = base_features_dict.copy()\n",
    "            modified_features[param_name] = value\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction = predict_with_single_model(\n",
    "                modified_features, model_name, loaded_models, use_scaler\n",
    "            )\n",
    "            \n",
    "            if prediction is not None:\n",
    "                results[\"param_values\"].append(value)\n",
    "                results[\"predictions\"].append(prediction)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in what-if analysis for value {value}: {str(e)}\")\n",
    "    \n",
    "    print(f\"What-if analysis completed: {len(results['predictions'])} data points\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c446af-360a-4a5b-aa4b-94f71583f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def plot_predictions_comparison(predictions_dict: Dict[str, float]):\n",
    "    \"\"\"Plot comparison of predictions from different models.\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        # Filter out None values\n",
    "        valid_predictions = {k: v for k, v in predictions_dict.items() if v is not None}\n",
    "        \n",
    "        if not valid_predictions:\n",
    "            print(\"No valid predictions to plot\")\n",
    "            return\n",
    "        \n",
    "        models = list(valid_predictions.keys())\n",
    "        values = list(valid_predictions.values())\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(models, values, color='skyblue', alpha=0.7)\n",
    "        plt.title('Model Predictions Comparison')\n",
    "        plt.xlabel('Models')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, values):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                    f'{value:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"Matplotlib not available for plotting\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting predictions: {str(e)}\")\n",
    "\n",
    "def plot_feature_importance(importance_results: Dict[str, np.ndarray]):\n",
    "    \"\"\"Plot feature importance for all models.\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        if not importance_results:\n",
    "            print(\"No feature importance data to plot\")\n",
    "            return\n",
    "        \n",
    "        feature_names = get_expected_feature_names_from_csv()\n",
    "        \n",
    "        fig, axes = plt.subplots(len(importance_results), 1, \n",
    "                               figsize=(12, 4 * len(importance_results)))\n",
    "        \n",
    "        if len(importance_results) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for idx, (model_name, importance) in enumerate(importance_results.items()):\n",
    "            if len(importance) == len(feature_names):\n",
    "                axes[idx].bar(feature_names, importance, alpha=0.7)\n",
    "                axes[idx].set_title(f'Feature Importance - {model_name}')\n",
    "                axes[idx].set_xlabel('Features')\n",
    "                axes[idx].set_ylabel('Importance')\n",
    "                axes[idx].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"Matplotlib not available for plotting\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting feature importance: {str(e)}\")\n",
    "\n",
    "def plot_what_if_analysis(what_if_results: Dict[str, List], param_name: str):\n",
    "    \"\"\"Plot what-if analysis results.\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        if not what_if_results[\"param_values\"]:\n",
    "            print(\"No what-if analysis data to plot\")\n",
    "            return\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(what_if_results[\"param_values\"], what_if_results[\"predictions\"], \n",
    "                'o-', linewidth=2, markersize=8, color='darkblue')\n",
    "        plt.title(f'What-If Analysis: Impact of {param_name}')\n",
    "        plt.xlabel(param_name)\n",
    "        plt.ylabel('Predicted Value')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"Matplotlib not available for plotting\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting what-if analysis: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfbb4ac8-ef4e-47fe-a7e5-b55567376bc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1119543484.py, line 591)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 591\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mif results is not\u001b[39m\n                     ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION PIPELINE\n",
    "# =============================================================================\n",
    "\n",
    "def run_enhanced_prediction_pipeline(\n",
    "    data_path=None, \n",
    "    sample_data=None, \n",
    "    use_scaler=True,\n",
    "    save_results=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete enhanced prediction pipeline with all features.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"STARTING ENHANCED PREDICTION PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Check and load models\n",
    "    model_status = check_required_models()\n",
    "    if not model_status[\"models_available\"]:\n",
    "        print(\"‚ùå No models found! Please train and save models first.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Step 2: Load all models\n",
    "    loaded_models = load_all_models()\n",
    "    if not loaded_models:\n",
    "        print(\"‚ùå Failed to load any models!\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Step 3: Prepare data\n",
    "    new_data = prepare_new_data(data_path, sample_data)\n",
    "    \n",
    "    # Step 4: Batch predictions\n",
    "    results_df = batch_predict_dataframe(new_data, loaded_models)\n",
    "    \n",
    "    # Step 5: Feature importance analysis\n",
    "    importance_results = analyze_feature_importance_all_models(loaded_models)\n",
    "    \n",
    "    # Step 6: Save results if requested\n",
    "    if save_results:\n",
    "        ensure_directories()\n",
    "        \n",
    "        # Save predictions\n",
    "        predictions_path = os.path.join(DATA_FOLDER, 'enhanced_predictions.csv')\n",
    "        results_df.to_csv(predictions_path, index=False)\n",
    "        print(f\"\\nüìÅ Predictions saved to: {predictions_path}\")\n",
    "        \n",
    "        # Save feature importance if available\n",
    "        if importance_results:\n",
    "            importance_path = os.path.join(DATA_FOLDER, 'feature_importance.csv')\n",
    "            feature_names = get_expected_feature_names_from_csv()\n",
    "            \n",
    "            importance_df_data = {}\n",
    "            for model_name, importance in importance_results.items():\n",
    "                if len(importance) == len(feature_names):\n",
    "                    importance_df_data[model_name] = importance\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Feature importance length mismatch for {model_name}\")\n",
    "            \n",
    "            if importance_df_data:\n",
    "                importance_df = pd.DataFrame(importance_df_data, index=feature_names)\n",
    "                importance_df.to_csv(importance_path)\n",
    "                print(f\"üìÅ Feature importance saved to: {importance_path}\")\n",
    "    \n",
    "    # Step 7: Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ENHANCED PREDICTION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    model_names = [name for name in loaded_models.keys() if name != 'standard_scaler']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
