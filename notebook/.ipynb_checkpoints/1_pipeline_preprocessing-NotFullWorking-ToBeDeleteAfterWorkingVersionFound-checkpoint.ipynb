{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f790fa4-3694-4fc7-b8d0-b3a480e05053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df43052d-4e2f-497a-9f7d-7884f05342dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nComplete Scikit-Learn Preprocessing Pipeline for ISBSG Data\\n===========================================================\\n\\nThis module provides a comprehensive preprocessing pipeline that handles:\\n1. Data loading and initial cleaning\\n2. Column name standardization\\n3. Missing value handling\\n4. Semicolon-separated value processing\\n5. One-hot encoding for categorical variables\\n6. Multi-label binarization for multi-value columns\\n7. Feature selection and filtering\\n8. Data validation and export\\n\\nBased on the preprocessing steps from the provided notebooks.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Complete Scikit-Learn Preprocessing Pipeline for ISBSG Data\n",
    "===========================================================\n",
    "\n",
    "This module provides a comprehensive preprocessing pipeline that handles:\n",
    "1. Data loading and initial cleaning\n",
    "2. Column name standardization\n",
    "3. Missing value handling\n",
    "4. Semicolon-separated value processing\n",
    "5. One-hot encoding for categorical variables\n",
    "6. Multi-label binarization for multi-value columns\n",
    "7. Feature selection and filtering\n",
    "8. Data validation and export\n",
    "\n",
    "Based on the preprocessing steps from the provided notebooks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e26088-9829-45c3-ad0e-f34c146cf120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb3dd6fc-4a21-4b17-b2cc-9e1d160bfab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp printing activated.\n",
      "Cell executed at: 2025-06-01 16:19:18.218819\n"
     ]
    }
   ],
   "source": [
    "# Sets up an automatic timestamp printout after each Jupyter cell execution \n",
    "# and configures the default visualization style.\n",
    "from IPython import get_ipython\n",
    "\n",
    "def setup_timestamp_callback():\n",
    "    \"\"\"Setup a timestamp callback for Jupyter cells without clearing existing callbacks.\"\"\"\n",
    "    ip = get_ipython()\n",
    "    if ip is not None:\n",
    "        # Define timestamp function\n",
    "        def print_timestamp(*args, **kwargs):\n",
    "            \"\"\"Print timestamp after cell execution.\"\"\"\n",
    "            print(f\"Cell executed at: {datetime.now()}\")\n",
    "        \n",
    "        # Check if our callback is already registered\n",
    "        callbacks = ip.events.callbacks.get('post_run_cell', [])\n",
    "        for cb in callbacks:\n",
    "            if hasattr(cb, '__name__') and cb.__name__ == 'print_timestamp':\n",
    "                # Already registered\n",
    "                return\n",
    "                \n",
    "        # Register new callback if not already present\n",
    "        ip.events.register('post_run_cell', print_timestamp)\n",
    "        print(\"Timestamp printing activated.\")\n",
    "    else:\n",
    "        print(\"Not running in IPython/Jupyter environment.\")\n",
    "\n",
    "# Setup timestamp callback\n",
    "setup_timestamp_callback()\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e705a6-19d4-488a-a6cc-751224ebcccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-06-01 16:19:18.231860\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "DATA_FOLDER = \"../data\"\n",
    "SAMPLE_FILE = \"ISBSG2016R1_1_agile_dataset_only.xlsx\"\n",
    "FULL_FILE = \"ISBSG2016R1_1_full_dataset.xlsx\"\n",
    "TARGET_COL = \"project_prf_normalised_work_effort\"  # be careful about case sensitive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c68d9a8a-470a-4f4f-8c3d-1a249d4400af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-06-01 16:19:18.238473\n"
     ]
    }
   ],
   "source": [
    "def convert_object_numeric_cols(df, threshold=0.8):\n",
    "    \"\"\"Convert object columns to numeric if most values can be coerced to numbers.\"\"\"\n",
    "    object_cols = df.select_dtypes(include='object').columns\n",
    "    for col in object_cols:\n",
    "        coerced = pd.to_numeric(df[col], errors='coerce')\n",
    "        if coerced.notnull().mean() > threshold:\n",
    "            df[col] = coerced\n",
    "            print(f\"Column '{col}' auto-converted to numeric (ratio={coerced.notnull().mean():.2f})\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "282c0614-af90-46dd-b1aa-408efab3ab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-06-01 16:19:18.417548\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def analyze_high_cardinality_multivalue(df, column, separator=';'):\n",
    "    \"\"\"\n",
    "    Analyze high-cardinality multi-value columns to choose best strategy\n",
    "    \"\"\"\n",
    "    print(f\"=== ANALYSIS FOR HIGH-CARDINALITY COLUMN: '{column}' ===\\n\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    non_null_data = df[column].dropna().astype(str)\n",
    "    split_values = non_null_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    # Get all unique values\n",
    "    all_values = []\n",
    "    for values_list in split_values:\n",
    "        all_values.extend(values_list)\n",
    "    \n",
    "    value_counts = Counter(all_values)\n",
    "    unique_values = list(value_counts.keys())\n",
    "    \n",
    "    print(f\"Total unique values: {len(unique_values)}\")\n",
    "    print(f\"Total value occurrences: {len(all_values)}\")\n",
    "    print(f\"Average values per row: {len(all_values) / len(split_values):.2f}\")\n",
    "    \n",
    "    # Show most common values\n",
    "    print(f\"\\nTop 15 most common values:\")\n",
    "    for value, count in value_counts.most_common(15):\n",
    "        percentage = (count / len(non_null_data)) * 100\n",
    "        print(f\"  '{value}': {count} times ({percentage:.1f}% of rows)\")\n",
    "    \n",
    "    # Show distribution of value frequencies\n",
    "    frequency_dist = Counter(value_counts.values())\n",
    "    print(f\"\\nFrequency distribution:\")\n",
    "    for freq, count in sorted(frequency_dist.items(), reverse=True)[:10]:\n",
    "        print(f\"  {count} values appear {freq} time(s)\")\n",
    "    \n",
    "    # Values per row distribution\n",
    "    values_per_row = split_values.apply(len)\n",
    "    print(f\"\\nValues per row:\")\n",
    "    print(f\"  Min: {values_per_row.min()}\")\n",
    "    print(f\"  Max: {values_per_row.max()}\")\n",
    "    print(f\"  Mean: {values_per_row.mean():.2f}\")\n",
    "    print(f\"  Median: {values_per_row.median():.2f}\")\n",
    "    \n",
    "    return value_counts, unique_values\n",
    "\n",
    "\n",
    "def handle_high_cardinality_multivalue(df, multi_value_columns, separator=';', strategy='top_k', **kwargs):\n",
    "    \"\"\"\n",
    "    Handle high-cardinality multi-value columns with various strategies\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    strategy options:\n",
    "    - 'top_k': Keep only top K most frequent values (k=kwargs['k'])\n",
    "    - 'frequency_threshold': Keep values that appear in at least X% of rows (threshold=kwargs['threshold'])\n",
    "    - 'tfidf': Use TF-IDF vectorization with dimensionality reduction (n_components=kwargs['n_components'])\n",
    "    - 'count_features': Simple counting features (count, unique_count, most_common)\n",
    "    - 'embedding': Create category embeddings (requires pre-trained embeddings)\n",
    "    \"\"\"\n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    new_columns_mapping = {}\n",
    "    \n",
    "    for col in multi_value_columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing high-cardinality column '{col}' with strategy '{strategy}'...\")\n",
    "        \n",
    "        # Clean and split values\n",
    "        split_values = df[col].fillna('').astype(str).apply(\n",
    "            lambda x: [val.strip() for val in x.split(separator) if val.strip()]\n",
    "        )\n",
    "        \n",
    "        # Get value counts\n",
    "        all_values = []\n",
    "        for values_list in split_values:\n",
    "            all_values.extend(values_list)\n",
    "        value_counts = Counter(all_values)\n",
    "        \n",
    "        if strategy == 'top_k':\n",
    "            k = kwargs.get('k', 20)  # Default to top 20\n",
    "            top_values = [val for val, count in value_counts.most_common(k)]\n",
    "            \n",
    "            new_col_names = []\n",
    "            for value in top_values:\n",
    "                new_col_name = f\"{col}_top_{value}\".replace(' ', '_').replace('-', '_')\n",
    "                df_processed[new_col_name] = split_values.apply(lambda x: 1 if value in x else 0)\n",
    "                new_col_names.append(new_col_name)\n",
    "            \n",
    "            # Add \"other\" category for remaining values\n",
    "            other_col_name = f\"{col}_other\"\n",
    "            df_processed[other_col_name] = split_values.apply(\n",
    "                lambda x: 1 if any(val not in top_values for val in x) else 0\n",
    "            )\n",
    "            new_col_names.append(other_col_name)\n",
    "            \n",
    "            new_columns_mapping[col] = new_col_names\n",
    "            print(f\"  Created {len(new_col_names)} columns (top {k} + other)\")\n",
    "            \n",
    "        elif strategy == 'frequency_threshold':\n",
    "            threshold = kwargs.get('threshold', 0.05)  # Default 5%\n",
    "            min_occurrences = int(len(df) * threshold)\n",
    "            \n",
    "            frequent_values = [val for val, count in value_counts.items() if count >= min_occurrences]\n",
    "            \n",
    "            new_col_names = []\n",
    "            for value in frequent_values:\n",
    "                new_col_name = f\"{col}_freq_{value}\".replace(' ', '_').replace('-', '_')\n",
    "                df_processed[new_col_name] = split_values.apply(lambda x: 1 if value in x else 0)\n",
    "                new_col_names.append(new_col_name)\n",
    "            \n",
    "            # Add rare category\n",
    "            rare_col_name = f\"{col}_rare\"\n",
    "            df_processed[rare_col_name] = split_values.apply(\n",
    "                lambda x: 1 if any(val not in frequent_values for val in x) else 0\n",
    "            )\n",
    "            new_col_names.append(rare_col_name)\n",
    "            \n",
    "            new_columns_mapping[col] = new_col_names\n",
    "            print(f\"  Created {len(new_col_names)} columns ({len(frequent_values)} frequent + rare)\")\n",
    "            \n",
    "        elif strategy == 'count_features':\n",
    "            # Create aggregate features instead of individual columns\n",
    "            new_col_names = []\n",
    "            \n",
    "            # Total count of values\n",
    "            count_col = f\"{col}_count\"\n",
    "            df_processed[count_col] = split_values.apply(len)\n",
    "            new_col_names.append(count_col)\n",
    "            \n",
    "            # Unique count (in case of duplicates)\n",
    "            unique_count_col = f\"{col}_unique_count\"\n",
    "            df_processed[unique_count_col] = split_values.apply(lambda x: len(set(x)))\n",
    "            new_col_names.append(unique_count_col)\n",
    "            \n",
    "            # Most common value in the dataset appears in this row\n",
    "            most_common_value = value_counts.most_common(1)[0][0] if value_counts else None\n",
    "            if most_common_value:\n",
    "                most_common_col = f\"{col}_has_most_common\"\n",
    "                df_processed[most_common_col] = split_values.apply(lambda x: 1 if most_common_value in x else 0)\n",
    "                new_col_names.append(most_common_col)\n",
    "            \n",
    "            # Average frequency of values in this row\n",
    "            avg_freq_col = f\"{col}_avg_frequency\"\n",
    "            df_processed[avg_freq_col] = split_values.apply(\n",
    "                lambda x: np.mean([value_counts[val] for val in x]) if x else 0\n",
    "            )\n",
    "            new_col_names.append(avg_freq_col)\n",
    "            \n",
    "            new_columns_mapping[col] = new_col_names\n",
    "            print(f\"  Created {len(new_col_names)} aggregate feature columns\")\n",
    "            \n",
    "        elif strategy == 'tfidf':\n",
    "            n_components = kwargs.get('n_components', 10)  # Default to 10 components\n",
    "            \n",
    "            # Convert to text format for TF-IDF\n",
    "            text_data = split_values.apply(lambda x: ' '.join(x))\n",
    "            \n",
    "            # Apply TF-IDF\n",
    "            tfidf = TfidfVectorizer(max_features=100, stop_words=None)\n",
    "            tfidf_matrix = tfidf.fit_transform(text_data)\n",
    "            \n",
    "            # Reduce dimensionality\n",
    "            pca = PCA(n_components=n_components)\n",
    "            tfidf_reduced = pca.fit_transform(tfidf_matrix.toarray())\n",
    "            \n",
    "            # Create new columns\n",
    "            new_col_names = []\n",
    "            for i in range(n_components):\n",
    "                new_col_name = f\"{col}_tfidf_comp_{i+1}\"\n",
    "                df_processed[new_col_name] = tfidf_reduced[:, i]\n",
    "                new_col_names.append(new_col_name)\n",
    "            \n",
    "            new_columns_mapping[col] = new_col_names\n",
    "            print(f\"  Created {len(new_col_names)} TF-IDF component columns\")\n",
    "            print(f\"  Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "            \n",
    "        elif strategy == 'hierarchical':\n",
    "            # Group similar values into higher-level categories\n",
    "            # This requires domain knowledge - example implementation\n",
    "            hierarchy = kwargs.get('hierarchy', {})  # Dictionary mapping values to categories\n",
    "            \n",
    "            if not hierarchy:\n",
    "                print(\"  Warning: No hierarchy provided for hierarchical strategy\")\n",
    "                continue\n",
    "            \n",
    "            # Create columns for each high-level category\n",
    "            categories = set(hierarchy.values())\n",
    "            new_col_names = []\n",
    "            \n",
    "            for category in categories:\n",
    "                category_values = [val for val, cat in hierarchy.items() if cat == category]\n",
    "                new_col_name = f\"{col}_category_{category}\".replace(' ', '_')\n",
    "                df_processed[new_col_name] = split_values.apply(\n",
    "                    lambda x: 1 if any(val in category_values for val in x) else 0\n",
    "                )\n",
    "                new_col_names.append(new_col_name)\n",
    "            \n",
    "            new_columns_mapping[col] = new_col_names\n",
    "            print(f\"  Created {len(new_col_names)} hierarchical category columns\")\n",
    "        \n",
    "        # Remove original column\n",
    "        df_processed = df_processed.drop(columns=[col])\n",
    "    \n",
    "    return df_processed, new_columns_mapping\n",
    "\n",
    "\n",
    "def recommend_strategy(df, column, separator=';'):\n",
    "    \"\"\"\n",
    "    Recommend the best strategy based on data characteristics\n",
    "    \"\"\"\n",
    "    value_counts, unique_values = analyze_high_cardinality_multivalue(df, column, separator)\n",
    "    \n",
    "    total_unique = len(unique_values)\n",
    "    total_rows = len(df[column].dropna())\n",
    "    \n",
    "    print(f\"\\n=== STRATEGY RECOMMENDATIONS FOR '{column}' ===\")\n",
    "    \n",
    "    if total_unique > 100:\n",
    "        print(\"ðŸ”´ VERY HIGH CARDINALITY (100+ unique values)\")\n",
    "        print(\"Recommended strategies:\")\n",
    "        print(\"1. 'count_features' - Create aggregate features (safest)\")\n",
    "        print(\"2. 'top_k' with k=15-25 - Keep only most important values\")\n",
    "        print(\"3. 'tfidf' with n_components=5-10 - If values have semantic meaning\")\n",
    "        \n",
    "    elif total_unique > 50:\n",
    "        print(\"ðŸŸ¡ HIGH CARDINALITY (50+ unique values)\")\n",
    "        print(\"Recommended strategies:\")\n",
    "        print(\"1. 'top_k' with k=20-30 - Keep most frequent values\")\n",
    "        print(\"2. 'frequency_threshold' with threshold=0.02-0.05\")\n",
    "        print(\"3. 'count_features' - If you want aggregate information\")\n",
    "        \n",
    "    else:\n",
    "        print(\"ðŸŸ¢ MODERATE CARDINALITY (<50 unique values)\")\n",
    "        print(\"Recommended strategies:\")\n",
    "        print(\"1. 'frequency_threshold' with threshold=0.01\")\n",
    "        print(\"2. 'top_k' with k=30-40\")\n",
    "        print(\"3. Binary encoding might be acceptable\")\n",
    "    \n",
    "    # Check frequency distribution\n",
    "    freq_values = list(value_counts.values())\n",
    "    if max(freq_values) / min(freq_values) > 100:\n",
    "        print(\"\\nâš ï¸  HIGHLY SKEWED DISTRIBUTION detected\")\n",
    "        print(\"   Consider 'frequency_threshold' or 'top_k' strategies\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3fcd3df-7d6b-431d-941f-e775698d7224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-06-01 16:19:18.464411\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def validate_multivalue_processing(df_original, df_processed, original_column, new_columns, separator=';', strategy='top_k'):\n",
    "    \"\"\"\n",
    "    Comprehensive validation of multi-value categorical processing\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_original : pd.DataFrame\n",
    "        Original dataset before processing\n",
    "    df_processed : pd.DataFrame  \n",
    "        Processed dataset after handling multi-value columns\n",
    "    original_column : str\n",
    "        Name of original multi-value column\n",
    "    new_columns : list\n",
    "        List of new column names created from the original column\n",
    "    separator : str\n",
    "        Separator used in original data\n",
    "    strategy : str\n",
    "        Strategy used for processing\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"=== VALIDATION REPORT FOR COLUMN '{original_column}' ===\\n\")\n",
    "    \n",
    "    # 1. BASIC CHECKS\n",
    "    print(\"1. BASIC INTEGRITY CHECKS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Check row count consistency\n",
    "    original_rows = len(df_original)\n",
    "    processed_rows = len(df_processed)\n",
    "    print(f\"âœ“ Row count: {original_rows} â†’ {processed_rows} {'âœ“ SAME' if original_rows == processed_rows else 'âš ï¸  DIFFERENT'}\")\n",
    "    \n",
    "    # Check if original column was removed\n",
    "    original_removed = original_column not in df_processed.columns\n",
    "    print(f\"âœ“ Original column removed: {'âœ“ YES' if original_removed else 'âš ï¸  NO'}\")\n",
    "    \n",
    "    # Check if new columns exist\n",
    "    new_cols_exist = all(col in df_processed.columns for col in new_columns)\n",
    "    print(f\"âœ“ New columns created: {'âœ“ YES' if new_cols_exist else 'âŒ NO'} ({len(new_columns)} columns)\")\n",
    "    \n",
    "    if not new_cols_exist:\n",
    "        missing_cols = [col for col in new_columns if col not in df_processed.columns]\n",
    "        print(f\"  Missing columns: {missing_cols}\")\n",
    "        return False\n",
    "    \n",
    "    # 2. DATA CONSISTENCY CHECKS\n",
    "    print(f\"\\n2. DATA CONSISTENCY CHECKS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Parse original data\n",
    "    original_data = df_original[original_column].fillna('').astype(str)\n",
    "    split_original = original_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    # Get all unique values from original\n",
    "    all_original_values = set()\n",
    "    for values_list in split_original:\n",
    "        all_original_values.update(values_list)\n",
    "    all_original_values = sorted([v for v in all_original_values if v and v != 'nan'])\n",
    "    \n",
    "    print(f\"Original unique values: {len(all_original_values)}\")\n",
    "    \n",
    "    if strategy == 'top_k':\n",
    "        # Validate top-k strategy\n",
    "        validate_top_k_strategy(df_original, df_processed, original_column, new_columns, separator)\n",
    "    elif strategy == 'count_features':\n",
    "        validate_count_features_strategy(df_original, df_processed, original_column, new_columns, separator)\n",
    "    elif strategy == 'frequency_threshold':\n",
    "        validate_frequency_threshold_strategy(df_original, df_processed, original_column, new_columns, separator)\n",
    "    \n",
    "    # 3. SAMPLE VALIDATION\n",
    "    print(f\"\\n3. SAMPLE-BY-SAMPLE VALIDATION\")\n",
    "    print(\"-\" * 40)\n",
    "    validate_sample_rows(df_original, df_processed, original_column, new_columns, separator, n_samples=5)\n",
    "    \n",
    "    # 4. STATISTICAL VALIDATION\n",
    "    print(f\"\\n4. STATISTICAL VALIDATION\")\n",
    "    print(\"-\" * 40)\n",
    "    validate_statistics(df_original, df_processed, original_column, new_columns, separator)\n",
    "    \n",
    "    # 5. INFORMATION LOSS ASSESSMENT\n",
    "    print(f\"\\n5. INFORMATION LOSS ASSESSMENT\")\n",
    "    print(\"-\" * 40)\n",
    "    assess_information_loss(df_original, df_processed, original_column, new_columns, separator)\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def validate_top_k_strategy(df_original, df_processed, original_column, new_columns, separator, k=None):\n",
    "    \"\"\"Validate top-k strategy specifically\"\"\"\n",
    "    \n",
    "    # Parse original data\n",
    "    original_data = df_original[original_column].fillna('').astype(str)\n",
    "    split_original = original_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    # Get value counts\n",
    "    all_values = []\n",
    "    for values_list in split_original:\n",
    "        all_values.extend(values_list)\n",
    "    value_counts = Counter(all_values)\n",
    "    \n",
    "    # Determine k if not provided\n",
    "    if k is None:\n",
    "        # Exclude \"other\" column to determine k\n",
    "        non_other_cols = [col for col in new_columns if not col.endswith('_other')]\n",
    "        k = len(non_other_cols)\n",
    "    \n",
    "    top_k_values = [val for val, count in value_counts.most_common(k)]\n",
    "    print(f\"Top {k} values: {top_k_values[:5]}{'...' if len(top_k_values) > 5 else ''}\")\n",
    "    \n",
    "    # Check each top-k column\n",
    "    for col in new_columns:\n",
    "        if col.endswith('_other'):\n",
    "            # Validate \"other\" column\n",
    "            validate_other_column(df_original, df_processed, original_column, col, top_k_values, separator)\n",
    "        else:\n",
    "            # Extract the value name from column name\n",
    "            value_name = col.replace(f\"{original_column}_top_\", \"\").replace(f\"{original_column}_\", \"\")\n",
    "            validate_binary_column(df_original, df_processed, original_column, col, value_name, separator)\n",
    "\n",
    "\n",
    "def validate_binary_column(df_original, df_processed, original_column, new_column, value_name, separator):\n",
    "    \"\"\"Validate a single binary column\"\"\"\n",
    "    \n",
    "    # Parse original data\n",
    "    original_data = df_original[original_column].fillna('').astype(str)\n",
    "    split_original = original_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    # Expected values: 1 if value_name in the list, 0 otherwise\n",
    "    expected = split_original.apply(lambda x: 1 if value_name in x else 0)\n",
    "    actual = df_processed[new_column]\n",
    "    \n",
    "    # Compare\n",
    "    matches = (expected == actual).sum()\n",
    "    total = len(expected)\n",
    "    match_rate = matches / total * 100\n",
    "    \n",
    "    print(f\"  '{new_column}': {matches}/{total} matches ({match_rate:.1f}%)\")\n",
    "    \n",
    "    if match_rate < 100:\n",
    "        mismatches = df_original.loc[expected != actual, original_column].head(3)\n",
    "        print(f\"    Sample mismatches: {list(mismatches)}\")\n",
    "\n",
    "\n",
    "def validate_other_column(df_original, df_processed, original_column, other_column, top_values, separator):\n",
    "    \"\"\"Validate the 'other' category column\"\"\"\n",
    "    \n",
    "    # Parse original data\n",
    "    original_data = df_original[original_column].fillna('').astype(str)\n",
    "    split_original = original_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    # Expected: 1 if any value is NOT in top_values, 0 if all values are in top_values\n",
    "    expected = split_original.apply(lambda x: 1 if any(val not in top_values for val in x) else 0)\n",
    "    actual = df_processed[other_column]\n",
    "    \n",
    "    matches = (expected == actual).sum()\n",
    "    total = len(expected)\n",
    "    match_rate = matches / total * 100\n",
    "    \n",
    "    print(f\"  '{other_column}': {matches}/{total} matches ({match_rate:.1f}%)\")\n",
    "\n",
    "\n",
    "def validate_count_features_strategy(df_original, df_processed, original_column, new_columns, separator):\n",
    "    \"\"\"Validate count features strategy\"\"\"\n",
    "    \n",
    "    # Parse original data\n",
    "    original_data = df_original[original_column].fillna('').astype(str)\n",
    "    split_original = original_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    for col in new_columns:\n",
    "        if col.endswith('_count'):\n",
    "            # Validate total count\n",
    "            expected = split_original.apply(len)\n",
    "            actual = df_processed[col]\n",
    "            matches = (expected == actual).sum()\n",
    "            print(f\"  '{col}': {matches}/{len(expected)} matches ({matches/len(expected)*100:.1f}%)\")\n",
    "            \n",
    "        elif col.endswith('_unique_count'):\n",
    "            # Validate unique count\n",
    "            expected = split_original.apply(lambda x: len(set(x)))\n",
    "            actual = df_processed[col]\n",
    "            matches = (expected == actual).sum()\n",
    "            print(f\"  '{col}': {matches}/{len(expected)} matches ({matches/len(expected)*100:.1f}%)\")\n",
    "\n",
    "\n",
    "def validate_sample_rows(df_original, df_processed, original_column, new_columns, separator, n_samples=5):\n",
    "    \"\"\"Manually validate a few sample rows\"\"\"\n",
    "    \n",
    "    print(f\"Validating {n_samples} random samples:\")\n",
    "    \n",
    "    # Get random sample indices\n",
    "    sample_indices = np.random.choice(len(df_original), min(n_samples, len(df_original)), replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices, 1):\n",
    "        original_value = df_original.iloc[idx][original_column]\n",
    "        if pd.isna(original_value):\n",
    "            original_values = []\n",
    "        else:\n",
    "            original_values = [v.strip() for v in str(original_value).split(separator) if v.strip()]\n",
    "        \n",
    "        print(f\"\\n  Sample {i} (row {idx}):\")\n",
    "        print(f\"    Original: '{original_value}'\")\n",
    "        print(f\"    Parsed: {original_values}\")\n",
    "        \n",
    "        # Check new columns for this row\n",
    "        for col in new_columns[:5]:  # Show first 5 columns only\n",
    "            processed_value = df_processed.iloc[idx][col]\n",
    "            print(f\"    {col}: {processed_value}\")\n",
    "\n",
    "\n",
    "def validate_statistics(df_original, df_processed, original_column, new_columns, separator):\n",
    "    \"\"\"Validate statistical properties\"\"\"\n",
    "    \n",
    "    # Parse original data\n",
    "    original_data = df_original[original_column].fillna('').astype(str)\n",
    "    split_original = original_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    # Original statistics\n",
    "    values_per_row = split_original.apply(len)\n",
    "    print(f\"Original values per row - Mean: {values_per_row.mean():.2f}, Std: {values_per_row.std():.2f}\")\n",
    "    \n",
    "    # New data statistics\n",
    "    if any('_count' in col for col in new_columns):\n",
    "        count_col = [col for col in new_columns if col.endswith('_count')][0]\n",
    "        new_counts = df_processed[count_col]\n",
    "        print(f\"Processed counts - Mean: {new_counts.mean():.2f}, Std: {new_counts.std():.2f}\")\n",
    "        \n",
    "        # They should match!\n",
    "        correlation = np.corrcoef(values_per_row, new_counts)[0, 1]\n",
    "        print(f\"Correlation between original and processed counts: {correlation:.4f}\")\n",
    "    \n",
    "    # Check for any impossible values\n",
    "    binary_cols = [col for col in new_columns if not col.endswith(('_count', '_frequency', '_avg_frequency'))]\n",
    "    for col in binary_cols:\n",
    "        unique_vals = df_processed[col].unique()\n",
    "        if not set(unique_vals).issubset({0, 1, np.nan}):\n",
    "            print(f\"âš ï¸  Warning: Non-binary values in '{col}': {unique_vals}\")\n",
    "\n",
    "\n",
    "def assess_information_loss(df_original, df_processed, original_column, new_columns, separator):\n",
    "    \"\"\"Assess how much information was lost in the transformation\"\"\"\n",
    "    \n",
    "    # Parse original data\n",
    "    original_data = df_original[original_column].fillna('').astype(str)\n",
    "    split_original = original_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    # Get all unique values\n",
    "    all_original_values = set()\n",
    "    for values_list in split_original:\n",
    "        all_original_values.update(values_list)\n",
    "    all_original_values = sorted([v for v in all_original_values if v and v != 'nan'])\n",
    "    \n",
    "    # Count how many unique values are captured by new columns\n",
    "    captured_values = set()\n",
    "    for col in new_columns:\n",
    "        if not col.endswith(('_other', '_count', '_unique_count', '_frequency', '_avg_frequency', '_rare')):\n",
    "            # Extract value name from column name\n",
    "            value_parts = col.replace(f\"{original_column}_\", \"\").replace(\"top_\", \"\").replace(\"freq_\", \"\")\n",
    "            captured_values.add(value_parts)\n",
    "    \n",
    "    capture_rate = len(captured_values) / len(all_original_values) * 100 if all_original_values else 0\n",
    "    print(f\"Value capture rate: {len(captured_values)}/{len(all_original_values)} ({capture_rate:.1f}%)\")\n",
    "    \n",
    "    if len(all_original_values) - len(captured_values) > 0:\n",
    "        lost_values = set(all_original_values) - captured_values\n",
    "        print(f\"Lost values (first 10): {list(lost_values)[:10]}\")\n",
    "    \n",
    "    # Estimate row-level information preservation\n",
    "    if any('_other' in col for col in new_columns):\n",
    "        other_col = [col for col in new_columns if col.endswith('_other')][0]\n",
    "        rows_with_other = df_processed[other_col].sum()\n",
    "        print(f\"Rows with 'other' values: {rows_with_other}/{len(df_processed)} ({rows_with_other/len(df_processed)*100:.1f}%)\")\n",
    "\n",
    "\n",
    "def quick_validation_summary(df_original, df_processed, column_mapping):\n",
    "    \"\"\"Quick validation summary for all processed columns\"\"\"\n",
    "    \n",
    "    print(\"=== QUICK VALIDATION SUMMARY ===\\n\")\n",
    "    \n",
    "    for original_col, new_cols in column_mapping.items():\n",
    "        print(f\"âœ“ {original_col} â†’ {len(new_cols)} new columns\")\n",
    "        \n",
    "        # Check for obvious issues\n",
    "        issues = []\n",
    "        \n",
    "        for col in new_cols:\n",
    "            if col not in df_processed.columns:\n",
    "                issues.append(f\"Missing column: {col}\")\n",
    "            else:\n",
    "                # Check for unexpected values in binary columns\n",
    "                if not col.endswith(('_count', '_frequency', '_avg_frequency')):\n",
    "                    unique_vals = set(df_processed[col].dropna().unique())\n",
    "                    if not unique_vals.issubset({0, 1, 0.0, 1.0}):\n",
    "                        issues.append(f\"Non-binary values in {col}: {unique_vals}\")\n",
    "        \n",
    "        if issues:\n",
    "            print(f\"  âš ï¸  Issues: {issues}\")\n",
    "        else:\n",
    "            print(f\"  âœ“ Looks good\")\n",
    "    \n",
    "    print(f\"\\nDataset size: {len(df_original)} â†’ {len(df_processed)} rows\")\n",
    "    print(f\"Column count: {len(df_original.columns)} â†’ {len(df_processed.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15658af4-b655-4429-a368-838ee7578410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-06-01 16:19:18.482188\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def add_missing_categories_from_full_dataset(sample_df, full_df, categorical_columns, samples_per_category=2):\n",
    "    \"\"\"\n",
    "    Add missing categorical values to sample dataset by sampling from full dataset\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    sample_df : pd.DataFrame\n",
    "        Your limited sample dataset\n",
    "    full_df : pd.DataFrame  \n",
    "        Your complete dataset\n",
    "    categorical_columns : list\n",
    "        List of categorical column names\n",
    "    samples_per_category : int\n",
    "        Number of examples to add for each missing category\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Enhanced dataset with missing categories included\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Analyzing missing categories...\")\n",
    "    \n",
    "    # Find missing categories in sample compared to full dataset\n",
    "    missing_categories = {}\n",
    "    category_stats = {}\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col not in sample_df.columns or col not in full_df.columns:\n",
    "            print(f\"Warning: Column '{col}' not found in one of the datasets\")\n",
    "            continue\n",
    "            \n",
    "        full_categories = set(full_df[col].dropna().unique())\n",
    "        sample_categories = set(sample_df[col].dropna().unique())\n",
    "        missing = full_categories - sample_categories\n",
    "        \n",
    "        if missing:\n",
    "            missing_categories[col] = missing\n",
    "            category_stats[col] = {\n",
    "                'total_in_full': len(full_categories),\n",
    "                'in_sample': len(sample_categories),\n",
    "                'missing_count': len(missing)\n",
    "            }\n",
    "            print(f\"Column '{col}': Missing {len(missing)} out of {len(full_categories)} categories\")\n",
    "            print(f\"  Missing categories: {list(missing)[:5]}{'...' if len(missing) > 5 else ''}\")\n",
    "        else:\n",
    "            print(f\"Column '{col}': All categories present in sample\")\n",
    "    \n",
    "    if not missing_categories:\n",
    "        print(\"No missing categories found! Your sample already contains all category values.\")\n",
    "        return sample_df.copy()\n",
    "    \n",
    "    # Collect additional rows for missing categories\n",
    "    additional_rows = []\n",
    "    rows_added_by_category = defaultdict(int)\n",
    "    \n",
    "    for col, missing_vals in missing_categories.items():\n",
    "        print(f\"\\nSampling for column '{col}'...\")\n",
    "        \n",
    "        for val in missing_vals:\n",
    "            # Find all rows in full dataset with this category value\n",
    "            matching_rows = full_df[full_df[col] == val]\n",
    "            \n",
    "            if len(matching_rows) == 0:\n",
    "                print(f\"  Warning: No rows found for {col}='{val}' in full dataset\")\n",
    "                continue\n",
    "            \n",
    "            # Sample requested number of rows (or all available if fewer)\n",
    "            n_samples = min(samples_per_category, len(matching_rows))\n",
    "            sampled_rows = matching_rows.sample(n=n_samples, random_state=42)\n",
    "            \n",
    "            additional_rows.append(sampled_rows)\n",
    "            rows_added_by_category[f\"{col}='{val}'\"] = n_samples\n",
    "            print(f\"  Added {n_samples} rows for '{val}' (out of {len(matching_rows)} available)\")\n",
    "    \n",
    "    # Combine all additional rows\n",
    "    if additional_rows:\n",
    "        df_additional = pd.concat(additional_rows, ignore_index=True)\n",
    "        \n",
    "        # Remove potential duplicates (in case same row satisfies multiple missing categories)\n",
    "        initial_additional_count = len(df_additional)\n",
    "        df_additional = df_additional.drop_duplicates()\n",
    "        final_additional_count = len(df_additional)\n",
    "        \n",
    "        if initial_additional_count != final_additional_count:\n",
    "            print(f\"\\nRemoved {initial_additional_count - final_additional_count} duplicate rows\")\n",
    "        \n",
    "        # Combine with original sample\n",
    "        df_enhanced = pd.concat([sample_df, df_additional], ignore_index=True)\n",
    "        \n",
    "        print(f\"\\n=== SUMMARY ===\")\n",
    "        print(f\"Original sample size: {len(sample_df)}\")\n",
    "        print(f\"Additional rows added: {len(df_additional)}\")\n",
    "        print(f\"Final dataset size: {len(df_enhanced)}\")\n",
    "        print(f\"Size increase: {len(df_additional)/len(sample_df)*100:.1f}%\")\n",
    "        \n",
    "        return df_enhanced\n",
    "    \n",
    "    else:\n",
    "        print(\"No additional rows could be sampled\")\n",
    "        return sample_df.copy()\n",
    "\n",
    "\n",
    "def verify_categories_coverage(df_before, df_after, categorical_columns):\n",
    "    \"\"\"\n",
    "    Verify that the enhanced dataset now covers all categories\n",
    "    \"\"\"\n",
    "    print(\"\\n=== CATEGORY COVERAGE VERIFICATION ===\")\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col not in df_before.columns:\n",
    "            continue\n",
    "            \n",
    "        before_cats = set(df_before[col].dropna().unique())\n",
    "        after_cats = set(df_after[col].dropna().unique())\n",
    "        new_cats = after_cats - before_cats\n",
    "        \n",
    "        print(f\"\\nColumn '{col}':\")\n",
    "        print(f\"  Before: {len(before_cats)} categories\")\n",
    "        print(f\"  After:  {len(after_cats)} categories\")\n",
    "        if new_cats:\n",
    "            print(f\"  New categories added: {list(new_cats)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b174ad57-80fd-4e9a-9871-142c98bb371f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-06-01 16:19:18.550924\n"
     ]
    }
   ],
   "source": [
    "# === 1. DataLoader: Load data and check target column ===\n",
    "\n",
    "class DataLoader(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Load and perform initial data validation whether the target col exists:\n",
    "        - Handles both .xlsx and .csv.\n",
    "        - Stores the original shape of the data.\n",
    "        - Raises an error if the target column is missing.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path, target_col='project_prf_normalised_work_effort'):\n",
    "        self.file_path = file_path\n",
    "        self.target_col = target_col  # This should be the standardized form\n",
    "        self.original_shape = None\n",
    "        self.original_target_col = None  # Store what we actually found\n",
    "        \n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _standardize_column_name(self, col_name):\n",
    "        \"\"\"Convert column name to standardized format\"\"\"\n",
    "        return col_name.strip().lower().replace(' ', '_')\n",
    "    \n",
    "    def _find_target_column(self, df_columns):\n",
    "        \"\"\"\n",
    "        Smart target column finder - handles various formats\n",
    "        Returns the actual column name from the dataframe\n",
    "        \"\"\"\n",
    "        target_standardized = self.target_col.lower().replace(' ', '_')\n",
    "        \n",
    "        # Try exact match first\n",
    "        if self.target_col in df_columns:\n",
    "            return self.target_col\n",
    "            \n",
    "        # Try standardized versions of all columns\n",
    "        for col in df_columns:\n",
    "            col_standardized = self._standardize_column_name(col)\n",
    "            if col_standardized == target_standardized:\n",
    "                return col\n",
    "                \n",
    "        # If still not found, look for partial matches (for debugging)\n",
    "        similar_cols = []\n",
    "        target_words = set(target_standardized.split('_'))\n",
    "        for col in df_columns:\n",
    "            col_words = set(self._standardize_column_name(col).split('_'))\n",
    "            if len(target_words.intersection(col_words)) >= 2:  # At least 2 words match\n",
    "                similar_cols.append(col)\n",
    "                \n",
    "        return None, similar_cols\n",
    "    \n",
    "    def transform(self, X=None):\n",
    "        \"\"\"Load data from file with smart column handling\"\"\"\n",
    "\n",
    "        print(f\"Loading data from: {self.file_path}\")\n",
    "        \n",
    "        # Determine file type and load accordingly; support for Excel or CSV\n",
    "        if self.file_path.endswith('.xlsx'):\n",
    "            df = pd.read_excel(self.file_path)\n",
    "        elif self.file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(self.file_path)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Use .xlsx or .csv\")\n",
    "        \n",
    "        self.original_shape = df.shape\n",
    "        print(f\"Loaded data with shape: {df.shape}\")\n",
    "\n",
    "        # Standardize ALL object/categorical columns: lowercase and strip\n",
    "        for col in df.select_dtypes(include='object').columns:\n",
    "            df[col] = df[col].str.lower().str.strip()\n",
    "\n",
    "        # Convert object columns to numeric if most values can be coerced to numbers.\n",
    "        df = convert_object_numeric_cols(df)\n",
    "        \n",
    "\n",
    "        # Smart target column finding\n",
    "        result = self._find_target_column(df.columns)\n",
    "        \n",
    "        if isinstance(result, tuple):  # Not found, got similar columns\n",
    "            actual_col, similar_cols = result\n",
    "            error_msg = f\"Target column '{self.target_col}' not found in data.\"\n",
    "            if similar_cols:\n",
    "                error_msg += f\" Similar columns found: {similar_cols}\"\n",
    "            else:\n",
    "                error_msg += f\" Available columns: {list(df.columns)}\"\n",
    "            raise ValueError(error_msg)\n",
    "        else:\n",
    "            actual_col = result\n",
    "            \n",
    "        # Store the original column name we found\n",
    "        self.original_target_col = actual_col\n",
    "        \n",
    "        if actual_col != self.target_col:\n",
    "            print(f\"Target column found: '{actual_col}' -> will be standardized to '{self.target_col}'\")\n",
    "            \n",
    "        return df\n",
    "\n",
    "# === 2. ColumnNameStandardizer: Clean and standardize column names ===\n",
    "class ColumnNameStandardizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Standardize column names for consistency (lowercase, underscores, removes odd chars):\n",
    "        - Strips spaces, lowercases, replaces & with _&_, removes special chars.\n",
    "        - Useful for later steps and compatibility with modeling libraries.)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_col=None, original_target_col=None):\n",
    "        self.column_mapping = {}\n",
    "        self.target_col = target_col\n",
    "        self.original_target_col = original_target_col\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _standardize_columns(self, columns):\n",
    "        \"\"\"Standardize column names\"\"\"\n",
    "        return [col.strip().lower().replace(' ', '_') for col in columns]\n",
    "    \n",
    "    def _clean_column_names(self, columns):\n",
    "        \"\"\"Clean column names for compatibility\"\"\"\n",
    "        cleaned_cols = []\n",
    "        for col in columns:\n",
    "            # Replace ampersands with _&_ to match expected transformations\n",
    "            col_clean = col.replace(' & ', '_&_')\n",
    "            # Remove special characters except underscores and ampersands\n",
    "            col_clean = re.sub(r'[^\\w\\s&]', '', col_clean)\n",
    "            # Replace spaces with underscores\n",
    "            col_clean = col_clean.replace(' ', '_')\n",
    "            cleaned_cols.append(col_clean)\n",
    "        return cleaned_cols\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Apply column name standardization\"\"\"\n",
    "        df = X.copy()\n",
    "        \n",
    "        # Store original column names\n",
    "        original_columns = df.columns.tolist()\n",
    "        \n",
    "        # Apply standardization\n",
    "        standardized_cols = self._standardize_columns(original_columns)\n",
    "        cleaned_cols = self._clean_column_names(standardized_cols)\n",
    "\n",
    "        # Special handling for target column\n",
    "        if self.original_target_col and self.target_col:\n",
    "            target_index = None\n",
    "            try:\n",
    "                target_index = original_columns.index(self.original_target_col)\n",
    "                cleaned_cols[target_index] = self.target_col\n",
    "                print(f\"Target column '{self.original_target_col}' -> '{self.target_col}'\")\n",
    "            except ValueError:\n",
    "                pass  # Original target col not found, proceed normally\n",
    "        \n",
    "        \n",
    "        # Create mapping\n",
    "        self.column_mapping = dict(zip(original_columns, cleaned_cols))\n",
    "        \n",
    "        # Apply new column names\n",
    "        df.columns = cleaned_cols\n",
    "        \n",
    "        # Report changes\n",
    "        changed_cols = sum(1 for orig, new in self.column_mapping.items() if orig != new)\n",
    "        print(f\"Standardized {changed_cols} column names\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "# === 3. MissingValueAnalyzer: Analyze and handle missing values ===\n",
    "class MissingValueAnalyzer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Analyze and handle missing values\n",
    "        - Reports number of columns with >50% and >70% missing.\n",
    "        - Drops columns with a high proportion of missing data, except those you want to keep.\n",
    "        - Fills remaining missing values:\n",
    "            - Categorical: Fills with \"Missing\".\n",
    "            - Numeric: Fills with column median.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, high_missing_threshold=0.7, cols_to_keep=None):\n",
    "        self.high_missing_threshold = high_missing_threshold\n",
    "        self.cols_to_keep = cols_to_keep or []\n",
    "        self.high_missing_cols = []\n",
    "        self.missing_stats = {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Analyze and handle missing values\"\"\"\n",
    "        df = X.copy()\n",
    "        \n",
    "        # Calculate missing percentages\n",
    "        missing_pct = df.isnull().mean()\n",
    "        self.missing_stats = missing_pct.sort_values(ascending=False)\n",
    "        \n",
    "        print(f\"\\nMissing value analysis:\")\n",
    "        print(f\"Columns with >50% missing: {sum(missing_pct > 0.5)}\")\n",
    "        print(f\"Columns with >70% missing: {sum(missing_pct > self.high_missing_threshold)}\")\n",
    "        \n",
    "        # Identify high missing columns\n",
    "        self.high_missing_cols = missing_pct[missing_pct > self.high_missing_threshold].index.tolist()\n",
    "        \n",
    "        # Filter out columns we want to keep\n",
    "        final_high_missing_cols = [col for col in self.high_missing_cols if col not in self.cols_to_keep]\n",
    "        \n",
    "        print(f\"Dropping {len(final_high_missing_cols)} columns with >{self.high_missing_threshold*100}% missing values\")\n",
    "        \n",
    "        # Drop high missing columns\n",
    "        df_clean = df.drop(columns=final_high_missing_cols)\n",
    "        \n",
    "        # Fill remaining missing values in categorical columns\n",
    "        cat_cols = df_clean.select_dtypes(include=['object', 'category']).columns\n",
    "        for col in cat_cols:\n",
    "            df_clean[col] = df_clean[col].fillna('Missing')\n",
    "        \n",
    "        # Fill remaining missing values in numerical columns with median\n",
    "        num_cols = df_clean.select_dtypes(include=['number']).columns\n",
    "        for col in num_cols:\n",
    "            if df_clean[col].isnull().sum() > 0:\n",
    "                median_val = df_clean[col].median()\n",
    "                df_clean[col] = df_clean[col].fillna(median_val)\n",
    "                print(f\"Filled {col} missing values with median: {median_val}\")\n",
    "        \n",
    "        print(f\"Data shape after missing value handling: {df_clean.shape}\")\n",
    "        return df_clean\n",
    "\n",
    "# === 4. SemicolonProcessor: Process multi-value columns (semicolon-separated) ===\n",
    "class SemicolonProcessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Process semicolon-separated values in columns (e.g., â€œPython; Java; SQLâ€)\n",
    "        - Identifies columns with semicolons.\n",
    "        - Cleans: lowercases, strips, deduplicates, sorts, optionally standardizes values (e.g., \"stand alone\" â†’ \"stand-alone\").\n",
    "        - Useful for multi-value categorical features.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, standardization_mapping=None):\n",
    "        self.semicolon_cols = []\n",
    "        self.standardization_mapping = standardization_mapping or {\n",
    "            \"scrum\": \"agile development\",\n",
    "            \"file &/or print server\": \"file/print server\",\n",
    "        }\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _clean_and_sort_semicolon(self, val, apply_standardization=False, mapping=None):\n",
    "        \"\"\"Clean, deduplicate, sort, and standardize semicolon-separated values\"\"\"\n",
    "        if pd.isnull(val) or val == '':\n",
    "            return val\n",
    "        \n",
    "        parts = [x.strip().lower() for x in str(val).split(';') if x.strip()]\n",
    "        \n",
    "        if apply_standardization and mapping is not None:\n",
    "            parts = [mapping.get(part, part) for part in parts]\n",
    "        \n",
    "        unique_cleaned = sorted(set(parts))\n",
    "        return '; '.join(unique_cleaned)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Process semicolon-separated columns\"\"\"\n",
    "        df = X.copy()\n",
    "        \n",
    "        # Identify columns with semicolons\n",
    "        self.semicolon_cols = [\n",
    "            col for col in df.columns\n",
    "            if df[col].dropna().astype(str).str.contains(';').any()\n",
    "        ]\n",
    "        \n",
    "        print(f\"Found {len(self.semicolon_cols)} columns with semicolons: {self.semicolon_cols}\")\n",
    "        \n",
    "        # Process each semicolon column\n",
    "        for col in self.semicolon_cols:\n",
    "            # Apply mapping for specific columns\n",
    "            apply_mapping = col in ['process_pmf_development_methodologies', 'tech_tf_server_roles']\n",
    "            mapping = self.standardization_mapping if apply_mapping else None\n",
    "            \n",
    "            # Clean the column\n",
    "            df[col] = df[col].apply(\n",
    "                lambda x: self._clean_and_sort_semicolon(x, apply_standardization=apply_mapping, mapping=mapping)\n",
    "            )\n",
    "        \n",
    "        return df\n",
    "\n",
    "# === 5. MultiValueEncoder: Encode semicolon columns using MultiLabelBinarizer ===\n",
    "class MultiValueEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Handle multi-value columns using MultiLabelBinarizer\n",
    "        - Only processes columns with a manageable number of unique values (max_cardinality).\n",
    "        - Each semicolon column becomes several binary columns (e.g., \"lang__python\", \"lang__java\", ...).     \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_cardinality=10):\n",
    "        # Ensure max_cardinality is always an integer\n",
    "        self.max_cardinality = int(max_cardinality) if max_cardinality is not None else 10\n",
    "        self.multi_value_cols = []\n",
    "        self.mlb_transformers = {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Encode multi-value columns\"\"\"\n",
    "        df = X.copy()\n",
    "        \n",
    "        # Identify semicolon columns (multi-value)\n",
    "        semicolon_cols = [\n",
    "            col for col in df.columns\n",
    "            if df[col].dropna().astype(str).str.contains(';').any()\n",
    "        ]\n",
    "        \n",
    "        # Filter for low cardinality multi-value columns\n",
    "        self.multi_value_cols = []\n",
    "        for col in semicolon_cols:\n",
    "            # Get unique values across all entries\n",
    "            all_values = set()\n",
    "            for val in df[col].dropna().astype(str):\n",
    "                values = [v.strip() for v in val.split(';') if v.strip()]\n",
    "                all_values.update(values)\n",
    "            \n",
    "            # Check cardinality (max_cardinality is already an integer from __init__)\n",
    "            if len(all_values) <= self.max_cardinality:\n",
    "                self.multi_value_cols.append(col)\n",
    "        \n",
    "        print(f\"Encoding {len(self.multi_value_cols)} multi-value columns: {self.multi_value_cols}\")\n",
    "        \n",
    "        # Process each multi-value column\n",
    "        for col in self.multi_value_cols:\n",
    "            # Prepare data for MultiLabelBinarizer\n",
    "            values = df[col].dropna().astype(str).apply(\n",
    "                lambda x: [item.strip() for item in x.split(';') if item.strip()]\n",
    "            )\n",
    "            \n",
    "            # Handle empty values - fill with empty list for MultiLabelBinarizer\n",
    "            if len(values) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Fit and transform\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            \n",
    "            # Convert to list of lists, handling NaN/empty cases\n",
    "            values_list = []\n",
    "            for idx in df.index:\n",
    "                if idx in values.index and values[idx]:\n",
    "                    values_list.append(values[idx])\n",
    "                else:\n",
    "                    values_list.append([])  # Empty list for missing values\n",
    "            \n",
    "            onehot = pd.DataFrame(\n",
    "                mlb.fit_transform(values_list),\n",
    "                columns=[f\"{col}__{cat}\" for cat in mlb.classes_],\n",
    "                index=df.index\n",
    "            )\n",
    "            \n",
    "            # Store transformer for later use\n",
    "            self.mlb_transformers[col] = mlb\n",
    "\n",
    "            # Check for duplicate columns BEFORE join\n",
    "            overlap = df.columns.intersection(onehot.columns)\n",
    "            if not overlap.empty:\n",
    "                print(f\"Duplicate columns found and will be dropped from onehot: {list(overlap)}\")\n",
    "                onehot = onehot.drop(columns=overlap, errors='ignore')\n",
    "\n",
    "         \n",
    "            # Join with main dataframe\n",
    "            df = df.join(onehot, how='left')\n",
    "            \n",
    "            print(f\"Encoded {col} into {len(mlb.classes_)} binary columns\")\n",
    "        \n",
    "        # Remove original multi-value columns\n",
    "        df = df.drop(columns=self.multi_value_cols)\n",
    "        \n",
    "        return df\n",
    "\n",
    "# === 6. CategoricalEncoder: One-hot encode regular categorical columns ===\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Handle single-value categorical columns\n",
    "        - Ignores semicolon columns.\n",
    "        - Only encodes columns with a number of categories â‰¤ max_cardinality (to avoid high-dimensional explosion).\n",
    "        - Can drop the first category for each variable to avoid multicollinearity.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_cardinality=10, drop_first=True):\n",
    "        self.max_cardinality = max_cardinality\n",
    "        self.drop_first = drop_first\n",
    "        self.categorical_cols = []\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Encode categorical columns\"\"\"\n",
    "        df = X.copy()\n",
    "        \n",
    "        # Identify categorical columns\n",
    "        cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        \n",
    "        # Identify semicolon columns to exclude\n",
    "        semicolon_cols = [\n",
    "            col for col in df.columns\n",
    "            if df[col].dropna().astype(str).str.contains(';').any()\n",
    "        ]\n",
    "        \n",
    "        # Filter for low cardinality single-value categorical columns\n",
    "        self.categorical_cols = [\n",
    "            col for col in cat_cols \n",
    "            if col not in semicolon_cols and df[col].nunique() <= self.max_cardinality\n",
    "        ]\n",
    "        \n",
    "        print(f\"/nOne-hot encoding {len(self.categorical_cols)} categorical columns: {self.categorical_cols}\")\n",
    "\n",
    "        # Print unique values before encoding\n",
    "        if self.categorical_cols:\n",
    "            print(\"\\nUnique values for each categorical column before one-hot encoding:\")\n",
    "            for col in self.categorical_cols:\n",
    "                print(f\"  - {col}: {sorted(df[col].dropna().unique())}\")\n",
    "        \n",
    "        # Apply one-hot encoding\n",
    "        if self.categorical_cols:\n",
    "            df = pd.get_dummies(df, columns=self.categorical_cols, drop_first=self.drop_first)\n",
    "        \n",
    "        return df\n",
    "\n",
    "# === 7. ColumnNameFixer: Final column name cleanup for PyCaret etc ===\n",
    "class ColumnNameFixer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Fix column names for PyCaret compatibility (removes illegal characters, replaces spaces/ampersands, handles duplicates):\n",
    "        - No duplicate column names after encoding.\n",
    "        - Only alphanumeric and underscores. \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.column_transformations = {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Fix problematic column names\"\"\"\n",
    "        df = X.copy()\n",
    "        original_cols = df.columns.tolist()\n",
    "        fixed_columns = []\n",
    "        seen_columns = set()\n",
    "        \n",
    "        for col in original_cols:\n",
    "            # Replace spaces with underscores\n",
    "            fixed_col = col.replace(' ', '_')\n",
    "            # Replace ampersands\n",
    "            fixed_col = fixed_col.replace('&', 'and')\n",
    "            # Remove other problematic characters\n",
    "            fixed_col = ''.join(c if c.isalnum() or c == '_' else '_' for c in fixed_col)\n",
    "            # Remove multiple consecutive underscores\n",
    "            fixed_col = re.sub('_+', '_', fixed_col)\n",
    "            # Remove leading/trailing underscores\n",
    "            fixed_col = fixed_col.strip('_')\n",
    "            \n",
    "            # Handle duplicates\n",
    "            base_col = fixed_col\n",
    "            suffix = 1\n",
    "            while fixed_col in seen_columns:\n",
    "                fixed_col = f\"{base_col}_{suffix}\"\n",
    "                suffix += 1\n",
    "            \n",
    "            seen_columns.add(fixed_col)\n",
    "            fixed_columns.append(fixed_col)\n",
    "        \n",
    "        # Store transformations\n",
    "        self.column_transformations = dict(zip(original_cols, fixed_columns))\n",
    "        \n",
    "        # Apply new column names\n",
    "        df.columns = fixed_columns\n",
    "        \n",
    "        # Check for duplicates\n",
    "        dup_check = [item for item, count in pd.Series(fixed_columns).value_counts().items() if count > 1]\n",
    "        if dup_check:\n",
    "            print(f\"WARNING: Found {len(dup_check)} duplicate column names: {dup_check}\")\n",
    "        else:\n",
    "            print(\"No duplicate column names after fixing\")\n",
    "        \n",
    "        n_changed = sum(1 for old, new in self.column_transformations.items() if old != new)\n",
    "        print(f\"Fixed {n_changed} column names for PyCaret compatibility\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "# === 8. DataValidator: Final summary and checks ===\n",
    "class DataValidator(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Validate final dataset\n",
    "        - Shape, missing values, infinities.\n",
    "        - Data types (numeric, categorical).\n",
    "        - Stats on the target column (mean, std, min, max, missing).\n",
    "        - Report issues if any.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_col):\n",
    "        self.target_col = target_col\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Validate the processed dataset\"\"\"\n",
    "        df = X.copy()\n",
    "        \n",
    "        print(f\"\\n=== Final Data Validation ===\")\n",
    "        print(f\"Final shape: {df.shape}\")\n",
    "        print(f\"Target column: {self.target_col}\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_count = df.isnull().sum().sum()\n",
    "        print(f\"Total missing values: {missing_count}\")\n",
    "        \n",
    "        # Check for infinite values\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        inf_count = np.isinf(df[numeric_cols].values).sum()\n",
    "        print(f\"Total infinite values: {inf_count}\")\n",
    "        \n",
    "        # Data types summary\n",
    "        print(f\"\\nData types:\")\n",
    "        print(f\"  Numeric columns: {len(df.select_dtypes(include=[np.number]).columns)}\")\n",
    "        print(f\"  Categorical columns: {len(df.select_dtypes(include=['object', 'category']).columns)}\")\n",
    "        \n",
    "        # Target variable summary\n",
    "        if self.target_col in df.columns:\n",
    "            target_stats = df[self.target_col].describe()\n",
    "            print(f\"\\nTarget variable '{self.target_col}' statistics:\")\n",
    "            print(f\"  Mean: {target_stats['mean']:.2f}\")\n",
    "            print(f\"  Std: {target_stats['std']:.2f}\")\n",
    "            print(f\"  Min: {target_stats['min']:.2f}\")\n",
    "            print(f\"  Max: {target_stats['max']:.2f}\")\n",
    "            print(f\"  Missing: {df[self.target_col].isnull().sum()}\")\n",
    "        else:\n",
    "            print(f\"WARNING: Target column '{self.target_col}' not found!\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "# === Pipeline creation function: returns the Scikit-learn pipeline ===\n",
    "def create_isbsg_preprocessing_pipeline(\n",
    "    target_col='project_prf_normalised_work_effort',\n",
    "    original_target_col=None,\n",
    "    high_missing_threshold=0.7,\n",
    "    cols_to_keep=None,\n",
    "    max_categorical_cardinality=10,\n",
    "    standardization_mapping=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create complete preprocessing pipeline with smart target column handling\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    target_col : str\n",
    "        Name of target column\n",
    "    original_target_col : str\n",
    "        Original target column name found in data\n",
    "    high_missing_threshold : float\n",
    "        Threshold for dropping columns with high missing values\n",
    "    cols_to_keep : list\n",
    "        Columns to keep even if they have high missing values\n",
    "    max_categorical_cardinality : int\n",
    "        Maximum number of unique values for categorical encoding\n",
    "    standardization_mapping : dict\n",
    "        Custom mapping for standardizing semicolon-separated values\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    sklearn.pipeline.Pipeline\n",
    "        Complete preprocessing pipeline\n",
    "    \"\"\"\n",
    "    \n",
    "    if cols_to_keep is None:\n",
    "        cols_to_keep = [\n",
    "            'project_prf_case_tool_used', \n",
    "            'process_pmf_prototyping_used',\n",
    "            'tech_tf_client_roles', \n",
    "            'tech_tf_type_of_server', \n",
    "            'tech_tf_clientserver_description'\n",
    "        ]\n",
    "    \n",
    "    # Ensure max_categorical_cardinality is an integer\n",
    "    if not isinstance(max_categorical_cardinality, int):\n",
    "        max_categorical_cardinality = 10\n",
    "        print(f\"Warning: max_categorical_cardinality was not an integer, defaulting to {max_categorical_cardinality}\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('column_standardizer', ColumnNameStandardizer(target_col, original_target_col)),\n",
    "        ('missing_handler', MissingValueAnalyzer(\n",
    "            high_missing_threshold=high_missing_threshold,\n",
    "            cols_to_keep=cols_to_keep\n",
    "        )),\n",
    "        ('semicolon_processor', SemicolonProcessor(standardization_mapping=standardization_mapping)),\n",
    "        ('multi_value_encoder', MultiValueEncoder(max_cardinality=max_categorical_cardinality)),\n",
    "        ('categorical_encoder', CategoricalEncoder(max_cardinality=max_categorical_cardinality)),\n",
    "        ('column_fixer', ColumnNameFixer()),\n",
    "        ('validator', DataValidator(target_col))\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# === Full workflow function: orchestrates loading, pipeline, and saving ===\n",
    "def preprocess_isbsg_data(\n",
    "    file_path,\n",
    "    target_col='project_prf_normalised_work_effort',  # Always use standardized form\n",
    "    output_dir='../data',\n",
    "    save_intermediate=True,\n",
    "    **pipeline_kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete preprocessing workflow for ISBSG data: loads the data, runs \n",
    "      the full preprocessing pipeline, saves processed data, pipeline \n",
    "      object, and a metadata report to disk, and returns the processed \n",
    "      DataFrame and metadata\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        Path to input data file\n",
    "    target_col : str\n",
    "        Name of target column\n",
    "    output_dir : str\n",
    "        Directory to save processed data\n",
    "    save_intermediate : bool\n",
    "        Whether to save intermediate processing steps\n",
    "    **pipeline_kwargs : dict\n",
    "        Additional arguments for pipeline creation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Processed dataframe ready for modeling\n",
    "    dict\n",
    "        Processing metadata and statistics\n",
    "    \"\"\"\n",
    "\n",
    "    # print pipeline header\n",
    "    print(\"=\"*60)\n",
    "    print(\"ISBSG Data Preprocessing Pipeline\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    print(f\"Target column (standardized): {target_col}\")\n",
    "    print(f\"Timestamp: {datetime.now()}\")\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load data with smart column detection\n",
    "    loader = DataLoader(file_path, target_col)\n",
    "    df_raw = loader.transform(X = None)\n",
    "    \n",
    "    # Create and fit preprocessing pipeline\n",
    "    pipeline = create_isbsg_preprocessing_pipeline(\n",
    "        target_col=target_col,\n",
    "        original_target_col=loader.original_target_col,  # Pass the found column name\n",
    "        **pipeline_kwargs\n",
    "    )\n",
    "    \n",
    "    # Apply preprocessing in order of ColumnNameStandardizer=> MissingValueAnalyzer =>\n",
    "    # SemicolonProcessor=> MultiValueEncoder=> CategoricalEncoder => ColumnNameFixer\n",
    "\n",
    "    # Apply preprocessing\n",
    "    df_processed = pipeline.fit_transform(df_raw)\n",
    "    \n",
    "    # Prepare metadata\n",
    "    metadata = {\n",
    "        'original_shape': loader.original_shape,\n",
    "        'processed_shape': df_processed.shape,\n",
    "        'processing_timestamp': datetime.now().isoformat(),\n",
    "        'target_column_standardized': target_col,\n",
    "        'target_column_original': loader.original_target_col,\n",
    "        'pipeline_steps': [step[0] for step in pipeline.steps]\n",
    "    }\n",
    "    \n",
    "    # Save processed data\n",
    "    file_stem = Path(file_path).stem\n",
    "    output_path = os.path.join(output_dir, f\"{file_stem}_preprocessed.csv\")\n",
    "    df_processed.to_csv(output_path, index=False)\n",
    "    print(f\"\\nProcessed data saved to: {output_path}\")\n",
    "    \n",
    "    # Save pipeline\n",
    "    pipeline_path = os.path.join(output_dir, f\"{file_stem}_preprocessing_pipeline.pkl\")\n",
    "    joblib.dump(pipeline, pipeline_path)\n",
    "    print(f\"Pipeline saved to: {pipeline_path}\")\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata_path = os.path.join(output_dir, f\"{file_stem}_preprocessing_metadata.txt\")\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        f.write(\"ISBSG Data Preprocessing Metadata\\n\")\n",
    "        f.write(\"=\"*40 + \"\\n\")\n",
    "        for key, value in metadata.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    print(f\"Metadata saved to: {metadata_path}\")\n",
    "\n",
    "    # Print completion & return results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Preprocessing completed successfully!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return df_processed, metadata\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6310e105-c7a4-4df3-adf6-9e4ddaef4fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-06-01 16:19:18.583830\n"
     ]
    }
   ],
   "source": [
    "def integrated_categorical_preprocessing(\n",
    "    sample_file_path: str,\n",
    "    full_file_path: str,\n",
    "    target_col: str,\n",
    "    output_dir: str,\n",
    "    cols_to_keep: List[str] = None,\n",
    "    high_card_columns: List[str] = None,\n",
    "    max_categorical_cardinality: int = 10,\n",
    "    samples_per_category: int = 3,\n",
    "    standardization_mapping: Dict[str, str] = None,\n",
    "    high_missing_threshold: float = 0.7,\n",
    "    separator: str = ';',\n",
    "    strategy: str = 'top_k',\n",
    "    k: int = 20\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Integrated pipeline to:\n",
    "    1. Load sample and full datasets\n",
    "    2. Auto-detect categorical columns\n",
    "    3. Handle high-cardinality multi-value columns\n",
    "    4. Enhance sample with missing categories from full dataset\n",
    "    5. Apply standardization and final preprocessing\n",
    "    \n",
    "    Returns:\n",
    "        - Enhanced and processed DataFrame\n",
    "        - Metadata about the processing steps\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"INTEGRATED CATEGORICAL PREPROCESSING PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Load datasets\n",
    "    print(\"\\n1. Loading datasets...\")\n",
    "    sample_df = pd.read_excel(sample_file_path)\n",
    "    full_df = pd.read_excel(full_file_path)\n",
    "\n",
    "    # Convert object columns to numeric if most values can be coerced to numbers.\n",
    "    sample_df = convert_object_numeric_cols(sample_df)\n",
    "    full_df = convert_object_numeric_cols(full_df)\n",
    "    \n",
    "    print(f\"Sample dataset shape: {sample_df.shape}\")\n",
    "    print(f\"Full dataset shape: {full_df.shape}\")\n",
    "    \n",
    "    # Step 2: Auto-detect categorical columns\n",
    "    print(\"\\n2. Auto-detecting categorical columns...\")\n",
    "    categorical_columns = []\n",
    "    for col in sample_df.columns:\n",
    "        if sample_df[col].dtype == 'object' and sample_df[col].nunique() < 20:\n",
    "            categorical_columns.append(col)\n",
    "    \n",
    "    print(f\"Detected categorical columns: {categorical_columns}\")\n",
    "    \n",
    "    # Step 3: Identify high-cardinality multi-value columns\n",
    "    print(\"\\n3. Processing high-cardinality multi-value columns...\")\n",
    "    if high_card_columns is None:\n",
    "        high_card_columns = ['external_eef_organisation_type', 'project_prf_application_type']\n",
    "    \n",
    "    # Analyze and process high-cardinality columns in full dataset first\n",
    "    full_df_processed = full_df.copy()\n",
    "    col_mapping = {}\n",
    "    \n",
    "    for col in high_card_columns:\n",
    "        if col in full_df.columns:\n",
    "            print(f\"\\nProcessing high-cardinality column: {col}\")\n",
    "            # Recommend strategy for this column\n",
    "            recommend_strategy(full_df, col, separator=separator)\n",
    "            \n",
    "            # Process the column\n",
    "            full_df_processed, temp_mapping = handle_high_cardinality_multivalue(\n",
    "                full_df_processed,\n",
    "                multi_value_columns=[col],\n",
    "                separator=separator,\n",
    "                strategy=strategy,\n",
    "                k=k\n",
    "            )\n",
    "            col_mapping.update(temp_mapping)\n",
    "    \n",
    "    # Step 4: Apply same processing to sample dataset\n",
    "    print(\"\\n4. Applying same processing to sample dataset...\")\n",
    "    sample_df_processed = sample_df.copy()\n",
    "    \n",
    "    for col in high_card_columns:\n",
    "        if col in sample_df.columns:\n",
    "            sample_df_processed, _ = handle_high_cardinality_multivalue(\n",
    "                sample_df_processed,\n",
    "                multi_value_columns=[col],\n",
    "                separator=separator,\n",
    "                strategy=strategy,\n",
    "                k=k\n",
    "            )\n",
    "    \n",
    "    # Step 5: Update categorical columns list after processing\n",
    "    print(\"\\n5. Updating categorical columns after high-cardinality processing...\")\n",
    "    updated_categorical_columns = []\n",
    "    for col in sample_df_processed.columns:\n",
    "        if sample_df_processed[col].dtype == 'object' or sample_df_processed[col].nunique() < max_categorical_cardinality:\n",
    "            updated_categorical_columns.append(col)\n",
    "    \n",
    "    print(f\"Updated categorical columns: {len(updated_categorical_columns)} columns\")\n",
    "    \n",
    "    # Step 6: Enhance sample with missing categories from full dataset\n",
    "    print(\"\\n6. Enhancing sample with missing categories from full dataset...\")\n",
    "    enhanced_df = add_missing_categories_from_full_dataset(\n",
    "        sample_df=sample_df_processed,\n",
    "        full_df=full_df_processed,\n",
    "        categorical_columns=updated_categorical_columns,\n",
    "        samples_per_category=samples_per_category\n",
    "    )\n",
    "    \n",
    "    print(f\"Enhanced dataset shape: {enhanced_df.shape}\")\n",
    "    \n",
    "    # Step 7: Verify categories coverage\n",
    "    print(\"\\n7. Verifying categories coverage...\")\n",
    "    verify_categories_coverage(sample_df_processed, enhanced_df, updated_categorical_columns)\n",
    "    \n",
    "    # Step 8: Check for and handle duplicate columns before final preprocessing\n",
    "    print(\"\\n8. Checking for duplicate columns...\")\n",
    "    duplicate_cols = enhanced_df.columns[enhanced_df.columns.duplicated()].tolist()\n",
    "    if duplicate_cols:\n",
    "        print(f\"Warning: Found duplicate columns: {duplicate_cols}\")\n",
    "        # Remove duplicates, keeping the first occurrence\n",
    "        enhanced_df = enhanced_df.loc[:, ~enhanced_df.columns.duplicated()]\n",
    "        print(\"Removed duplicate columns\")\n",
    "    \n",
    "    # Step 9: Apply final preprocessing using safe wrapper\n",
    "    print(\"\\n9. Applying final preprocessing...\")\n",
    "    final_df, preprocessing_metadata = safe_preprocess_with_fallback(\n",
    "        enhanced_df=enhanced_df,\n",
    "        target_col=target_col,\n",
    "        output_dir=output_dir,\n",
    "        cols_to_keep=cols_to_keep,\n",
    "        max_categorical_cardinality=max_categorical_cardinality,\n",
    "        standardization_mapping=standardization_mapping,\n",
    "        high_missing_threshold=high_missing_threshold\n",
    "    )\n",
    "    \n",
    "    # Step 10: Final validation and duplicate check\n",
    "    print(\"\\n10. Final validation and duplicate check...\")\n",
    "    \n",
    "    # Check for any remaining duplicates after all processing\n",
    "    final_duplicate_cols = final_df.columns[final_df.columns.duplicated()].tolist()\n",
    "    if final_duplicate_cols:\n",
    "        print(f\"Warning: Found duplicate columns in final dataset: {final_duplicate_cols}\")\n",
    "        # Remove duplicates, keeping the first occurrence\n",
    "        final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "        print(\"Removed final duplicate columns\")\n",
    "    \n",
    "    print(f\"Original sample shape: {sample_df.shape}\")\n",
    "    print(f\"Final processed shape: {final_df.shape}\")\n",
    "    print(f\"Columns added: {final_df.shape[1] - sample_df.shape[1]}\")\n",
    "    print(f\"Rows added: {final_df.shape[0] - sample_df.shape[0]}\")\n",
    "    \n",
    "    # Check for columns with similar names (potential duplicates)\n",
    "    similar_cols = []\n",
    "    for col in final_df.columns:\n",
    "        if col.endswith('_1') or col.endswith('_2'):\n",
    "            base_name = col.rsplit('_', 1)[0]\n",
    "            if base_name in final_df.columns:\n",
    "                similar_cols.append((base_name, col))\n",
    "    \n",
    "    if similar_cols:\n",
    "        print(f\"\\nWarning: Found potentially duplicate columns:\")\n",
    "        for base, duplicate in similar_cols:\n",
    "            print(f\"  - '{base}' and '{duplicate}'\")\n",
    "        print(\"Consider reviewing your preprocessing functions to avoid double processing.\")\n",
    "    \n",
    "    # Compile metadata\n",
    "    metadata = {\n",
    "        'original_sample_shape': sample_df.shape,\n",
    "        'original_full_shape': full_df.shape,\n",
    "        'final_shape': final_df.shape,\n",
    "        'categorical_columns_detected': categorical_columns,\n",
    "        'updated_categorical_columns': updated_categorical_columns,\n",
    "        'high_cardinality_columns_processed': high_card_columns,\n",
    "        'column_mapping': col_mapping,\n",
    "        'preprocessing_metadata': preprocessing_metadata,\n",
    "        'rows_added_from_full_dataset': final_df.shape[0] - sample_df.shape[0]\n",
    "    }\n",
    "    \n",
    "    return final_df, metadata\n",
    "\n",
    "def safe_preprocess_with_fallback(\n",
    "    enhanced_df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    output_dir: str,\n",
    "    cols_to_keep: List[str] = None,\n",
    "    max_categorical_cardinality: int = 10,\n",
    "    standardization_mapping: Dict[str, str] = None,\n",
    "    high_missing_threshold: float = 0.7\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Safe preprocessing function that handles the file_path requirement\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save enhanced dataset to temporary file\n",
    "    temp_enhanced_path = os.path.join(output_dir, 'temp_enhanced_sample.xlsx')\n",
    "    enhanced_df.to_excel(temp_enhanced_path, index=False)\n",
    "    \n",
    "    try:\n",
    "        # Apply preprocessing using existing function\n",
    "        final_df, preprocessing_metadata = preprocess_isbsg_data(\n",
    "            file_path=temp_enhanced_path,\n",
    "            target_col=target_col,\n",
    "            output_dir=output_dir,\n",
    "            cols_to_keep=cols_to_keep,\n",
    "            max_categorical_cardinality=max_categorical_cardinality,\n",
    "            standardization_mapping=standardization_mapping,\n",
    "            high_missing_threshold=high_missing_threshold\n",
    "        )\n",
    "        \n",
    "        return final_df, preprocessing_metadata\n",
    "        \n",
    "    finally:\n",
    "        # Clean up temporary file\n",
    "        try:\n",
    "            os.remove(temp_enhanced_path)\n",
    "        except:\n",
    "            print(f\"Warning: Could not remove temporary file {temp_enhanced_path}\")\n",
    "    \n",
    "    return enhanced_df, {'error': 'Preprocessing failed'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "319619a4-0165-4783-b589-2b49e740c91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-06-01 16:19:18.586839\n"
     ]
    }
   ],
   "source": [
    "# Main execution function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the integrated pipeline\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    sample_file_path = os.path.join(DATA_FOLDER, SAMPLE_FILE)\n",
    "    full_file_path = os.path.join(DATA_FOLDER, FULL_FILE)\n",
    "    \n",
    "    # Columns to keep (customize as needed)\n",
    "    cols_to_keep = [\n",
    "        'Project_PRF_CASE_Tool_Used', \n",
    "        'Process_PMF_Prototyping_Used',\n",
    "        'Tech_TF_Client_Roles', \n",
    "        'Tech_TF_Type_of_Server', \n",
    "        'Tech_TF_ClientServer_Description'\n",
    "    ]\n",
    "    \n",
    "    # High-cardinality multi-value columns\n",
    "    high_card_columns = [\n",
    "        'external_eef_organisation_type', \n",
    "        'project_prf_application_type'\n",
    "    ]\n",
    "    \n",
    "    # Standardization rules\n",
    "    standardization_map = {\n",
    "        'stand alone': 'stand-alone',\n",
    "        'client server': 'client-server',\n",
    "        'mathematically intensive': 'mathematically-intensive',\n",
    "        #'mathematically intensive application': 'mathematically-intensive application',\n",
    "        \"file &/or print server\": \"file/print server\",\n",
    "        \"Web?\": \"Web\",\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Run integrated pipeline\n",
    "        final_df, metadata = integrated_categorical_preprocessing(\n",
    "            sample_file_path=sample_file_path,\n",
    "            full_file_path=full_file_path,\n",
    "            target_col=TARGET_COL,\n",
    "            output_dir=DATA_FOLDER,\n",
    "            cols_to_keep=cols_to_keep,\n",
    "            high_card_columns=high_card_columns,\n",
    "            max_categorical_cardinality=10,\n",
    "            samples_per_category=3,\n",
    "            standardization_mapping=standardization_map,\n",
    "            high_missing_threshold=0.7,\n",
    "            separator=';',\n",
    "            strategy='top_k',\n",
    "            k=20\n",
    "        )\n",
    "        \n",
    "        # Save results\n",
    "        output_path = os.path.join(DATA_FOLDER, 'enhanced_sample_final.csv')\n",
    "        final_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Final dataset saved to: {output_path}\")\n",
    "        print(f\"Final shape: {final_df.shape}\")\n",
    "        print(f\"Ready for PyCaret setup!\")\n",
    "        \n",
    "        # Print summary of changes\n",
    "        print(f\"\\nSUMMARY:\")\n",
    "        print(f\"- Original sample rows: {metadata['original_sample_shape'][0]}\")\n",
    "        print(f\"- Rows added from full dataset: {metadata['rows_added_from_full_dataset']}\")\n",
    "        print(f\"- Final rows: {metadata['final_shape'][0]}\")\n",
    "        print(f\"- Original columns: {metadata['original_sample_shape'][1]}\")\n",
    "        print(f\"- Final columns: {metadata['final_shape'][1]}\")\n",
    "        \n",
    "        return final_df, metadata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in integrated pipeline: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1167827a-a72d-4767-b4d0-a525ff81bb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INTEGRATED CATEGORICAL PREPROCESSING PIPELINE\n",
      "============================================================\n",
      "\n",
      "1. Loading datasets...\n",
      "Sample dataset shape: (78, 52)\n",
      "Full dataset shape: (7518, 52)\n",
      "\n",
      "2. Auto-detecting categorical columns...\n",
      "Detected categorical columns: ['External_EEF_Data Quality Rating', 'External_EEF_Industry Sector', 'Project_PRF_Application Group', 'Project_PRF_Development Type', 'Tech_TF_Development Platform', 'Tech_TF_Language Type', 'Tech_TF_Primary Programming Language', 'Project_PRF_Relative Size', 'Project_PRF_Team Size Group', 'Project_PRF_CASE Tool Used', 'Process_PMF_Development Methodologies', 'Process_PMF_Prototyping Used', 'Tech_TF_Architecture', 'Tech_TF_Client_Server', 'Tech_TF_Client_Roles', 'Tech_TF_Server_Roles', 'Tech_TF_Web_Development', 'Tech_TF_DBMS_Used', 'Project_PRF_Cost_currency', 'Project_PRF_Currency_multiple']\n",
      "\n",
      "3. Processing high-cardinality multi-value columns...\n",
      "\n",
      "4. Applying same processing to sample dataset...\n",
      "\n",
      "5. Updating categorical columns after high-cardinality processing...\n",
      "Updated categorical columns: 38 columns\n",
      "\n",
      "6. Enhancing sample with missing categories from full dataset...\n",
      "Analyzing missing categories...\n",
      "Column 'External_EEF_Data Quality Rating': All categories present in sample\n",
      "Column 'Project_PRF_Year of Project': Missing 18 out of 27 categories\n",
      "  Missing categories: [1989, 1990, 1991, 1992, 1993]...\n",
      "Column 'External_EEF_Industry Sector': Missing 7 out of 17 categories\n",
      "  Missing categories: ['Construction', 'Communication', 'Logistics', 'Professional Services', 'Insurance']...\n",
      "Column 'External_EEF_Organisation Type': Missing 170 out of 193 categories\n",
      "  Missing categories: ['Recreation & Personnel Services;Professional Services;Computers & Software;', 'Electronics;', 'Government;Electricity, Gas, Water;Communications;Community Services;Professional Services;Electronics;', 'Wholesale & Retail Trade;Consumer Goods;', 'Government;Financial, Property & Business Services;']...\n",
      "Column 'Project_PRF_Application Group': Missing 2 out of 6 categories\n",
      "  Missing categories: ['Mathematically intensive application', 'Business Application; Infrastructure Software;']\n",
      "Column 'Project_PRF_Application Type': Missing 537 out of 568 categories\n",
      "  Missing categories: ['Financial;', 'ERP;', 'Transportation;', 'Factory parts follow up;', 'Document management;Online analysis and reporting;Workflow support & management;Complex process control;']...\n",
      "Column 'Project_PRF_Development Type': Missing 4 out of 7 categories\n",
      "  Missing categories: ['Porting', 'POC', 'Other', 'Not Defined']\n",
      "Column 'Tech_TF_Development Platform': Missing 2 out of 6 categories\n",
      "  Missing categories: ['Hand Held', 'MF']\n",
      "Column 'Tech_TF_Language Type': Missing 3 out of 6 categories\n",
      "  Missing categories: ['ApG', '2GL', 'APG']\n",
      "Column 'Tech_TF_Primary Programming Language': Missing 119 out of 128 categories\n",
      "  Missing categories: ['Unix', 'VisualFoxPro', 'ColdFusion', 'Data base language', 'Access']...\n",
      "Column 'Project_PRF_Relative Size': Missing 2 out of 9 categories\n",
      "  Missing categories: ['XXL', 'XXXL']\n",
      "Column 'Project_PRF_Team Size Group': Missing 7 out of 15 categories\n",
      "  Missing categories: ['31-40', '15-20', '91-100', '101+', '71-80']...\n",
      "Column 'Project_PRF_CASE Tool Used': Missing 1 out of 3 categories\n",
      "  Missing categories: [\"Don't Know\"]\n",
      "Column 'Process_PMF_Development Methodologies': Missing 31 out of 39 categories\n",
      "  Missing categories: ['Joint Application Development (JAD);Timeboxing;', 'Joint Application Development (JAD);Rapid Application Development (RAD);', 'IT Unified Process (ITUP);', 'Multifunctional Teams;Rapid Application Development (RAD);', 'Waterfall (incl Linear Processing & SSADM);']...\n",
      "Column 'Process_PMF_Prototyping Used': All categories present in sample\n",
      "Column 'Tech_TF_Architecture': Missing 4 out of 7 categories\n",
      "  Missing categories: ['Stand-alone', 'Multi-tier with web interface', 'Multi-tier', 'Multi-tier / Client server']\n",
      "Column 'Tech_TF_Client_Server': Missing 2 out of 4 categories\n",
      "  Missing categories: ['Not Applicable', \"Don't Know\"]\n",
      "Column 'Tech_TF_Client_Roles': Missing 51 out of 61 categories\n",
      "  Missing categories: ['Data retrieval & presentation;Web/HTML browser;', 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;', 'HandHeld Device;', 'Data entry & validation;Web/HTML browser;', 'Data entry & validation;Data retrieval & presentation;Web/HTML browser;Web public interface;']...\n",
      "Column 'Tech_TF_Server_Roles': Missing 74 out of 85 categories\n",
      "  Missing categories: ['Browser/server;Database server;FTP server;HTML/web server;Multi-user legacy application;Security/authentication;', 'Database server;Multi-user legacy application;Object/component server;', 'Database server;Mail server;Security/authentication;', 'Database server;HTML/web server;Object/component server;Business logic;', 'FTP server;HTML/web server;Multi-user legacy application;']...\n",
      "Column 'Tech_TF_Type_of_Server': Missing 9 out of 9 categories\n",
      "  Missing categories: ['LAN Based;', 'Multi-tier with web public interface;', 'Stand alone;', 'Mainframe;', 'Unix;']...\n",
      "Column 'Tech_TF_Client/Server_Description': Missing 26 out of 26 categories\n",
      "  Missing categories: ['Client Server;', 'Client: presentation, processing, data;', 'Embedded;', 'Presentation & Logic on server;', 'Client presentation & processing, data on server;']...\n",
      "Column 'Tech_TF_Web_Development': Missing 1 out of 2 categories\n",
      "  Missing categories: ['Web?']\n",
      "Column 'Tech_TF_DBMS_Used': Missing 1 out of 2 categories\n",
      "  Missing categories: ['No']\n",
      "Column 'Tech_TF_Tools_Used': Missing 4 out of 13 categories\n",
      "  Missing categories: [8, 10, 12, 13]\n",
      "Column 'People_PRF_Project_user_involvement': Missing 5 out of 5 categories\n",
      "  Missing categories: ['Best', 'No', 'Low', 'Yes', \"Don't Know\"]\n",
      "Column 'People_PRF_BA_team_experience_less_than_1_yr': Missing 14 out of 22 categories\n",
      "  Missing categories: [4.0, 7.0, 9.0, 10.0, 13.0]...\n",
      "Column 'People_PRF_BA_team_experience_1_to_3_yr': Missing 11 out of 19 categories\n",
      "  Missing categories: [6.0, 7.0, 40.0, 9.0, 10.0]...\n",
      "Column 'People_PRF_BA_team_experience_great_than_3_yr': Missing 11 out of 20 categories\n",
      "  Missing categories: [4.0, 7.0, 9.0, 10.0, 11.0]...\n",
      "Column 'People_PRF_IT_experience_less_than_1_yr': Missing 12 out of 12 categories\n",
      "  Missing categories: [0.0, 1.0, 2.0, 3.0, 4.0]...\n",
      "Column 'People_PRF_IT_experience_1_to_3_yr': Missing 17 out of 17 categories\n",
      "  Missing categories: [0.0, 1.0, 2.0, 3.0, 4.0]...\n",
      "Column 'People_PRF_IT_experience_great_than_3_yr': Missing 18 out of 18 categories\n",
      "  Missing categories: [0.0, 1.0, 2.0, 3.0, 4.0]...\n",
      "Column 'People_PRF_IT_experience_less_than_3_yr': Missing 12 out of 20 categories\n",
      "  Missing categories: [33.0, 3.0, 36.0, 6.0, 7.0]...\n",
      "Column 'People_PRF_IT_experience_3_to_9_yr': Missing 10 out of 19 categories\n",
      "  Missing categories: [7.0, 8.0, 9.0, 10.0, 11.0]...\n",
      "Column 'People_PRF_IT_experience_great_than_9_yr': Missing 15 out of 22 categories\n",
      "  Missing categories: [5.0, 6.0, 7.0, 8.0, 9.0]...\n",
      "Column 'People_PRF_Project_manage_changes': Missing 2 out of 5 categories\n",
      "  Missing categories: [3.0, 4.0]\n",
      "Column 'People_PRF_Personnel_changes': Missing 11 out of 16 categories\n",
      "  Missing categories: [4.0, 5.0, 6.0, 7.0, 8.0]...\n",
      "Column 'Project_PRF_Cost_currency': Missing 16 out of 19 categories\n",
      "  Missing categories: ['South Africa, rand', 'Sweden, krona', 'Australia, dollar', 'India, Rupees', 'Switzerland, franc']...\n",
      "Column 'Project_PRF_Currency_multiple': Missing 1 out of 3 categories\n",
      "  Missing categories: ['Yes 1,000']\n",
      "\n",
      "Sampling for column 'Project_PRF_Year of Project'...\n",
      "  Added 3 rows for '1989' (out of 5 available)\n",
      "  Added 3 rows for '1990' (out of 11 available)\n",
      "  Added 3 rows for '1991' (out of 39 available)\n",
      "  Added 3 rows for '1992' (out of 38 available)\n",
      "  Added 3 rows for '1993' (out of 76 available)\n",
      "  Added 3 rows for '1994' (out of 142 available)\n",
      "  Added 3 rows for '1995' (out of 134 available)\n",
      "  Added 3 rows for '1996' (out of 123 available)\n",
      "  Added 3 rows for '1997' (out of 164 available)\n",
      "  Added 3 rows for '1998' (out of 309 available)\n",
      "  Added 3 rows for '1999' (out of 549 available)\n",
      "  Added 3 rows for '2000' (out of 592 available)\n",
      "  Added 3 rows for '2001' (out of 281 available)\n",
      "  Added 3 rows for '2002' (out of 442 available)\n",
      "  Added 3 rows for '2003' (out of 289 available)\n",
      "  Added 3 rows for '2004' (out of 707 available)\n",
      "  Added 3 rows for '2006' (out of 619 available)\n",
      "  Added 3 rows for '2007' (out of 210 available)\n",
      "\n",
      "Sampling for column 'External_EEF_Industry Sector'...\n",
      "  Added 3 rows for 'Construction' (out of 42 available)\n",
      "  Added 3 rows for 'Communication' (out of 1410 available)\n",
      "  Added 3 rows for 'Logistics' (out of 39 available)\n",
      "  Added 3 rows for 'Professional Services' (out of 63 available)\n",
      "  Added 3 rows for 'Insurance' (out of 1100 available)\n",
      "  Added 3 rows for 'Mining' (out of 16 available)\n",
      "  Added 3 rows for 'Defence' (out of 21 available)\n",
      "\n",
      "Sampling for column 'External_EEF_Organisation Type'...\n",
      "  Added 2 rows for 'Recreation & Personnel Services;Professional Services;Computers & Software;' (out of 2 available)\n",
      "  Added 3 rows for 'Electronics;' (out of 12 available)\n",
      "  Added 1 rows for 'Government;Electricity, Gas, Water;Communications;Community Services;Professional Services;Electronics;' (out of 1 available)\n",
      "  Added 1 rows for 'Wholesale & Retail Trade;Consumer Goods;' (out of 1 available)\n",
      "  Added 3 rows for 'Government;Financial, Property & Business Services;' (out of 4 available)\n",
      "  Added 1 rows for 'Agriculture, Forestry, Fishing, Hunting;Government;' (out of 1 available)\n",
      "  Added 1 rows for 'Medical and Health Care;Public Administration;Insurance;' (out of 1 available)\n",
      "  Added 3 rows for 'Public Administration;' (out of 174 available)\n",
      "  Added 3 rows for 'Agriculture, Forestry, Fishing, Hunting;' (out of 5 available)\n",
      "  Added 1 rows for 'IT Services;' (out of 1 available)\n",
      "  Added 1 rows for 'Agriculture, Forestry, Fishing, Hunting;Chemicals;Computers & Software;Construction;Defence;Electricity, Gas, Water;Electronics;Food Processing;Government;generic application;' (out of 1 available)\n",
      "  Added 3 rows for 'Software products;' (out of 8 available)\n",
      "  Added 1 rows for 'Coronial Services;' (out of 1 available)\n",
      "  Added 3 rows for 'Oil & Petroleum;' (out of 3 available)\n",
      "  Added 1 rows for 'Government;Local administration and counties;' (out of 1 available)\n",
      "  Added 1 rows for 'Professional Services;Environmental Consulting;' (out of 1 available)\n",
      "  Added 3 rows for 'Art , Events , Ticketing;' (out of 3 available)\n",
      "  Added 1 rows for 'Manufacturing;Professional Services;' (out of 1 available)\n",
      "  Added 1 rows for 'Real Estate & Property;Community Services;' (out of 1 available)\n",
      "  Added 1 rows for 'Occupational Health and Safety;' (out of 1 available)\n",
      "  Added 2 rows for 'general public (mobile phone end user);' (out of 2 available)\n",
      "  Added 3 rows for 'All-purpose;' (out of 3 available)\n",
      "  Added 3 rows for 'Retail;' (out of 3 available)\n",
      "  Added 3 rows for 'Government;Public Administration (Revenue);' (out of 5 available)\n",
      "  Added 2 rows for 'Internet;' (out of 2 available)\n",
      "  Added 2 rows for 'Post/mail services;' (out of 2 available)\n",
      "  Added 3 rows for 'Telecommunications;' (out of 516 available)\n",
      "  Added 1 rows for 'Financial, Property & Business Services;(Banking, Insurance, Stock);' (out of 1 available)\n",
      "  Added 1 rows for 'Chemicals;Energy;' (out of 1 available)\n",
      "  Added 3 rows for 'Education Institution;Electricity, Gas, Water;University;' (out of 5 available)\n",
      "  Added 1 rows for 'Advertising;' (out of 1 available)\n",
      "  Added 1 rows for 'Public Administration;Financial, Property & Business Services;' (out of 1 available)\n",
      "  Added 3 rows for 'Wholesale & Retail Trade;Transport & Storage;' (out of 4 available)\n",
      "  Added 3 rows for 'Wholesale & Retail Trade;' (out of 54 available)\n",
      "  Added 1 rows for 'Wholesale & Retail Trade;Oil;' (out of 1 available)\n",
      "  Added 2 rows for 'Real Estate & Property;' (out of 2 available)\n",
      "  Added 3 rows for 'Public Administration;Community Services;Insurance;' (out of 45 available)\n",
      "  Added 1 rows for 'Environmental Monitoring;Public Administration;' (out of 1 available)\n",
      "  Added 1 rows for 'UniversityEvent Management-involves external users;' (out of 1 available)\n",
      "  Added 1 rows for 'Transit Corporation;' (out of 1 available)\n",
      "  Added 2 rows for 'Government;Professional Services;' (out of 2 available)\n",
      "  Added 3 rows for 'Professional Services;Computers & Software;' (out of 3 available)\n",
      "  Added 3 rows for 'General;' (out of 4 available)\n",
      "  Added 1 rows for 'Government;Medical and Health Care;' (out of 1 available)\n",
      "  Added 3 rows for 'Public Administration;Insurance;' (out of 6 available)\n",
      "  Added 1 rows for 'Communications;Financial (Banking, Insurance, Stock);Government;Public Administration (Revenue);Manufacturing;Medical and Health Care;Post;Traffic (Aerospace/railway/Automotive);Transport;Logistic (Wholesale & Retail/Storage);Research & Development;Energy' (out of 1 available)\n",
      "  Added 1 rows for 'Commercial services;' (out of 1 available)\n",
      "  Added 1 rows for 'Services;' (out of 1 available)\n",
      "  Added 2 rows for 'Financial, Property & Business Services;Insurance;' (out of 2 available)\n",
      "  Added 3 rows for 'Information Technology Services Provider;' (out of 5 available)\n",
      "  Added 3 rows for 'Marketing;' (out of 3 available)\n",
      "  Added 2 rows for 'Computers and IT business;' (out of 2 available)\n",
      "  Added 3 rows for 'Media;' (out of 11 available)\n",
      "  Added 3 rows for 'Oil;' (out of 6 available)\n",
      "  Added 1 rows for 'Construction;Financial, Property & Business Services;Government;Real Estate & Property;Transport & Storage;Housing;' (out of 1 available)\n",
      "  Added 3 rows for 'Manufacturing;Computers & Software;' (out of 3 available)\n",
      "  Added 2 rows for 'Manufacturing;Oil;' (out of 2 available)\n",
      "  Added 1 rows for 'Service;Recreation, Personnel & Other Services;' (out of 1 available)\n",
      "  Added 1 rows for 'Data Provisioning;' (out of 1 available)\n",
      "  Added 3 rows for 'Engineering;' (out of 15 available)\n",
      "  Added 1 rows for 'Content Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Computers & Software;Citizens of DK;' (out of 1 available)\n",
      "  Added 3 rows for 'Voice Provisioning;' (out of 17 available)\n",
      "  Added 1 rows for 'Virtual Assistants (Lingubots);' (out of 1 available)\n",
      "  Added 2 rows for 'Public Administration;Community Services;' (out of 2 available)\n",
      "  Added 1 rows for 'Manufacturing;Computers;Diversified Corp;' (out of 1 available)\n",
      "  Added 3 rows for 'Government;Municipal Services;' (out of 4 available)\n",
      "  Added 1 rows for 'Government;Health Sciences;' (out of 1 available)\n",
      "  Added 1 rows for 'Government;Electricity, Gas, Water;' (out of 1 available)\n",
      "  Added 1 rows for 'Tax administration;' (out of 1 available)\n",
      "  Added 1 rows for 'Citizens and the Municipalities;' (out of 1 available)\n",
      "  Added 1 rows for 'Manufacturing;Wholesale & Retail Trade;Transport & Storage;' (out of 1 available)\n",
      "  Added 1 rows for 'Post;' (out of 1 available)\n",
      "  Added 3 rows for 'Communications;Telecom;' (out of 5 available)\n",
      "  Added 3 rows for 'Government;Public Administration;' (out of 7 available)\n",
      "  Added 3 rows for 'Engineering;Research & Development;Software Development;Client/Server architecture for Language Services;' (out of 15 available)\n",
      "  Added 3 rows for 'Chemicals;' (out of 18 available)\n",
      "  Added 3 rows for 'Mining;' (out of 4 available)\n",
      "  Added 1 rows for 'Government, Public Administration (Revenue);' (out of 1 available)\n",
      "  Added 2 rows for 'Publishing;' (out of 2 available)\n",
      "  Added 1 rows for 'Aerospace / Automotive;Chemicals;Defence;Electronics;Food Processing;Government;Manufacturing;Medical and Health Care;Mining;Oil & Petroleum;Transport & Storage;Generic application;' (out of 1 available)\n",
      "  Added 3 rows for 'Agriculture, Forestry, Fishing, Hunting;Manufacturing;' (out of 5 available)\n",
      "  Added 3 rows for 'Communications;' (out of 708 available)\n",
      "  Added 1 rows for 'Human Resource (HR) Domain;' (out of 1 available)\n",
      "  Added 1 rows for 'Manufacturing;Computers;Diversified corporation;' (out of 1 available)\n",
      "  Added 1 rows for 'Any organization which counts function points;' (out of 1 available)\n",
      "  Added 1 rows for 'Exhibition Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Government;Real Estate & Property;' (out of 1 available)\n",
      "  Added 1 rows for 'Community Services;Invoice-handling;' (out of 1 available)\n",
      "  Added 2 rows for 'Airport;' (out of 2 available)\n",
      "  Added 1 rows for 'Research & development;' (out of 1 available)\n",
      "  Added 1 rows for 'Aerospace / Automotive;Computers & Software;' (out of 1 available)\n",
      "  Added 3 rows for 'Mining;Manufacturing;Chemicals;' (out of 3 available)\n",
      "  Added 2 rows for 'Public Administration;Aerospace / Automotive;Computers & Software;Insurance;' (out of 2 available)\n",
      "  Added 1 rows for 'Wholesale & Retail Trade;Computers & Software;' (out of 1 available)\n",
      "  Added 3 rows for 'Credit Card Processor;' (out of 4 available)\n",
      "  Added 3 rows for 'Service;' (out of 4 available)\n",
      "  Added 1 rows for 'Education Institution;Research;' (out of 1 available)\n",
      "  Added 1 rows for 'Transport & Storage;Media;' (out of 1 available)\n",
      "  Added 1 rows for 'Finance;' (out of 1 available)\n",
      "  Added 1 rows for 'IS-Metrics collection system;' (out of 1 available)\n",
      "  Added 3 rows for 'Manufacturing;Transport & Storage;' (out of 8 available)\n",
      "  Added 1 rows for 'Government;Danish citizens;' (out of 1 available)\n",
      "  Added 2 rows for 'Computers & Software;Consumer Goods;Electronics;' (out of 2 available)\n",
      "  Added 3 rows for 'Financial (Banking, Insurance, Stock);' (out of 6 available)\n",
      "  Added 3 rows for 'Utilities;' (out of 7 available)\n",
      "  Added 3 rows for 'Defence;Aerospace / Automotive;' (out of 3 available)\n",
      "  Added 1 rows for 'Imaging;' (out of 1 available)\n",
      "  Added 1 rows for 'Universal;' (out of 1 available)\n",
      "  Added 1 rows for 'Traffic (Aerospace/Railway/Automotive);Transport;' (out of 1 available)\n",
      "  Added 1 rows for 'Telecom;' (out of 1 available)\n",
      "  Added 1 rows for 'Chemicals;Community Services;Electricity, Gas, Water;Government;' (out of 1 available)\n",
      "  Added 1 rows for 'Energy Sources (Oil & Petroleum/Electricity etc);' (out of 1 available)\n",
      "  Added 3 rows for 'Recreation & Personnel Services;' (out of 13 available)\n",
      "  Added 3 rows for 'Revenue;' (out of 10 available)\n",
      "  Added 3 rows for 'Consultancy;' (out of 4 available)\n",
      "  Added 1 rows for 'Communications;Electronics;' (out of 1 available)\n",
      "  Added 3 rows for 'E-Business;' (out of 6 available)\n",
      "  Added 1 rows for 'Education;' (out of 1 available)\n",
      "  Added 2 rows for 'Amusement/Game Center;' (out of 2 available)\n",
      "  Added 3 rows for 'Construction;' (out of 23 available)\n",
      "  Added 1 rows for 'Manufacturing;Consumer Goods;' (out of 1 available)\n",
      "  Added 1 rows for 'Security;' (out of 1 available)\n",
      "  Added 3 rows for 'Manufacturing;' (out of 699 available)\n",
      "  Added 2 rows for 'Communications;Computers & Software;' (out of 2 available)\n",
      "  Added 3 rows for 'Sales & Marketing;' (out of 7 available)\n",
      "  Added 1 rows for 'Warehouse Management;' (out of 1 available)\n",
      "  Added 3 rows for 'Communications;Telecom & Networking;' (out of 3 available)\n",
      "  Added 1 rows for 'Travel;' (out of 1 available)\n",
      "  Added 3 rows for 'Logistics;' (out of 39 available)\n",
      "  Added 3 rows for 'Computers & Software;' (out of 122 available)\n",
      "  Added 3 rows for 'Defence;' (out of 17 available)\n",
      "  Added 1 rows for 'Distribution;' (out of 1 available)\n",
      "  Added 3 rows for 'Local;' (out of 14 available)\n",
      "  Added 3 rows for 'Billing;' (out of 22 available)\n",
      "  Added 3 rows for 'Government;Defence;' (out of 62 available)\n",
      "  Added 3 rows for 'Professional Services;' (out of 23 available)\n",
      "  Added 2 rows for 'Car Rental;' (out of 2 available)\n",
      "  Added 1 rows for 'Agriculture, Forestry, Fishing, Hunting;Transport & Storage;' (out of 1 available)\n",
      "  Added 1 rows for 'Community Services;Municipality;' (out of 1 available)\n",
      "  Added 1 rows for 'Transport & Storage;Professional Services;' (out of 1 available)\n",
      "  Added 1 rows for 'Government;Defence;Aerospace / Automotive;' (out of 1 available)\n",
      "  Added 2 rows for 'Medical and Health Care;Professional Services;' (out of 2 available)\n",
      "  Added 3 rows for 'Building Automation;' (out of 4 available)\n",
      "  Added 1 rows for 'Manufacturing;Manufacture of steel products;' (out of 1 available)\n",
      "  Added 1 rows for 'Revenue collection;' (out of 1 available)\n",
      "  Added 3 rows for 'Financial, Property & Business Services;Banking;' (out of 3 available)\n",
      "  Added 1 rows for 'Manufacturing;Wholesale & Retail Trade;' (out of 1 available)\n",
      "  Added 3 rows for 'Insurance;' (out of 1096 available)\n",
      "  Added 2 rows for 'Air Traffic Management;' (out of 2 available)\n",
      "  Added 3 rows for 'Government;Public administration;' (out of 4 available)\n",
      "  Added 1 rows for 'Agriculture, Forestry, Fishing, Hunting;Banking;' (out of 1 available)\n",
      "  Added 3 rows for 'Business Services;' (out of 5 available)\n",
      "  Added 1 rows for 'Computers & Software;Human Ressources;' (out of 1 available)\n",
      "  Added 1 rows for 'Information Technology;Human Resource (HR) Domain;' (out of 1 available)\n",
      "  Added 3 rows for 'Logistic (Wholesale & Retail/Storage);' (out of 4 available)\n",
      "  Added 1 rows for 'Computer Consultants;' (out of 1 available)\n",
      "  Added 3 rows for 'Ordering;' (out of 23 available)\n",
      "  Added 1 rows for 'Restaurant;' (out of 1 available)\n",
      "  Added 1 rows for 'Government;Municipal;' (out of 1 available)\n",
      "  Added 3 rows for 'Telecommunication;' (out of 134 available)\n",
      "  Added 2 rows for 'Computer Systems Consultant;Public Administration;' (out of 2 available)\n",
      "  Added 1 rows for 'Government;Municipality;' (out of 1 available)\n",
      "  Added 3 rows for 'Electricity, Gas, Water;' (out of 57 available)\n",
      "  Added 1 rows for 'Developing global software solutions;' (out of 1 available)\n",
      "  Added 1 rows for 'Wholesale & Retail Trade;Financial, Property & Business Services;' (out of 1 available)\n",
      "  Added 1 rows for 'Transport & Storage;Aerospace / Automotive;' (out of 1 available)\n",
      "  Added 3 rows for 'Maintenance;' (out of 8 available)\n",
      "  Added 1 rows for 'Transport & Storage;Public Administration;' (out of 1 available)\n",
      "  Added 2 rows for 'Sales;' (out of 2 available)\n",
      "\n",
      "Sampling for column 'Project_PRF_Application Group'...\n",
      "  Added 3 rows for 'Mathematically intensive application' (out of 6 available)\n",
      "  Added 2 rows for 'Business Application; Infrastructure Software;' (out of 2 available)\n",
      "\n",
      "Sampling for column 'Project_PRF_Application Type'...\n",
      "  Added 3 rows for 'Financial;' (out of 4 available)\n",
      "  Added 1 rows for 'ERP;' (out of 1 available)\n",
      "  Added 1 rows for 'Transportation;' (out of 1 available)\n",
      "  Added 3 rows for 'Factory parts follow up;' (out of 3 available)\n",
      "  Added 1 rows for 'Document management;Online analysis and reporting;Workflow support & management;Complex process control;' (out of 1 available)\n",
      "  Added 3 rows for 'Decision Support System;' (out of 26 available)\n",
      "  Added 1 rows for 'Document management;Financial transaction process/accounting;' (out of 1 available)\n",
      "  Added 1 rows for 'Workflow support & management;Management Information System;' (out of 1 available)\n",
      "  Added 2 rows for 'Catalogue/register of things or events;Customer billing/relationship management;Document management;Geographic or spatial information system;Mathematical modelling (finance or eng.);Electronic Data Interchange;' (out of 2 available)\n",
      "  Added 1 rows for 'Spare parts management;' (out of 1 available)\n",
      "  Added 1 rows for 'International;' (out of 1 available)\n",
      "  Added 3 rows for 'Customer billing;' (out of 17 available)\n",
      "  Added 3 rows for 'Workflow support & management;' (out of 103 available)\n",
      "  Added 1 rows for 'Document management;Logistic or supply planning & control;' (out of 1 available)\n",
      "  Added 1 rows for 'MultiMedia;' (out of 1 available)\n",
      "  Added 3 rows for 'Internet Banking;' (out of 3 available)\n",
      "  Added 3 rows for 'Mainframe;' (out of 5 available)\n",
      "  Added 3 rows for 'Management system;' (out of 7 available)\n",
      "  Added 1 rows for 'Transaction/Production System;Artificial Intelligence;' (out of 1 available)\n",
      "  Added 1 rows for 'Condemnation proceedings;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Data or database management;' (out of 1 available)\n",
      "  Added 2 rows for 'Retailler sells reporting;' (out of 2 available)\n",
      "  Added 1 rows for 'Energy Reporting;' (out of 1 available)\n",
      "  Added 1 rows for 'Device or interface driver;' (out of 1 available)\n",
      "  Added 3 rows for 'Telecommunications;' (out of 4 available)\n",
      "  Added 1 rows for 'Parts database for conception;' (out of 1 available)\n",
      "  Added 1 rows for 'Reparation management;' (out of 1 available)\n",
      "  Added 3 rows for 'Team Management;' (out of 6 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Customer billing/relationship management;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Performance monitoring;' (out of 1 available)\n",
      "  Added 1 rows for 'Inventory Control;' (out of 1 available)\n",
      "  Added 1 rows for 'Test Equipment;' (out of 1 available)\n",
      "  Added 1 rows for 'Call Center Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Production process documentation;' (out of 1 available)\n",
      "  Added 1 rows for 'Chemical Risks Information System;' (out of 1 available)\n",
      "  Added 2 rows for 'Strategic planning;' (out of 2 available)\n",
      "  Added 1 rows for 'Data Warehouse;' (out of 1 available)\n",
      "  Added 1 rows for 'Micro Marketing;' (out of 1 available)\n",
      "  Added 3 rows for 'Sales promotion tool;' (out of 5 available)\n",
      "  Added 3 rows for 'Production management system;' (out of 10 available)\n",
      "  Added 1 rows for 'Marketing Info System;' (out of 1 available)\n",
      "  Added 1 rows for 'Decision Support System;Management Information System;Office Information System;' (out of 1 available)\n",
      "  Added 3 rows for 'Process of factory management;' (out of 3 available)\n",
      "  Added 1 rows for 'Equipment Management;' (out of 1 available)\n",
      "  Added 3 rows for 'Website;' (out of 3 available)\n",
      "  Added 1 rows for 'Car Documentation management;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Document management;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Logistic tracking;' (out of 1 available)\n",
      "  Added 1 rows for 'Network management;' (out of 1 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Customer billing/relationship management;' (out of 4 available)\n",
      "  Added 1 rows for 'Telecom Data Circuits;' (out of 1 available)\n",
      "  Added 1 rows for 'Stock factory manegement;' (out of 1 available)\n",
      "  Added 1 rows for 'Scientific/Math;' (out of 1 available)\n",
      "  Added 1 rows for 'Corporate Taxation;' (out of 1 available)\n",
      "  Added 2 rows for 'Customer billing/relationship management;Contact Management;' (out of 2 available)\n",
      "  Added 1 rows for 'Analysis and Environmental Risk Assessment;' (out of 1 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Online analysis and reporting;' (out of 5 available)\n",
      "  Added 1 rows for 'Class Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Customer billing/relationship management;Document management;Administrative system for daycare;' (out of 1 available)\n",
      "  Added 1 rows for 'Translation;' (out of 1 available)\n",
      "  Added 2 rows for 'Factory follow up;' (out of 2 available)\n",
      "  Added 1 rows for 'Automate exchange between two IT Systems;' (out of 1 available)\n",
      "  Added 1 rows for 'System conversion;' (out of 1 available)\n",
      "  Added 2 rows for 'Technical Support  Information System;' (out of 2 available)\n",
      "  Added 1 rows for 'Web-based App. J2EE;' (out of 1 available)\n",
      "  Added 1 rows for 'Building Automation;Embedded software - simple device control;Protocol Linux ARM9;Device or interface driver;' (out of 1 available)\n",
      "  Added 1 rows for 'Tools management;' (out of 1 available)\n",
      "  Added 1 rows for 'Quality Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Salaries Reporting;' (out of 1 available)\n",
      "  Added 1 rows for 'Fault Tolerance;Management Information System;Fault Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Supply Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Device or interface driver;Financial transaction process/accounting;Complex process control;' (out of 1 available)\n",
      "  Added 1 rows for 'Provider Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Rules documentation management;' (out of 1 available)\n",
      "  Added 2 rows for 'Management Information System;EDI;' (out of 2 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Document management;Online analysis and reporting;' (out of 4 available)\n",
      "  Added 1 rows for 'Vehicle Systems Software;' (out of 1 available)\n",
      "  Added 1 rows for 'Project Risk management;' (out of 1 available)\n",
      "  Added 1 rows for 'Human resource;' (out of 1 available)\n",
      "  Added 1 rows for 'MiddleWare Telecom Switching;' (out of 1 available)\n",
      "  Added 2 rows for 'Health Management;' (out of 2 available)\n",
      "  Added 3 rows for 'MiddleWare;' (out of 12 available)\n",
      "  Added 3 rows for 'Providing Management;' (out of 5 available)\n",
      "  Added 2 rows for 'Quality Factory Reporting;' (out of 2 available)\n",
      "  Added 2 rows for 'Business;Catalogue/register of things or events;' (out of 2 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Document management;Job, case, incident, project management;Logistic or supply planning & control;Online analysis and reporting;Personal productivity (e.g. spreadsheet);Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Online analysis and reporting;' (out of 1 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Job, case, incident, project management;Personal productivity (e.g. spreadsheet);Workflow support & management;' (out of 1 available)\n",
      "  Added 1 rows for 'Part management in factory;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Document management;Customer relationship management;' (out of 1 available)\n",
      "  Added 1 rows for 'Telecom;Network Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Computing of the thermodynamic process;' (out of 1 available)\n",
      "  Added 2 rows for 'Selling reporting;' (out of 2 available)\n",
      "  Added 1 rows for 'Sales calculation (DRP);' (out of 1 available)\n",
      "  Added 1 rows for 'POS;' (out of 1 available)\n",
      "  Added 3 rows for 'E-Business;' (out of 6 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Document management;Online analysis and reporting;Workflow support & management;' (out of 1 available)\n",
      "  Added 1 rows for 'Customer Billing;' (out of 1 available)\n",
      "  Added 2 rows for 'Instant Messaging client;' (out of 2 available)\n",
      "  Added 3 rows for 'Calculation, quotation, insurance policy issue;' (out of 7 available)\n",
      "  Added 1 rows for 'web;' (out of 1 available)\n",
      "  Added 1 rows for 'Number of Hosting Solution;' (out of 1 available)\n",
      "  Added 2 rows for 'Financial transaction process/accounting;Management or performance reporting;' (out of 2 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Document management;Workflow support & management;' (out of 1 available)\n",
      "  Added 1 rows for 'Human Ressources;' (out of 1 available)\n",
      "  Added 2 rows for 'Msg.Switch/cel phone;' (out of 2 available)\n",
      "  Added 1 rows for 'Marketing systems;' (out of 1 available)\n",
      "  Added 1 rows for 'Online analysis and reporting;Personal productivity (e.g. spreadsheet);' (out of 1 available)\n",
      "  Added 2 rows for 'Logistic or supply planning & control;Stock control & order processing;' (out of 2 available)\n",
      "  Added 1 rows for 'Rules documentation;' (out of 1 available)\n",
      "  Added 3 rows for 'Operating system or software utility;(Re-usable component);' (out of 7 available)\n",
      "  Added 1 rows for 'Customer Resource Management;' (out of 1 available)\n",
      "  Added 3 rows for 'Trading;' (out of 25 available)\n",
      "  Added 3 rows for 'IT management;' (out of 3 available)\n",
      "  Added 1 rows for 'Job, case, incident, project management;Online analysis and reporting;' (out of 1 available)\n",
      "  Added 1 rows for 'Online System for University fraternities;' (out of 1 available)\n",
      "  Added 3 rows for 'Accounting;' (out of 4 available)\n",
      "  Added 2 rows for 'Executive Information System;Management Information System;' (out of 2 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Customer billing;Customer relationship management;' (out of 1 available)\n",
      "  Added 3 rows for 'Management or performance reporting;' (out of 21 available)\n",
      "  Added 1 rows for 'Other;' (out of 1 available)\n",
      "  Added 1 rows for 'Software for machine control;Complex process control;' (out of 1 available)\n",
      "  Added 3 rows for 'Management of Licences and Permits;' (out of 72 available)\n",
      "  Added 1 rows for 'Management of registration number;' (out of 1 available)\n",
      "  Added 2 rows for 'Job, case, incident, project management;Online analysis and reporting;Personal productivity (e.g. spreadsheet);' (out of 2 available)\n",
      "  Added 2 rows for 'Management or performance reporting;Complex process control;' (out of 2 available)\n",
      "  Added 2 rows for 'Project's management;' (out of 2 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;CRM;' (out of 1 available)\n",
      "  Added 1 rows for 'Transaction/Production System;Office Automation System;Decision Support System;' (out of 1 available)\n",
      "  Added 3 rows for 'Follow up of car failure;' (out of 7 available)\n",
      "  Added 1 rows for 'IP Contact Centers;' (out of 1 available)\n",
      "  Added 1 rows for 'GUI Interface Application;' (out of 1 available)\n",
      "  Added 3 rows for 'Network Management;Telecom & Networking;' (out of 3 available)\n",
      "  Added 1 rows for 'Providing management;' (out of 1 available)\n",
      "  Added 1 rows for 'Telecom Data Circuits and Revenue;' (out of 1 available)\n",
      "  Added 3 rows for 'Fault Tolerance;' (out of 4 available)\n",
      "  Added 1 rows for 'Management of car distribution;' (out of 1 available)\n",
      "  Added 1 rows for 'Human ressources management;' (out of 1 available)\n",
      "  Added 1 rows for 'Customs Informations management;' (out of 1 available)\n",
      "  Added 3 rows for 'Office Information System;' (out of 60 available)\n",
      "  Added 1 rows for 'Factory Reporting;' (out of 1 available)\n",
      "  Added 2 rows for 'Manufacturing process management;' (out of 2 available)\n",
      "  Added 1 rows for 'Sensor Ctl. + presentation;' (out of 1 available)\n",
      "  Added 1 rows for 'Cost logistic Computing;' (out of 1 available)\n",
      "  Added 1 rows for 'Logistic or supply planning & control;Stock control & order processing;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Warranty Management;' (out of 1 available)\n",
      "  Added 3 rows for 'Engineering Software;' (out of 3 available)\n",
      "  Added 3 rows for 'Inventory Management;' (out of 3 available)\n",
      "  Added 1 rows for 'Dealer management;' (out of 1 available)\n",
      "  Added 3 rows for 'Marketing management;' (out of 3 available)\n",
      "  Added 3 rows for 'Customisation (Add-ons) to a Product Data Management System;' (out of 14 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Document management;Financial transaction process/accounting;Job, case, incident, project management;Logistic or supply planning & control;Management or performance reporting;Online analysis and reporting;Stock contr' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Electronic Data Interchange;Online analysis and reporting;Legislation and consideration of building cases;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Operating system or software utility;' (out of 1 available)\n",
      "  Added 1 rows for 'Car design tool;' (out of 1 available)\n",
      "  Added 3 rows for 'Cars selling;' (out of 25 available)\n",
      "  Added 1 rows for 'Supplier Warranty Charge Back;' (out of 1 available)\n",
      "  Added 1 rows for 'Algorithmic + DB;' (out of 1 available)\n",
      "  Added 2 rows for 'Printing Documentation Design;' (out of 2 available)\n",
      "  Added 1 rows for 'resources Management;' (out of 1 available)\n",
      "  Added 2 rows for 'After sales Documentation;' (out of 2 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;Billing management - Batch processing;' (out of 1 available)\n",
      "  Added 1 rows for 'Document management;Job, case, incident, project management;Management or performance reporting;Online analysis and reporting;Operating system or software utility;Workflow support & management;Telecom & network management;' (out of 1 available)\n",
      "  Added 2 rows for 'GUI for Protocol;Protocol Enhancement;' (out of 2 available)\n",
      "  Added 3 rows for 'Financial transaction process/accounting;Client Server;' (out of 116 available)\n",
      "  Added 1 rows for 'Reporting on factoring process;' (out of 1 available)\n",
      "  Added 1 rows for 'Diagnostic distribution  management;' (out of 1 available)\n",
      "  Added 1 rows for 'Knowledge Based Multimedia;' (out of 1 available)\n",
      "  Added 1 rows for 'Online analysis and reporting;Embedded software - simple device control;Telecom & network management;' (out of 1 available)\n",
      "  Added 1 rows for 'Job, case, incident, project management;Management or performance reporting;Operating system or software utility;Workflow support & management;Telecom & network management;' (out of 1 available)\n",
      "  Added 3 rows for 'Document management;Financial transaction process/accounting;Image, video or sound processing;' (out of 26 available)\n",
      "  Added 3 rows for 'Design management;' (out of 5 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Processing application for public subsidies;' (out of 1 available)\n",
      "  Added 1 rows for 'Data Provisioning;' (out of 1 available)\n",
      "  Added 3 rows for 'Voice Provisioning;' (out of 17 available)\n",
      "  Added 2 rows for 'Parts catalogue management;' (out of 2 available)\n",
      "  Added 1 rows for 'Test vehicles Reporting;' (out of 1 available)\n",
      "  Added 2 rows for 'After Sales Management Contract service;' (out of 2 available)\n",
      "  Added 1 rows for 'To determine which IVR credit card refresh used;' (out of 1 available)\n",
      "  Added 1 rows for 'Office Information System;Functional Specification System;' (out of 1 available)\n",
      "  Added 2 rows for 'Knowledge-based App. w/ Interactive & Batch dbs;' (out of 2 available)\n",
      "  Added 1 rows for 'Suppliers Follow up;' (out of 1 available)\n",
      "  Added 1 rows for 'Computer Integrated Manufactuaring system;' (out of 1 available)\n",
      "  Added 1 rows for 'Reconciliation;' (out of 1 available)\n",
      "  Added 1 rows for 'Web Content;' (out of 1 available)\n",
      "  Added 3 rows for 'Management or performance reporting;Online analysis and reporting;' (out of 4 available)\n",
      "  Added 1 rows for 'Scheduling of work orders assembly lines;' (out of 1 available)\n",
      "  Added 2 rows for 'Management Information System;Office Information System;Transaction/Production System;' (out of 2 available)\n",
      "  Added 1 rows for 'Management of manufacturing needs additional;' (out of 1 available)\n",
      "  Added 1 rows for 'VIrtual Synthesis for Acoustic;' (out of 1 available)\n",
      "  Added 3 rows for 'MS Billing;' (out of 4 available)\n",
      "  Added 1 rows for 'Spec/Document Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Motor simulator;' (out of 1 available)\n",
      "  Added 1 rows for 'website for Parts selling;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Financial transaction process/accounting;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Car renting;' (out of 1 available)\n",
      "  Added 3 rows for 'Geometric design;' (out of 7 available)\n",
      "  Added 3 rows for 'Quality of factory;' (out of 3 available)\n",
      "  Added 3 rows for 'Document management;' (out of 10 available)\n",
      "  Added 3 rows for 'Protocols;' (out of 8 available)\n",
      "  Added 1 rows for 'Fault Tolerance;Process Control;Call Centre;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Document management;Online analysis and reporting;Workflow support & management;Complex process control;' (out of 1 available)\n",
      "  Added 1 rows for 'human resources organisation in the factories;' (out of 1 available)\n",
      "  Added 3 rows for 'Customer management;' (out of 19 available)\n",
      "  Added 1 rows for 'Parts reporting IS;' (out of 1 available)\n",
      "  Added 3 rows for 'Real-time System;' (out of 8 available)\n",
      "  Added 3 rows for 'Management Information System;Linguistic Software;' (out of 15 available)\n",
      "  Added 2 rows for 'CIS;' (out of 2 available)\n",
      "  Added 1 rows for 'Tax system;' (out of 1 available)\n",
      "  Added 3 rows for 'Document management;Financial transaction process/accounting;Online analysis and reporting;Stock control & order processing;Workflow support & management;Customer billing;Reservation system (eg. Airline, hotel);' (out of 3 available)\n",
      "  Added 1 rows for 'Web;' (out of 1 available)\n",
      "  Added 1 rows for 'Parts requirement's calculation (DRP);' (out of 1 available)\n",
      "  Added 2 rows for 'Airport Weather Observation Systems;Meteorological  events detection;' (out of 2 available)\n",
      "  Added 1 rows for 'Security management;' (out of 1 available)\n",
      "  Added 3 rows for 'Utility;' (out of 8 available)\n",
      "  Added 1 rows for 'Internal Telecom Ordering Application;' (out of 1 available)\n",
      "  Added 1 rows for 'Cost Tools Computing;' (out of 1 available)\n",
      "  Added 2 rows for 'Trading? (procurement management);' (out of 2 available)\n",
      "  Added 3 rows for 'Client Server;' (out of 18 available)\n",
      "  Added 1 rows for 'Personal system;' (out of 1 available)\n",
      "  Added 1 rows for 'Client Server and Mainframe;' (out of 1 available)\n",
      "  Added 3 rows for 'Enterprise Management;' (out of 7 available)\n",
      "  Added 2 rows for 'Sales statistics;' (out of 2 available)\n",
      "  Added 3 rows for 'Fixed asset;' (out of 3 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Online analysis and reporting;Space management of schools;' (out of 1 available)\n",
      "  Added 1 rows for 'Information systems (Web);' (out of 1 available)\n",
      "  Added 1 rows for 'Optimisation for Industrial Scenarios;' (out of 1 available)\n",
      "  Added 1 rows for 'Data protection;' (out of 1 available)\n",
      "  Added 3 rows for 'Suppliers Management;' (out of 3 available)\n",
      "  Added 3 rows for 'Car logistic management;' (out of 6 available)\n",
      "  Added 3 rows for 'Telecom & network management;' (out of 57 available)\n",
      "  Added 1 rows for 'Car embedded Computer Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Switching;' (out of 1 available)\n",
      "  Added 1 rows for 'IT project Management;' (out of 1 available)\n",
      "  Added 1 rows for 'University Admission Application Portal;' (out of 1 available)\n",
      "  Added 3 rows for 'Reporting;' (out of 15 available)\n",
      "  Added 1 rows for 'eCommerce;' (out of 1 available)\n",
      "  Added 1 rows for 'insurance quotation;' (out of 1 available)\n",
      "  Added 1 rows for 'Interface;' (out of 1 available)\n",
      "  Added 1 rows for 'Card Administration  INCAS & Fault Assurance CAPRA;' (out of 1 available)\n",
      "  Added 1 rows for 'Employee self-service system;' (out of 1 available)\n",
      "  Added 2 rows for 'DB Serch system;' (out of 2 available)\n",
      "  Added 1 rows for 'Electronic Data Interchange;Reusable component;' (out of 1 available)\n",
      "  Added 1 rows for 'Graphical Modeling;' (out of 1 available)\n",
      "  Added 1 rows for 'Vendors management;' (out of 1 available)\n",
      "  Added 1 rows for 'Process management;' (out of 1 available)\n",
      "  Added 1 rows for 'Sales and Logistics Standard Application;' (out of 1 available)\n",
      "  Added 3 rows for 'Stock control & order processing;' (out of 73 available)\n",
      "  Added 2 rows for 'Commercial Web site;' (out of 2 available)\n",
      "  Added 3 rows for 'System Software;' (out of 11 available)\n",
      "  Added 3 rows for 'Parts management;' (out of 7 available)\n",
      "  Added 2 rows for 'Production programming;' (out of 2 available)\n",
      "  Added 1 rows for 'Customer Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Document management;Workflow support & management;' (out of 1 available)\n",
      "  Added 3 rows for 'Automated Customer Statements;' (out of 6 available)\n",
      "  Added 3 rows for 'Service Order & Activation Management;' (out of 4 available)\n",
      "  Added 3 rows for 'Selling application;' (out of 4 available)\n",
      "  Added 3 rows for 'Capacity management;' (out of 7 available)\n",
      "  Added 3 rows for 'Mission-critical system;' (out of 5 available)\n",
      "  Added 2 rows for 'After sales parts contract management;' (out of 2 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Geographic or spatial information system;Online analysis and reporting;Stock control & order processing;Workflow support & management;' (out of 1 available)\n",
      "  Added 1 rows for 'Document management;Financial transaction process/accounting;Personal productivity (e.g. spreadsheet);Workflow support & management;Complex process control;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 3 rows for 'Car Database for factory;' (out of 3 available)\n",
      "  Added 1 rows for 'Business system;' (out of 1 available)\n",
      "  Added 1 rows for 'Track test management;' (out of 1 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Management or performance reporting;Customer billing;' (out of 1 available)\n",
      "  Added 1 rows for 'Job, case, incident, project management;Management or performance reporting;' (out of 1 available)\n",
      "  Added 2 rows for 'Mathematical modelling (finance or eng.);Online analysis and reporting;' (out of 2 available)\n",
      "  Added 1 rows for 'Application Security Control;' (out of 1 available)\n",
      "  Added 3 rows for 'Maintenance;' (out of 9 available)\n",
      "  Added 1 rows for 'After selling reporting;' (out of 1 available)\n",
      "  Added 1 rows for 'Follow up of the production in  factories;' (out of 1 available)\n",
      "  Added 1 rows for 'Purchaser performance management;' (out of 1 available)\n",
      "  Added 3 rows for 'Billing and ERP;' (out of 9 available)\n",
      "  Added 3 rows for 'Knowledge Based;' (out of 11 available)\n",
      "  Added 3 rows for 'Document management;Job, case, incident, project management;' (out of 3 available)\n",
      "  Added 1 rows for 'Selling programming;' (out of 1 available)\n",
      "  Added 3 rows for 'Business;Stock control & order processing;' (out of 8 available)\n",
      "  Added 1 rows for 'GPS Portal;' (out of 1 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;Logistic or supply planning & control;' (out of 1 available)\n",
      "  Added 1 rows for 'Monitoring of the factoring process;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue for IT products and IT services;' (out of 1 available)\n",
      "  Added 1 rows for 'Technical administrative system;' (out of 1 available)\n",
      "  Added 2 rows for 'Inventory gathering and Managing;' (out of 2 available)\n",
      "  Added 2 rows for 'Electronic Banking;' (out of 2 available)\n",
      "  Added 1 rows for 'New Screen Design;' (out of 1 available)\n",
      "  Added 1 rows for 'Parts Database;' (out of 1 available)\n",
      "  Added 1 rows for 'Geographic or spatial information system;Management or performance reporting;Telecom & network management;' (out of 1 available)\n",
      "  Added 1 rows for 'Services Selling;' (out of 1 available)\n",
      "  Added 1 rows for 'Pay;' (out of 1 available)\n",
      "  Added 1 rows for 'Insurance quotation;' (out of 1 available)\n",
      "  Added 1 rows for 'Retailler sells follow up;' (out of 1 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Document management;' (out of 3 available)\n",
      "  Added 3 rows for 'GEO Information Management;' (out of 10 available)\n",
      "  Added 3 rows for 'Mixed;' (out of 4 available)\n",
      "  Added 2 rows for 'Financial transaction processing & Accounting;' (out of 2 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;Stock control & order processing;' (out of 1 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Logistic or supply planning & control;Complex process control;' (out of 1 available)\n",
      "  Added 3 rows for 'Selling Organisation;' (out of 3 available)\n",
      "  Added 1 rows for 'Geographic or spatial information system;Complex process control;' (out of 1 available)\n",
      "  Added 1 rows for 'Process documentation;' (out of 1 available)\n",
      "  Added 3 rows for 'Operating system or software utility;' (out of 8 available)\n",
      "  Added 1 rows for 'Workflow support & management;Precedents System;' (out of 1 available)\n",
      "  Added 1 rows for 'European homologation management;' (out of 1 available)\n",
      "  Added 1 rows for 'Shrink-wrap;' (out of 1 available)\n",
      "  Added 1 rows for 'Document Management & Catalogue;' (out of 1 available)\n",
      "  Added 2 rows for 'Handling payment of social pensions within government;' (out of 2 available)\n",
      "  Added 1 rows for 'Operating system or software utility;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 3 rows for 'Complex process control;' (out of 30 available)\n",
      "  Added 1 rows for 'Pollution statistics;' (out of 1 available)\n",
      "  Added 1 rows for 'Document management;Operating system or software utility;' (out of 1 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;Document management;Trading;' (out of 1 available)\n",
      "  Added 1 rows for 'suppliers management;' (out of 1 available)\n",
      "  Added 1 rows for 'Factory change programming;' (out of 1 available)\n",
      "  Added 3 rows for 'Logistic or supply planning & control;Management or performance reporting;' (out of 4 available)\n",
      "  Added 1 rows for 'Management of parts buying;' (out of 1 available)\n",
      "  Added 1 rows for 'Management or performance reporting;Online analysis and reporting;Telecom & network management;' (out of 1 available)\n",
      "  Added 1 rows for 'Document management;Management or performance reporting;Online analysis and reporting;Workflow support & management;' (out of 1 available)\n",
      "  Added 1 rows for 'HR;' (out of 1 available)\n",
      "  Added 1 rows for 'Accounting of stock;' (out of 1 available)\n",
      "  Added 1 rows for 'Document management;Logistic or supply planning & control;Online analysis and reporting;Personal productivity (e.g. spreadsheet);' (out of 1 available)\n",
      "  Added 1 rows for 'Web based fullfilment tool for Advertising;' (out of 1 available)\n",
      "  Added 3 rows for 'Integration;' (out of 41 available)\n",
      "  Added 1 rows for 'Change Management Tool;' (out of 1 available)\n",
      "  Added 1 rows for 'Logistic or supply planning & control;Stock control & order processing;Complex process control;' (out of 1 available)\n",
      "  Added 1 rows for 'Forecastselling;' (out of 1 available)\n",
      "  Added 1 rows for 'CAD;' (out of 1 available)\n",
      "  Added 1 rows for 'Datawarehouse/ Business Intelligence;' (out of 1 available)\n",
      "  Added 1 rows for 'Product Order management;' (out of 1 available)\n",
      "  Added 1 rows for 'Administrative Support System;' (out of 1 available)\n",
      "  Added 1 rows for 'Optimisation of the production;' (out of 1 available)\n",
      "  Added 1 rows for 'Car test management;' (out of 1 available)\n",
      "  Added 1 rows for 'Tax Legislative;' (out of 1 available)\n",
      "  Added 1 rows for 'Mathematical modelling (finance or eng.);' (out of 1 available)\n",
      "  Added 1 rows for 'Central cmd./ctl of sensors;' (out of 1 available)\n",
      "  Added 3 rows for 'Course management system;Dynamic website;' (out of 5 available)\n",
      "  Added 2 rows for 'Healthcare;' (out of 2 available)\n",
      "  Added 3 rows for 'Office Automation;' (out of 3 available)\n",
      "  Added 1 rows for 'Geographic or spatial information system;Image, video or sound processing;Job, case, incident, project management;Online analysis and reporting;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Exchange system;' (out of 1 available)\n",
      "  Added 1 rows for 'Customer billing;e-commerce;' (out of 1 available)\n",
      "  Added 2 rows for 'Financial transaction process/accounting;Graphics & publishing tools or system;Management or performance reporting;Online analysis and reporting;Personal productivity (e.g. spreadsheet);' (out of 2 available)\n",
      "  Added 1 rows for 'training Management;' (out of 1 available)\n",
      "  Added 3 rows for 'Network Switch Provisioning;' (out of 7 available)\n",
      "  Added 1 rows for 'Artifical Intelligence based engine;' (out of 1 available)\n",
      "  Added 3 rows for 'Tools or system;' (out of 5 available)\n",
      "  Added 3 rows for 'relatively complex application;' (out of 154 available)\n",
      "  Added 1 rows for 'Simulator;' (out of 1 available)\n",
      "  Added 1 rows for 'Management or performance reporting;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Customer Data repository with applicatin interface;' (out of 1 available)\n",
      "  Added 3 rows for 'Purchasing;' (out of 4 available)\n",
      "  Added 1 rows for 'DSP;' (out of 1 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Online analysis and reporting;Electronic Data Interchange;' (out of 3 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Logistic or supply planning & control;' (out of 1 available)\n",
      "  Added 1 rows for 'Interface database;' (out of 1 available)\n",
      "  Added 2 rows for 'Packaging Visibility System;' (out of 2 available)\n",
      "  Added 1 rows for 'Management and follow up of the parts;' (out of 1 available)\n",
      "  Added 1 rows for 'Accounting system;' (out of 1 available)\n",
      "  Added 2 rows for 'web EC site;' (out of 2 available)\n",
      "  Added 1 rows for 'Printing Document Design;' (out of 1 available)\n",
      "  Added 3 rows for 'Geographic or spatial information system;' (out of 5 available)\n",
      "  Added 1 rows for 'Handling payment of social pensions in government;' (out of 1 available)\n",
      "  Added 3 rows for 'IT projet Management;' (out of 3 available)\n",
      "  Added 1 rows for 'Gaming & Wagering;' (out of 1 available)\n",
      "  Added 3 rows for 'Information systems;' (out of 5 available)\n",
      "  Added 1 rows for 'Access Control;' (out of 1 available)\n",
      "  Added 1 rows for 'Template for data-exchange;' (out of 1 available)\n",
      "  Added 2 rows for 'Quality of purchasing;' (out of 2 available)\n",
      "  Added 1 rows for 'Case management;' (out of 1 available)\n",
      "  Added 1 rows for 'Dynamic calculation accessory drive and distribution;' (out of 1 available)\n",
      "  Added 1 rows for 'Graphics & publishing tools or system;' (out of 1 available)\n",
      "  Added 2 rows for 'Simulation of the behaviour of vehicles on the road;' (out of 2 available)\n",
      "  Added 1 rows for 'Security;' (out of 1 available)\n",
      "  Added 2 rows for 'European Warranty Management;' (out of 2 available)\n",
      "  Added 2 rows for 'After sales Follow up;' (out of 2 available)\n",
      "  Added 1 rows for 'Document management;Image, video or sound processing;' (out of 1 available)\n",
      "  Added 1 rows for 'Supporting of the commercial network;' (out of 1 available)\n",
      "  Added 1 rows for 'Premium Paid Certificate;' (out of 1 available)\n",
      "  Added 1 rows for 'Central database;' (out of 1 available)\n",
      "  Added 2 rows for 'After Sales management Contract service;' (out of 2 available)\n",
      "  Added 3 rows for 'Image, video or sound processing;' (out of 3 available)\n",
      "  Added 3 rows for 'Job, case, incident, project management;Workflow support & management;' (out of 3 available)\n",
      "  Added 1 rows for 'Distribution;' (out of 1 available)\n",
      "  Added 1 rows for 'Support for parts documentation;' (out of 1 available)\n",
      "  Added 3 rows for 'Local;' (out of 8 available)\n",
      "  Added 1 rows for 'Advertising/Mailing Campaign;' (out of 1 available)\n",
      "  Added 2 rows for 'Personal productivity (e.g. spreadsheet);' (out of 2 available)\n",
      "  Added 3 rows for 'Billing;' (out of 22 available)\n",
      "  Added 1 rows for 'Internet Banking for personal customers;' (out of 1 available)\n",
      "  Added 2 rows for 'Database customers for Parts;' (out of 2 available)\n",
      "  Added 1 rows for 'Geographic Information System;' (out of 1 available)\n",
      "  Added 1 rows for 'Dealer network management;' (out of 1 available)\n",
      "  Added 1 rows for 'Management of customs activities;' (out of 1 available)\n",
      "  Added 3 rows for 'Sales contact management;' (out of 55 available)\n",
      "  Added 1 rows for 'Qualty Factory Reporting;' (out of 1 available)\n",
      "  Added 3 rows for 'Executive Information System;' (out of 28 available)\n",
      "  Added 1 rows for 'Stock control & order processing;Workflow support & management;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Process Control;Workflow support & management;The tool is Used By Employees of this Organization;' (out of 1 available)\n",
      "  Added 1 rows for 'Case Management Study;' (out of 1 available)\n",
      "  Added 1 rows for 'Insurance annities;Online user interface;' (out of 1 available)\n",
      "  Added 1 rows for 'Video Game;' (out of 1 available)\n",
      "  Added 2 rows for 'Car design;' (out of 2 available)\n",
      "  Added 1 rows for 'Operating system or software utility;Synchronization of Outlook and Application;' (out of 1 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Ordering;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Job, case, incident, project management;' (out of 1 available)\n",
      "  Added 1 rows for 'Management of selling conditions to society;' (out of 1 available)\n",
      "  Added 3 rows for 'Car Design;' (out of 9 available)\n",
      "  Added 3 rows for 'Data Warehouse system;' (out of 41 available)\n",
      "  Added 1 rows for 'Client/Server Customer Service application;' (out of 1 available)\n",
      "  Added 3 rows for 'Financial transaction process/accounting;Workflow support & management;' (out of 3 available)\n",
      "  Added 1 rows for 'Car Sales;' (out of 1 available)\n",
      "  Added 1 rows for 'Defect Tracking System;' (out of 1 available)\n",
      "  Added 1 rows for 'Stock factory management;' (out of 1 available)\n",
      "  Added 3 rows for 'Parts selling;' (out of 28 available)\n",
      "  Added 1 rows for 'Sales;' (out of 1 available)\n",
      "  Added 1 rows for 'Factory process follow up;' (out of 1 available)\n",
      "  Added 1 rows for 'Post exchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Infrastructure;' (out of 1 available)\n",
      "  Added 3 rows for 'Car selling;' (out of 3 available)\n",
      "  Added 2 rows for 'Parts Selling website;' (out of 2 available)\n",
      "  Added 1 rows for 'Software for machine control;Mathematical modelling (finance or eng.);' (out of 1 available)\n",
      "  Added 1 rows for 'Car electronic design;' (out of 1 available)\n",
      "  Added 3 rows for 'Software for machine control;' (out of 60 available)\n",
      "  Added 2 rows for 'Car Database;' (out of 2 available)\n",
      "  Added 2 rows for 'website;' (out of 2 available)\n",
      "  Added 3 rows for 'Unknown;' (out of 272 available)\n",
      "  Added 2 rows for 'Directory Assistance;' (out of 2 available)\n",
      "  Added 3 rows for 'Online. eSales;' (out of 87 available)\n",
      "  Added 2 rows for 'Cards and Payments;' (out of 2 available)\n",
      "  Added 1 rows for 'Company car management;' (out of 1 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Job, case, incident, project management;Management or performance reporting;Online analysis and reporting;Workflow support & management;' (out of 1 available)\n",
      "  Added 1 rows for 'Car pricing;' (out of 1 available)\n",
      "  Added 3 rows for 'Web-based application;' (out of 4 available)\n",
      "  Added 3 rows for 'Mobile Application;' (out of 6 available)\n",
      "  Added 3 rows for 'Logistic or supply planning & control;Management or performance reporting;Personal productivity (e.g. spreadsheet);Workflow support & management;' (out of 3 available)\n",
      "  Added 1 rows for 'Management of the centre activities;' (out of 1 available)\n",
      "  Added 1 rows for 'Immobility & Facilities Management;' (out of 1 available)\n",
      "  Added 3 rows for 'Business;Customer billing/relationship management;' (out of 24 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Management or performance reporting;' (out of 1 available)\n",
      "  Added 3 rows for 'Financial transaction process/accounting;' (out of 999 available)\n",
      "  Added 1 rows for 'Scientific;' (out of 1 available)\n",
      "  Added 3 rows for 'Office Automation System;' (out of 4 available)\n",
      "  Added 1 rows for 'e-commerce;' (out of 1 available)\n",
      "  Added 1 rows for 'Calculation and quotation of casualty insurance;' (out of 1 available)\n",
      "  Added 1 rows for 'Network Management;Migration tool;' (out of 1 available)\n",
      "  Added 1 rows for 'Web Content & Middleware;' (out of 1 available)\n",
      "  Added 1 rows for 'Identity Card Emission;Data or database management;' (out of 1 available)\n",
      "  Added 1 rows for 'Workflow support & management;Proposal creation and submission;' (out of 1 available)\n",
      "  Added 3 rows for 'Government;' (out of 11 available)\n",
      "  Added 3 rows for 'Ordering & provisioning system;' (out of 6 available)\n",
      "  Added 2 rows for 'Provider management;' (out of 2 available)\n",
      "  Added 1 rows for 'Parts logistic management;' (out of 1 available)\n",
      "  Added 3 rows for 'Logistic or supply planning & control;' (out of 37 available)\n",
      "  Added 3 rows for 'Production management;' (out of 12 available)\n",
      "  Added 1 rows for 'IT cost project management;' (out of 1 available)\n",
      "  Added 1 rows for 'Packaged software;' (out of 1 available)\n",
      "  Added 3 rows for 'Products management;' (out of 4 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Customer relationship management;' (out of 5 available)\n",
      "  Added 1 rows for 'Logistic or supply planning & control;Workflow support & management;' (out of 1 available)\n",
      "  Added 3 rows for 'Human Resources;' (out of 5 available)\n",
      "  Added 1 rows for 'Technical support for diagnostic and repair;' (out of 1 available)\n",
      "  Added 3 rows for 'Business;' (out of 3 available)\n",
      "  Added 1 rows for 'Training;' (out of 1 available)\n",
      "  Added 1 rows for 'Trading;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 3 rows for 'Embedded system/real-time application;' (out of 91 available)\n",
      "  Added 3 rows for 'Stock Management;' (out of 3 available)\n",
      "  Added 3 rows for 'Business;Workflow support & management;' (out of 3 available)\n",
      "  Added 3 rows for 'not recorded;' (out of 477 available)\n",
      "  Added 3 rows for 'MS Business Platform;' (out of 4 available)\n",
      "  Added 3 rows for 'Online analysis and reporting;Workflow support & management;' (out of 3 available)\n",
      "  Added 3 rows for 'Job, case, incident, project management;' (out of 15 available)\n",
      "  Added 3 rows for 'Company hierarchy and staff directory;' (out of 3 available)\n",
      "  Added 2 rows for 'Network Management;' (out of 2 available)\n",
      "  Added 1 rows for 'Office Information System;Case Management System;' (out of 1 available)\n",
      "  Added 1 rows for 'Job, case, incident, project management;Software for communities to support administration;' (out of 1 available)\n",
      "  Added 1 rows for 'Geographic or spatial information system;Online analysis and reporting;' (out of 1 available)\n",
      "  Added 1 rows for 'Taxation;' (out of 1 available)\n",
      "  Added 3 rows for 'Web-based App. DOTNet;' (out of 4 available)\n",
      "  Added 1 rows for 'Operating system or software utility;Workflow support & management;' (out of 1 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Workflow support & management;' (out of 5 available)\n",
      "  Added 1 rows for 'Cost Computing;' (out of 1 available)\n",
      "  Added 3 rows for 'Personnel system;' (out of 16 available)\n",
      "  Added 2 rows for 'Factory reporting;' (out of 2 available)\n",
      "  Added 3 rows for 'Remote Banking;' (out of 3 available)\n",
      "  Added 1 rows for 'For credit collection;' (out of 1 available)\n",
      "  Added 1 rows for 'Mathematical modelling (finance or engineering);' (out of 1 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;Financial transaction process/accounting;Online analysis and reporting;Trading;Workflow support & management;Complex process control;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 3 rows for 'Document management;Management or performance reporting;' (out of 4 available)\n",
      "  Added 1 rows for 'Contract management After Sales;' (out of 1 available)\n",
      "  Added 3 rows for 'Cars documentation;' (out of 3 available)\n",
      "  Added 3 rows for 'Financial transaction process/accounting;Data Warehouse;' (out of 46 available)\n",
      "  Added 2 rows for 'Decision Support System;Management Information System;' (out of 2 available)\n",
      "  Added 2 rows for 'Idea/Patent Information System;' (out of 2 available)\n",
      "  Added 1 rows for 'Interactive Voice Response;' (out of 1 available)\n",
      "  Added 1 rows for 'Protocol in Building automation;Protocol Enhancement;' (out of 1 available)\n",
      "  Added 1 rows for 'Database  Parts;' (out of 1 available)\n",
      "  Added 3 rows for 'Broadband application;' (out of 3 available)\n",
      "  Added 2 rows for 'Car production;' (out of 2 available)\n",
      "  Added 1 rows for 'Military;' (out of 1 available)\n",
      "  Added 1 rows for 'Project management;' (out of 1 available)\n",
      "  Added 1 rows for 'Business enabling service;' (out of 1 available)\n",
      "  Added 1 rows for 'Extranet application;' (out of 1 available)\n",
      "  Added 3 rows for 'Embedded Systems;' (out of 17 available)\n",
      "  Added 3 rows for 'Cost analysis;' (out of 3 available)\n",
      "  Added 2 rows for 'diagnostic tools;' (out of 2 available)\n",
      "  Added 1 rows for 'Workplace Savings;' (out of 1 available)\n",
      "  Added 1 rows for 'Device or interface driver;Financial transaction process/accounting;Online analysis and reporting;Complex process control;' (out of 1 available)\n",
      "  Added 1 rows for 'Document management;Logistic or supply planning & control;Online analysis and reporting;Personal productivity (e.g. spreadsheet);Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 3 rows for 'Transaction/Production System;' (out of 497 available)\n",
      "  Added 3 rows for 'Software development tool;' (out of 6 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Workflow support & management;Electronic Data Interchange;' (out of 4 available)\n",
      "  Added 3 rows for 'After sales Parts documentation;' (out of 6 available)\n",
      "  Added 3 rows for 'Business;Network Management;' (out of 8 available)\n",
      "  Added 1 rows for 'Type 1 Function Point Counting Tool;' (out of 1 available)\n",
      "  Added 3 rows for 'Logistic indicators;' (out of 3 available)\n",
      "  Added 1 rows for 'Communication systrem;' (out of 1 available)\n",
      "  Added 1 rows for 'Online analysis and reporting;Software development tool;' (out of 1 available)\n",
      "  Added 2 rows for 'Quality management;' (out of 2 available)\n",
      "  Added 2 rows for 'Order Processing System;' (out of 2 available)\n",
      "  Added 1 rows for 'Management or performance reporting;Workflow support & management;' (out of 1 available)\n",
      "  Added 2 rows for 'Air Traffic Management;' (out of 2 available)\n",
      "  Added 1 rows for 'Technical Information System;' (out of 1 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;Trading;' (out of 1 available)\n",
      "  Added 3 rows for 'Financial application area;' (out of 142 available)\n",
      "  Added 1 rows for 'Online Insurance product comparision tool;' (out of 1 available)\n",
      "  Added 2 rows for 'Back-Office;' (out of 2 available)\n",
      "  Added 3 rows for 'Parts documentation;' (out of 9 available)\n",
      "  Added 1 rows for 'Workflow support & management;Ordering tool enhancements for telecom components;' (out of 1 available)\n",
      "  Added 3 rows for 'Factory's process management;' (out of 6 available)\n",
      "  Added 1 rows for 'Network Management;Telecom and Networking;' (out of 1 available)\n",
      "  Added 2 rows for 'Client-Server Application;' (out of 2 available)\n",
      "  Added 1 rows for 'Retailer sales reporting;' (out of 1 available)\n",
      "  Added 1 rows for 'Robot;' (out of 1 available)\n",
      "  Added 1 rows for 'Transaction/Production System;EDI front-end for order processing system;' (out of 1 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;Financial transaction process/accounting;Electronic Data Interchange;' (out of 1 available)\n",
      "\n",
      "Sampling for column 'Project_PRF_Development Type'...\n",
      "  Added 1 rows for 'Porting' (out of 1 available)\n",
      "  Added 1 rows for 'POC' (out of 1 available)\n",
      "  Added 3 rows for 'Other' (out of 4 available)\n",
      "  Added 3 rows for 'Not Defined' (out of 15 available)\n",
      "\n",
      "Sampling for column 'Tech_TF_Development Platform'...\n",
      "  Added 1 rows for 'Hand Held' (out of 1 available)\n",
      "  Added 3 rows for 'MF' (out of 1849 available)\n",
      "\n",
      "Sampling for column 'Tech_TF_Language Type'...\n",
      "  Added 3 rows for 'ApG' (out of 175 available)\n",
      "  Added 3 rows for '2GL' (out of 22 available)\n",
      "  Added 1 rows for 'APG' (out of 1 available)\n",
      "\n",
      "Sampling for column 'Tech_TF_Primary Programming Language'...\n",
      "  Added 1 rows for 'Unix' (out of 1 available)\n",
      "  Added 3 rows for 'VisualFoxPro' (out of 3 available)\n",
      "  Added 3 rows for 'ColdFusion' (out of 8 available)\n",
      "  Added 2 rows for 'Data base language' (out of 2 available)\n",
      "  Added 3 rows for 'Access' (out of 56 available)\n",
      "  Added 1 rows for 'BEA Weblogic' (out of 1 available)\n",
      "  Added 3 rows for 'ASAP' (out of 4 available)\n",
      "  Added 3 rows for 'Centura' (out of 3 available)\n",
      "  Added 1 rows for 'NCR teradata scripting' (out of 1 available)\n",
      "  Added 3 rows for 'VisualAge' (out of 5 available)\n",
      "  Added 3 rows for 'Perl' (out of 3 available)\n",
      "  Added 1 rows for 'IEF' (out of 1 available)\n",
      "  Added 2 rows for 'MAPPER' (out of 2 available)\n",
      "  Added 1 rows for 'BO' (out of 1 available)\n",
      "  Added 3 rows for 'Adobe Flex' (out of 8 available)\n",
      "  Added 1 rows for 'Enablon' (out of 1 available)\n",
      "  Added 3 rows for 'CSP' (out of 10 available)\n",
      "  Added 3 rows for 'C/AL' (out of 3 available)\n",
      "  Added 1 rows for 'Informatica PowerCenter' (out of 1 available)\n",
      "  Added 3 rows for 'IDEAL' (out of 6 available)\n",
      "  Added 1 rows for 'Caa' (out of 1 available)\n",
      "  Added 3 rows for 'C' (out of 309 available)\n",
      "  Added 3 rows for 'PL/SQL' (out of 92 available)\n",
      "  Added 2 rows for 'ABF' (out of 2 available)\n",
      "  Added 1 rows for 'LEX' (out of 1 available)\n",
      "  Added 3 rows for 'DELPHI' (out of 66 available)\n",
      "  Added 1 rows for 'COGNOS' (out of 1 available)\n",
      "  Added 1 rows for 'LISP' (out of 1 available)\n",
      "  Added 3 rows for 'ASP.Net' (out of 15 available)\n",
      "  Added 3 rows for 'Smalltalk' (out of 16 available)\n",
      "  Added 3 rows for 'Lotus Notes' (out of 30 available)\n",
      "  Added 2 rows for 'Periproducer' (out of 2 available)\n",
      "  Added 1 rows for 'PowerPlay' (out of 1 available)\n",
      "  Added 3 rows for 'BPM' (out of 7 available)\n",
      "  Added 1 rows for 'AB INITIO' (out of 1 available)\n",
      "  Added 1 rows for 'A:G' (out of 1 available)\n",
      "  Added 3 rows for 'OutlookVBA' (out of 4 available)\n",
      "  Added 3 rows for 'RPL' (out of 5 available)\n",
      "  Added 1 rows for 'Must Modeller' (out of 1 available)\n",
      "  Added 3 rows for 'FORTRAN' (out of 6 available)\n",
      "  Added 3 rows for 'RALLY' (out of 6 available)\n",
      "  Added 3 rows for 'Siebel' (out of 37 available)\n",
      "  Added 3 rows for 'NATURAL' (out of 102 available)\n",
      "  Added 1 rows for 'Pega Workflows' (out of 1 available)\n",
      "  Added 1 rows for 'Huron/Object Star' (out of 1 available)\n",
      "  Added 2 rows for 'DRIFT' (out of 2 available)\n",
      "  Added 1 rows for 'SLEL' (out of 1 available)\n",
      "  Added 3 rows for 'INGRES' (out of 6 available)\n",
      "  Added 3 rows for 'ADS/Online' (out of 7 available)\n",
      "  Added 2 rows for 'SAPIENS' (out of 2 available)\n",
      "  Added 2 rows for 'iPlanet Netscape Application Server' (out of 2 available)\n",
      "  Added 1 rows for 'gcc' (out of 1 available)\n",
      "  Added 1 rows for 'BRE' (out of 1 available)\n",
      "  Added 1 rows for 'Jam' (out of 1 available)\n",
      "  Added 3 rows for 'IIS' (out of 6 available)\n",
      "  Added 1 rows for 'Spreadsheet' (out of 1 available)\n",
      "  Added 3 rows for 'AppBuilder' (out of 5 available)\n",
      "  Added 3 rows for 'PowerBuilder' (out of 47 available)\n",
      "  Added 3 rows for 'Visual C++' (out of 30 available)\n",
      "  Added 1 rows for 'ACCEL' (out of 1 available)\n",
      "  Added 3 rows for 'Datastage' (out of 9 available)\n",
      "  Added 3 rows for 'XML' (out of 3 available)\n",
      "  Added 3 rows for 'COOL:Gen' (out of 109 available)\n",
      "  Added 2 rows for 'STAFFWARE' (out of 2 available)\n",
      "  Added 3 rows for 'Visual Basic' (out of 460 available)\n",
      "  Added 3 rows for 'SQL' (out of 150 available)\n",
      "  Added 3 rows for 'TIBCO' (out of 44 available)\n",
      "  Added 1 rows for 'Visual FoxPro' (out of 1 available)\n",
      "  Added 3 rows for 'Assembler' (out of 17 available)\n",
      "  Added 3 rows for 'ASP' (out of 46 available)\n",
      "  Added 3 rows for 'PHP' (out of 36 available)\n",
      "  Added 3 rows for 'Formspath' (out of 3 available)\n",
      "  Added 3 rows for 'Object oriented language' (out of 3 available)\n",
      "  Added 3 rows for 'CLIPPER' (out of 9 available)\n",
      "  Added 1 rows for 'Express' (out of 1 available)\n",
      "  Added 3 rows for 'RPG' (out of 14 available)\n",
      "  Added 3 rows for 'SAS' (out of 6 available)\n",
      "  Added 3 rows for 'iOS' (out of 6 available)\n",
      "  Added 1 rows for 'Mendix' (out of 1 available)\n",
      "  Added 3 rows for 'Shell' (out of 47 available)\n",
      "  Added 3 rows for 'HLL/WB' (out of 5 available)\n",
      "  Added 2 rows for 'PYTHON' (out of 2 available)\n",
      "  Added 3 rows for 'FOCUS' (out of 7 available)\n",
      "  Added 3 rows for 'Unix Shell' (out of 14 available)\n",
      "  Added 3 rows for 'TELON' (out of 34 available)\n",
      "  Added 3 rows for 'Shell, C' (out of 5 available)\n",
      "  Added 1 rows for 'ADO.Net' (out of 1 available)\n",
      "  Added 3 rows for 'PERIPHONICS' (out of 6 available)\n",
      "  Added 1 rows for 'MANTIS' (out of 1 available)\n",
      "  Added 3 rows for 'UNIFACE' (out of 5 available)\n",
      "  Added 1 rows for 'MS-Navision Properitory Language' (out of 1 available)\n",
      "  Added 3 rows for 'Pro*C' (out of 11 available)\n",
      "  Added 1 rows for 'Jdeveloper' (out of 1 available)\n",
      "  Added 1 rows for 'ARBOR/BP' (out of 1 available)\n",
      "  Added 3 rows for 'EASYTRIEVE' (out of 15 available)\n",
      "  Added 1 rows for 'Brightware proprietary' (out of 1 available)\n",
      "  Added 1 rows for 'Azure' (out of 1 available)\n",
      "  Added 1 rows for 'IBM WTX' (out of 1 available)\n",
      "  Added 1 rows for 'Magic' (out of 1 available)\n",
      "  Added 3 rows for 'HPS' (out of 14 available)\n",
      "  Added 3 rows for 'BASIC' (out of 4 available)\n",
      "  Added 1 rows for 'XGML' (out of 1 available)\n",
      "  Added 3 rows for 'Ada' (out of 3 available)\n",
      "  Added 1 rows for 'EJB' (out of 1 available)\n",
      "  Added 3 rows for 'Visual Studio .Net' (out of 3 available)\n",
      "  Added 3 rows for 'MATLAB' (out of 8 available)\n",
      "  Added 3 rows for 'SLOGAN' (out of 7 available)\n",
      "  Added 3 rows for 'APPS' (out of 4 available)\n",
      "  Added 3 rows for 'CICS' (out of 4 available)\n",
      "  Added 3 rows for 'Script Language' (out of 9 available)\n",
      "  Added 3 rows for 'PASCAL' (out of 8 available)\n",
      "  Added 3 rows for 'COBOL' (out of 997 available)\n",
      "  Added 1 rows for 'Delphi' (out of 1 available)\n",
      "  Added 3 rows for 'Upfront' (out of 5 available)\n",
      "  Added 1 rows for 'TNSDL' (out of 1 available)\n",
      "  Added 1 rows for 'Doc1 Designer (Entorno visual)' (out of 1 available)\n",
      "  Added 1 rows for 'J2EE' (out of 1 available)\n",
      "  Added 1 rows for 'REXX' (out of 1 available)\n",
      "  Added 3 rows for 'HTML' (out of 16 available)\n",
      "\n",
      "Sampling for column 'Project_PRF_Relative Size'...\n",
      "  Added 3 rows for 'XXL' (out of 12 available)\n",
      "  Added 2 rows for 'XXXL' (out of 2 available)\n",
      "\n",
      "Sampling for column 'Project_PRF_Team Size Group'...\n",
      "  Added 3 rows for '31-40' (out of 99 available)\n",
      "  Added 3 rows for '15-20' (out of 168 available)\n",
      "  Added 3 rows for '91-100' (out of 14 available)\n",
      "  Added 3 rows for '101+' (out of 54 available)\n",
      "  Added 3 rows for '71-80' (out of 24 available)\n",
      "  Added 3 rows for '81-90' (out of 27 available)\n",
      "  Added 3 rows for '51-60' (out of 39 available)\n",
      "\n",
      "Sampling for column 'Project_PRF_CASE Tool Used'...\n",
      "  Added 3 rows for 'Don't Know' (out of 351 available)\n",
      "\n",
      "Sampling for column 'Process_PMF_Development Methodologies'...\n",
      "  Added 1 rows for 'Joint Application Development (JAD);Timeboxing;' (out of 1 available)\n",
      "  Added 3 rows for 'Joint Application Development (JAD);Rapid Application Development (RAD);' (out of 24 available)\n",
      "  Added 1 rows for 'IT Unified Process (ITUP);' (out of 1 available)\n",
      "  Added 3 rows for 'Multifunctional Teams;Rapid Application Development (RAD);' (out of 6 available)\n",
      "  Added 3 rows for 'Waterfall (incl Linear Processing & SSADM);' (out of 2201 available)\n",
      "  Added 3 rows for 'Joint Application Development (JAD);Multifunctional Teams;' (out of 33 available)\n",
      "  Added 1 rows for 'Interactive;' (out of 1 available)\n",
      "  Added 3 rows for 'Multifunctional Teams;' (out of 74 available)\n",
      "  Added 1 rows for 'Joint Application Development (JAD);Multifunctional Teams;Timeboxing;' (out of 1 available)\n",
      "  Added 2 rows for 'Multifunctional Teams;Unified Process;' (out of 2 available)\n",
      "  Added 3 rows for 'OCE;' (out of 3 available)\n",
      "  Added 3 rows for 'Joint Application Development (JAD);Rapid Application Development (RAD);Timeboxing;' (out of 3 available)\n",
      "  Added 3 rows for 'Unified Process;' (out of 6 available)\n",
      "  Added 1 rows for 'Personal Software Process (PSP);' (out of 1 available)\n",
      "  Added 3 rows for 'Joint Application Development (JAD);Multifunctional Teams;Rapid Application Development (RAD);Timeboxing;' (out of 6 available)\n",
      "  Added 3 rows for 'Timeboxing;' (out of 20 available)\n",
      "  Added 3 rows for 'Joint Application Development (JAD);Multifunctional Teams;Rapid Application Development (RAD);' (out of 4 available)\n",
      "  Added 2 rows for 'Rapid Application Development (RAD);Timeboxing;' (out of 2 available)\n",
      "  Added 3 rows for 'Rapid Application Development (RAD);' (out of 106 available)\n",
      "  Added 3 rows for 'Iterative;' (out of 3 available)\n",
      "  Added 1 rows for 'Extreme Programming (XP);' (out of 1 available)\n",
      "  Added 1 rows for 'Multifunctional Teams;Rapid Application Development (RAD);Timeboxing;' (out of 1 available)\n",
      "  Added 1 rows for 'Scrum;' (out of 1 available)\n",
      "  Added 3 rows for 'Multifunctional Teams;Timeboxing;' (out of 4 available)\n",
      "  Added 3 rows for 'Incremental;' (out of 31 available)\n",
      "  Added 3 rows for 'Joint Application Development (JAD);' (out of 79 available)\n",
      "  Added 2 rows for 'Lean;' (out of 2 available)\n",
      "  Added 3 rows for 'Multifunctional Teams;Waterfall (incl Linear Processing & SSADM);' (out of 5 available)\n",
      "  Added 3 rows for 'Personal Software Process (PSP);Unified Process;' (out of 5 available)\n",
      "  Added 3 rows for 'Spiral;' (out of 4 available)\n",
      "  Added 1 rows for 'Iterative;Unified Process;' (out of 1 available)\n",
      "\n",
      "Sampling for column 'Tech_TF_Architecture'...\n",
      "  Added 3 rows for 'Stand-alone' (out of 14 available)\n",
      "  Added 3 rows for 'Multi-tier with web interface' (out of 25 available)\n",
      "  Added 3 rows for 'Multi-tier' (out of 540 available)\n",
      "  Added 3 rows for 'Multi-tier / Client server' (out of 276 available)\n",
      "\n",
      "Sampling for column 'Tech_TF_Client_Server'...\n",
      "  Added 3 rows for 'Not Applicable' (out of 7 available)\n",
      "  Added 3 rows for 'Don't Know' (out of 342 available)\n",
      "\n",
      "Sampling for column 'Tech_TF_Client_Roles'...\n",
      "  Added 3 rows for 'Data retrieval & presentation;Web/HTML browser;' (out of 6 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;' (out of 21 available)\n",
      "  Added 1 rows for 'HandHeld Device;' (out of 1 available)\n",
      "  Added 3 rows for 'Data entry & validation;Web/HTML browser;' (out of 3 available)\n",
      "  Added 1 rows for 'Data entry & validation;Data retrieval & presentation;Web/HTML browser;Web public interface;' (out of 1 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Data retrieval & presentation;' (out of 5 available)\n",
      "  Added 1 rows for 'Device/equipment interface;' (out of 1 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;' (out of 3 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;' (out of 13 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;Web public interface;' (out of 1 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Data entry & validation;Web/HTML browser;' (out of 3 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;Security;' (out of 1 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;Web public interface;Security;' (out of 1 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Web/HTML browser;' (out of 4 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Data entry & validation;' (out of 7 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Device/equipment interface;' (out of 1 available)\n",
      "  Added 1 rows for 'Data entry & validation;' (out of 1 available)\n",
      "  Added 3 rows for 'Business logic or rule processing;Web/HTML browser;' (out of 3 available)\n",
      "  Added 1 rows for 'Query and update data;' (out of 1 available)\n",
      "  Added 1 rows for 'Business logic or rule processing;Data retrieval & presentation;Device/equipment interface;Security;' (out of 1 available)\n",
      "  Added 2 rows for 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Device/equipment interface;Web/HTML browser;' (out of 2 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Data retrieval & presentation;Web/HTML browser;' (out of 6 available)\n",
      "  Added 3 rows for 'Business logic or rule processing;Data retrieval & presentation;' (out of 9 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Data retrieval & presentation;Web/HTML browser;Security;' (out of 3 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;' (out of 6 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Device/equipment interface;Terminal emulation;Provide some calculations;' (out of 1 available)\n",
      "  Added 1 rows for 'Business logic or rule processing;Data retrieval & presentation;Web public interface;' (out of 1 available)\n",
      "  Added 3 rows for 'Data entry & validation;Data retrieval & presentation;' (out of 11 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Data retrieval & presentation;Web/HTML browser;Web public interface;' (out of 1 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Business logic or rule processing;Web/HTML browser;' (out of 3 available)\n",
      "  Added 3 rows for 'mobile app;' (out of 6 available)\n",
      "  Added 1 rows for 'Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Data extraction, transformation and loading;' (out of 1 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Business logic or rule processing;Data retrieval & presentation;' (out of 1 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Device/equipment interface;Web/HTML browser;' (out of 1 available)\n",
      "  Added 3 rows for 'Web/HTML browser;Web public interface;' (out of 9 available)\n",
      "  Added 3 rows for 'front-end;' (out of 3 available)\n",
      "  Added 3 rows for 'Data retrieval & presentation;Web/HTML browser;Security;' (out of 3 available)\n",
      "  Added 1 rows for 'Business logic or rule processing;Data retrieval & presentation;Web/HTML browser;' (out of 1 available)\n",
      "  Added 3 rows for 'Business logic or rule processing;' (out of 5 available)\n",
      "  Added 3 rows for 'Terminal emulation;' (out of 4 available)\n",
      "  Added 3 rows for 'Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;' (out of 6 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Business logic or rule processing;Data retrieval & presentation;Device/equipment interface;' (out of 1 available)\n",
      "  Added 3 rows for 'Business logic or rule processing;Data entry & validation;' (out of 3 available)\n",
      "  Added 3 rows for 'Data entry & validation;Device/equipment interface;Web/HTML browser;' (out of 12 available)\n",
      "  Added 2 rows for 'Run a computer-human interface;Data entry & validation;Device/equipment interface;Web/HTML browser;' (out of 2 available)\n",
      "  Added 1 rows for 'Business logic or rule processing;Data entry & validation;Device/equipment interface;Terminal emulation;' (out of 1 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Web/HTML browser;' (out of 1 available)\n",
      "  Added 1 rows for 'Business logic or rule processing;Data entry & validation;Device/equipment interface;Web/HTML browser;' (out of 1 available)\n",
      "  Added 3 rows for 'Data retrieval & presentation;' (out of 14 available)\n",
      "  Added 1 rows for 'Business logic or rule processing;Data retrieval & presentation;Web/HTML browser;Web public interface;' (out of 1 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Business logic or rule processing;' (out of 1 available)\n",
      "\n",
      "Sampling for column 'Tech_TF_Server_Roles'...\n",
      "  Added 1 rows for 'Browser/server;Database server;FTP server;HTML/web server;Multi-user legacy application;Security/authentication;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;Multi-user legacy application;Object/component server;' (out of 3 available)\n",
      "  Added 1 rows for 'Database server;Mail server;Security/authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Object/component server;Business logic;' (out of 1 available)\n",
      "  Added 1 rows for 'FTP server;HTML/web server;Multi-user legacy application;' (out of 1 available)\n",
      "  Added 2 rows for 'Database server;Messaging server;Security/authentication;' (out of 2 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;HTML/web server;Mail server;' (out of 1 available)\n",
      "  Added 2 rows for 'Database server;FTP server;Messaging server;' (out of 2 available)\n",
      "  Added 3 rows for 'Messaging server;' (out of 3 available)\n",
      "  Added 1 rows for 'File &/or print server;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Security/authentication;Exchange Server;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;Multi-user legacy application;' (out of 8 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;FTP server;HTML/web server;Mail server;Multi-user legacy application;Object/component server;Security/authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;Security/authentication;Delivery server for end products, f.e.Cognos Cubes;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;Object/component server;' (out of 7 available)\n",
      "  Added 2 rows for 'Mail server;Messaging server;' (out of 2 available)\n",
      "  Added 2 rows for 'Object/component server;' (out of 2 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;FTP server;Mail server;Security/authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Multi-user legacy application;Object/component server;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;File &/or print server;Object/component server;Security/authentication;' (out of 8 available)\n",
      "  Added 1 rows for 'Database server;FTP server;Messaging server;Security/authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'HTML/web server;Messaging server;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;HTML/web server;Messaging server;Security/authentication;' (out of 3 available)\n",
      "  Added 3 rows for 'Database server;File &/or print server;Security/authentication;' (out of 6 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;Mail server;Messaging server;Security/authentication;' (out of 1 available)\n",
      "  Added 2 rows for 'Database server;FTP server;HTML/web server;Object/component server;' (out of 2 available)\n",
      "  Added 3 rows for 'Database server;Multi-user legacy application;Security/authentication;' (out of 6 available)\n",
      "  Added 2 rows for 'Database server;HTML/web server;Mail server;Object/component server;Security/authentication;' (out of 2 available)\n",
      "  Added 1 rows for 'FTP server;HTML/web server;Multi-user legacy application;Security/authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'Mail server;Multi-user legacy application;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Multi-user legacy application;Security/authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Mail server;WAS Server;' (out of 1 available)\n",
      "  Added 2 rows for 'Database server;File &/or print server;HTML/web server;Security/authentication;' (out of 2 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Mail server;Object/component server;' (out of 1 available)\n",
      "  Added 2 rows for 'Database server;HTML/web server;Multi-user legacy application;Object/component server;Security/authentication;' (out of 2 available)\n",
      "  Added 1 rows for 'HTML/web server;Mail server;Security/authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;FTP server;HTML/web server;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;Security/authentication;Law-based business logic;' (out of 1 available)\n",
      "  Added 1 rows for 'HTML/web server;virtualisation server API;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;HTML/web server;Mail server;Messaging server;Object/component server;Security/authentication;' (out of 1 available)\n",
      "  Added 3 rows for 'webserver;' (out of 3 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;HTML/web server;Mail server;Messaging server;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;Security/authentication;Data entry & validation, business logic;' (out of 1 available)\n",
      "  Added 2 rows for 'Database server;FTP server;HTML/web server;Mail server;' (out of 2 available)\n",
      "  Added 1 rows for 'Database server;FTP server;Security/authentication;' (out of 1 available)\n",
      "  Added 2 rows for 'Database server;HTML/web server;Mail server;' (out of 2 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Messaging server;Object/component server;Security/authentication;Application Server;' (out of 1 available)\n",
      "  Added 2 rows for 'Database server;File &/or print server;HTML/web server;Object/component server;Security/authentication;' (out of 2 available)\n",
      "  Added 1 rows for 'Database server;Object/component server;Security/authentication;Business logic;' (out of 1 available)\n",
      "  Added 1 rows for 'HTML/web server;Object/component server;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;HTML/web server;' (out of 1 available)\n",
      "  Added 3 rows for 'HTML/web server;' (out of 3 available)\n",
      "  Added 3 rows for 'Database server;Object/component server;Security/authentication;' (out of 4 available)\n",
      "  Added 3 rows for 'Database server;FTP server;Messaging server;Object/component server;' (out of 5 available)\n",
      "  Added 3 rows for 'Database server;File &/or print server;HTML/web server;Messaging server;Multi-user legacy application;' (out of 7 available)\n",
      "  Added 3 rows for 'Database server;Security/authentication;' (out of 26 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;FTP server;Multi-user legacy application;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;Mail server;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;File &/or print server;Multi-user legacy application;Security/authentication;' (out of 4 available)\n",
      "  Added 3 rows for 'Database server;HTML/web server;Security/authentication;' (out of 19 available)\n",
      "  Added 3 rows for 'back-end;' (out of 6 available)\n",
      "  Added 3 rows for 'Database server;FTP server;HTML/web server;Security/authentication;' (out of 3 available)\n",
      "  Added 3 rows for 'Database server;HTML/web server;Security/authentication;ETL Server;' (out of 3 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Mail server;Multi-user legacy application;Object/component server;Security/authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'Multi-user legacy application;Security/authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'FTP server;Messaging server;Object/component server;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Messaging server;Object/component server;Security/authentication;DR;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;Security/authentication;Business logic;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;File &/or print server;' (out of 4 available)\n",
      "  Added 3 rows for 'Database server;HTML/web server;Object/component server;' (out of 6 available)\n",
      "  Added 1 rows for 'Database server;FTP server;HTML/web server;Object/component server;Security/authentication;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;FTP server;HTML/web server;Mail server;Security/authentication;' (out of 14 available)\n",
      "  Added 3 rows for 'Database server;FTP server;HTML/web server;Mail server;Messaging server;Object/component server;Security/authentication;' (out of 3 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Object/component server;Security/authentication;' (out of 1 available)\n",
      "\n",
      "Sampling for column 'Tech_TF_Type_of_Server'...\n",
      "  Added 3 rows for 'LAN Based;' (out of 59 available)\n",
      "  Added 3 rows for 'Multi-tier with web public interface;' (out of 24 available)\n",
      "  Added 3 rows for 'Stand alone;' (out of 21 available)\n",
      "  Added 3 rows for 'Mainframe;' (out of 92 available)\n",
      "  Added 3 rows for 'Unix;' (out of 93 available)\n",
      "  Added 3 rows for 'back-end;' (out of 6 available)\n",
      "  Added 3 rows for 'Client server;' (out of 294 available)\n",
      "  Added 3 rows for 'Proprietary Midrange;' (out of 20 available)\n",
      "  Added 3 rows for 'webserver;' (out of 3 available)\n",
      "\n",
      "Sampling for column 'Tech_TF_Client/Server_Description'...\n",
      "  Added 3 rows for 'Client Server;' (out of 236 available)\n",
      "  Added 3 rows for 'Client: presentation, processing, data;' (out of 17 available)\n",
      "  Added 3 rows for 'Embedded;' (out of 3 available)\n",
      "  Added 3 rows for 'Presentation & Logic on server;' (out of 6 available)\n",
      "  Added 1 rows for 'Client presentation & processing, data on server;' (out of 1 available)\n",
      "  Added 1 rows for 'not assessed;' (out of 1 available)\n",
      "  Added 2 rows for '25%;' (out of 2 available)\n",
      "  Added 3 rows for 'Client: presentation, processing;' (out of 66 available)\n",
      "  Added 2 rows for '20%;' (out of 2 available)\n",
      "  Added 1 rows for '50%;' (out of 1 available)\n",
      "  Added 3 rows for 'Client: presentation; Server: processing;' (out of 93 available)\n",
      "  Added 1 rows for 'Client: presentation, processing; Server: data;' (out of 1 available)\n",
      "  Added 1 rows for 'Client-server Architecture;Browser-server Architecture;' (out of 1 available)\n",
      "  Added 3 rows for 'Unknown;' (out of 3 available)\n",
      "  Added 3 rows for '100%;' (out of 3 available)\n",
      "  Added 3 rows for 'C/S;' (out of 301 available)\n",
      "  Added 3 rows for 'Browser-server Architecture;' (out of 34 available)\n",
      "  Added 1 rows for 'Client-server Architecture/P2P;' (out of 1 available)\n",
      "  Added 3 rows for 'Web;' (out of 193 available)\n",
      "  Added 3 rows for 'Client-server Architecture;' (out of 11 available)\n",
      "  Added 1 rows for 'Presentation and logic on client;' (out of 1 available)\n",
      "  Added 1 rows for '90%;' (out of 1 available)\n",
      "  Added 2 rows for '30%;' (out of 2 available)\n",
      "  Added 1 rows for 'Dynamic Link Library;' (out of 1 available)\n",
      "  Added 2 rows for '10%;' (out of 2 available)\n",
      "  Added 3 rows for 'Stand-alone;' (out of 9 available)\n",
      "\n",
      "Sampling for column 'Tech_TF_Web_Development'...\n",
      "  Added 2 rows for 'Web?' (out of 2 available)\n",
      "\n",
      "Sampling for column 'Tech_TF_DBMS_Used'...\n",
      "  Added 3 rows for 'No' (out of 56 available)\n",
      "\n",
      "Sampling for column 'Tech_TF_Tools_Used'...\n",
      "  Added 3 rows for '8' (out of 73 available)\n",
      "  Added 3 rows for '10' (out of 7 available)\n",
      "  Added 1 rows for '12' (out of 1 available)\n",
      "  Added 1 rows for '13' (out of 1 available)\n",
      "\n",
      "Sampling for column 'People_PRF_Project_user_involvement'...\n",
      "  Added 2 rows for 'Best' (out of 2 available)\n",
      "  Added 3 rows for 'No' (out of 86 available)\n",
      "  Added 1 rows for 'Low' (out of 1 available)\n",
      "  Added 3 rows for 'Yes' (out of 509 available)\n",
      "  Added 3 rows for 'Don't Know' (out of 168 available)\n",
      "\n",
      "Sampling for column 'People_PRF_BA_team_experience_less_than_1_yr'...\n",
      "  Added 3 rows for '4.0' (out of 24 available)\n",
      "  Added 3 rows for '7.0' (out of 8 available)\n",
      "  Added 3 rows for '9.0' (out of 5 available)\n",
      "  Added 1 rows for '10.0' (out of 1 available)\n",
      "  Added 2 rows for '13.0' (out of 2 available)\n",
      "  Added 3 rows for '14.0' (out of 3 available)\n",
      "  Added 3 rows for '15.0' (out of 3 available)\n",
      "  Added 1 rows for '16.0' (out of 1 available)\n",
      "  Added 1 rows for '17.0' (out of 1 available)\n",
      "  Added 2 rows for '19.0' (out of 2 available)\n",
      "  Added 1 rows for '23.0' (out of 1 available)\n",
      "  Added 1 rows for '27.0' (out of 1 available)\n",
      "  Added 1 rows for '30.0' (out of 1 available)\n",
      "  Added 1 rows for '31.0' (out of 1 available)\n",
      "\n",
      "Sampling for column 'People_PRF_BA_team_experience_1_to_3_yr'...\n",
      "  Added 3 rows for '6.0' (out of 14 available)\n",
      "  Added 3 rows for '7.0' (out of 8 available)\n",
      "  Added 2 rows for '40.0' (out of 2 available)\n",
      "  Added 1 rows for '9.0' (out of 1 available)\n",
      "  Added 3 rows for '10.0' (out of 5 available)\n",
      "  Added 1 rows for '11.0' (out of 1 available)\n",
      "  Added 1 rows for '13.0' (out of 1 available)\n",
      "  Added 2 rows for '15.0' (out of 2 available)\n",
      "  Added 1 rows for '17.0' (out of 1 available)\n",
      "  Added 1 rows for '23.0' (out of 1 available)\n",
      "  Added 1 rows for '25.0' (out of 1 available)\n",
      "\n",
      "Sampling for column 'People_PRF_BA_team_experience_great_than_3_yr'...\n",
      "  Added 3 rows for '4.0' (out of 44 available)\n",
      "  Added 3 rows for '7.0' (out of 9 available)\n",
      "  Added 3 rows for '9.0' (out of 9 available)\n",
      "  Added 3 rows for '10.0' (out of 13 available)\n",
      "  Added 3 rows for '11.0' (out of 6 available)\n",
      "  Added 3 rows for '12.0' (out of 3 available)\n",
      "  Added 3 rows for '13.0' (out of 3 available)\n",
      "  Added 2 rows for '14.0' (out of 2 available)\n",
      "  Added 2 rows for '15.0' (out of 2 available)\n",
      "  Added 1 rows for '18.0' (out of 1 available)\n",
      "  Added 2 rows for '20.0' (out of 2 available)\n",
      "\n",
      "Sampling for column 'People_PRF_IT_experience_less_than_1_yr'...\n",
      "  Added 3 rows for '0.0' (out of 32 available)\n",
      "  Added 3 rows for '1.0' (out of 20 available)\n",
      "  Added 3 rows for '2.0' (out of 5 available)\n",
      "  Added 3 rows for '3.0' (out of 6 available)\n",
      "  Added 3 rows for '4.0' (out of 3 available)\n",
      "  Added 2 rows for '5.0' (out of 2 available)\n",
      "  Added 3 rows for '6.0' (out of 3 available)\n",
      "  Added 1 rows for '9.0' (out of 1 available)\n",
      "  Added 1 rows for '10.0' (out of 1 available)\n",
      "  Added 1 rows for '16.0' (out of 1 available)\n",
      "  Added 1 rows for '17.0' (out of 1 available)\n",
      "  Added 1 rows for '24.0' (out of 1 available)\n",
      "\n",
      "Sampling for column 'People_PRF_IT_experience_1_to_3_yr'...\n",
      "  Added 3 rows for '0.0' (out of 25 available)\n",
      "  Added 3 rows for '1.0' (out of 19 available)\n",
      "  Added 3 rows for '2.0' (out of 9 available)\n",
      "  Added 3 rows for '3.0' (out of 6 available)\n",
      "  Added 3 rows for '4.0' (out of 8 available)\n",
      "  Added 1 rows for '5.0' (out of 1 available)\n",
      "  Added 3 rows for '6.0' (out of 4 available)\n",
      "  Added 3 rows for '7.0' (out of 4 available)\n",
      "  Added 1 rows for '8.0' (out of 1 available)\n",
      "  Added 3 rows for '9.0' (out of 3 available)\n",
      "  Added 3 rows for '10.0' (out of 3 available)\n",
      "  Added 1 rows for '11.0' (out of 1 available)\n",
      "  Added 1 rows for '15.0' (out of 1 available)\n",
      "  Added 2 rows for '16.0' (out of 2 available)\n",
      "  Added 1 rows for '17.0' (out of 1 available)\n",
      "  Added 1 rows for '23.0' (out of 1 available)\n",
      "  Added 1 rows for '61.0' (out of 1 available)\n",
      "\n",
      "Sampling for column 'People_PRF_IT_experience_great_than_3_yr'...\n",
      "  Added 3 rows for '0.0' (out of 6 available)\n",
      "  Added 3 rows for '1.0' (out of 16 available)\n",
      "  Added 3 rows for '2.0' (out of 11 available)\n",
      "  Added 3 rows for '3.0' (out of 15 available)\n",
      "  Added 3 rows for '4.0' (out of 14 available)\n",
      "  Added 3 rows for '5.0' (out of 10 available)\n",
      "  Added 3 rows for '6.0' (out of 5 available)\n",
      "  Added 3 rows for '7.0' (out of 5 available)\n",
      "  Added 3 rows for '8.0' (out of 6 available)\n",
      "  Added 3 rows for '9.0' (out of 4 available)\n",
      "  Added 3 rows for '10.0' (out of 3 available)\n",
      "  Added 1 rows for '11.0' (out of 1 available)\n",
      "  Added 3 rows for '14.0' (out of 3 available)\n",
      "  Added 1 rows for '15.0' (out of 1 available)\n",
      "  Added 1 rows for '16.0' (out of 1 available)\n",
      "  Added 1 rows for '81.0' (out of 1 available)\n",
      "  Added 1 rows for '22.0' (out of 1 available)\n",
      "  Added 1 rows for '87.0' (out of 1 available)\n",
      "\n",
      "Sampling for column 'People_PRF_IT_experience_less_than_3_yr'...\n",
      "  Added 1 rows for '33.0' (out of 1 available)\n",
      "  Added 3 rows for '3.0' (out of 27 available)\n",
      "  Added 1 rows for '36.0' (out of 1 available)\n",
      "  Added 3 rows for '6.0' (out of 13 available)\n",
      "  Added 3 rows for '7.0' (out of 6 available)\n",
      "  Added 3 rows for '9.0' (out of 5 available)\n",
      "  Added 2 rows for '10.0' (out of 2 available)\n",
      "  Added 3 rows for '11.0' (out of 3 available)\n",
      "  Added 1 rows for '42.0' (out of 1 available)\n",
      "  Added 3 rows for '15.0' (out of 3 available)\n",
      "  Added 1 rows for '20.0' (out of 1 available)\n",
      "  Added 3 rows for '24.0' (out of 3 available)\n",
      "\n",
      "Sampling for column 'People_PRF_IT_experience_3_to_9_yr'...\n",
      "  Added 3 rows for '7.0' (out of 11 available)\n",
      "  Added 2 rows for '8.0' (out of 2 available)\n",
      "  Added 2 rows for '9.0' (out of 2 available)\n",
      "  Added 3 rows for '10.0' (out of 16 available)\n",
      "  Added 2 rows for '11.0' (out of 2 available)\n",
      "  Added 2 rows for '12.0' (out of 2 available)\n",
      "  Added 2 rows for '13.0' (out of 2 available)\n",
      "  Added 2 rows for '40.0' (out of 2 available)\n",
      "  Added 1 rows for '15.0' (out of 1 available)\n",
      "  Added 1 rows for '17.0' (out of 1 available)\n",
      "\n",
      "Sampling for column 'People_PRF_IT_experience_great_than_9_yr'...\n",
      "  Added 3 rows for '5.0' (out of 24 available)\n",
      "  Added 3 rows for '6.0' (out of 18 available)\n",
      "  Added 3 rows for '7.0' (out of 10 available)\n",
      "  Added 3 rows for '8.0' (out of 10 available)\n",
      "  Added 3 rows for '9.0' (out of 12 available)\n",
      "  Added 3 rows for '10.0' (out of 11 available)\n",
      "  Added 2 rows for '11.0' (out of 2 available)\n",
      "  Added 3 rows for '12.0' (out of 3 available)\n",
      "  Added 3 rows for '13.0' (out of 4 available)\n",
      "  Added 3 rows for '14.0' (out of 4 available)\n",
      "  Added 3 rows for '15.0' (out of 8 available)\n",
      "  Added 1 rows for '17.0' (out of 1 available)\n",
      "  Added 3 rows for '20.0' (out of 3 available)\n",
      "  Added 1 rows for '21.0' (out of 1 available)\n",
      "  Added 1 rows for '25.0' (out of 1 available)\n",
      "\n",
      "Sampling for column 'People_PRF_Project_manage_changes'...\n",
      "  Added 3 rows for '3.0' (out of 6 available)\n",
      "  Added 3 rows for '4.0' (out of 5 available)\n",
      "\n",
      "Sampling for column 'People_PRF_Personnel_changes'...\n",
      "  Added 3 rows for '4.0' (out of 11 available)\n",
      "  Added 3 rows for '5.0' (out of 8 available)\n",
      "  Added 3 rows for '6.0' (out of 3 available)\n",
      "  Added 2 rows for '7.0' (out of 2 available)\n",
      "  Added 2 rows for '8.0' (out of 2 available)\n",
      "  Added 1 rows for '9.0' (out of 1 available)\n",
      "  Added 2 rows for '10.0' (out of 2 available)\n",
      "  Added 3 rows for '11.0' (out of 3 available)\n",
      "  Added 1 rows for '15.0' (out of 1 available)\n",
      "  Added 1 rows for '16.0' (out of 1 available)\n",
      "  Added 1 rows for '21.0' (out of 1 available)\n",
      "\n",
      "Sampling for column 'Project_PRF_Cost_currency'...\n",
      "  Added 1 rows for 'South Africa, rand' (out of 1 available)\n",
      "  Added 1 rows for 'Sweden, krona' (out of 1 available)\n",
      "  Added 3 rows for 'Australia, dollar' (out of 20 available)\n",
      "  Added 1 rows for 'India, Rupees' (out of 1 available)\n",
      "  Added 1 rows for 'Switzerland, franc' (out of 1 available)\n",
      "  Added 1 rows for 'Malaysia, Renggette' (out of 1 available)\n",
      "  Added 3 rows for 'Chinese, RMB' (out of 4 available)\n",
      "  Added 1 rows for 'Ecuador' (out of 1 available)\n",
      "  Added 3 rows for 'Germany, Mark' (out of 3 available)\n",
      "  Added 3 rows for 'Netherlands, florin' (out of 74 available)\n",
      "  Added 1 rows for 'TRL' (out of 1 available)\n",
      "  Added 2 rows for 'Brazil, real' (out of 2 available)\n",
      "  Added 1 rows for 'New Zealand, dollar' (out of 1 available)\n",
      "  Added 3 rows for 'India, rupee' (out of 3 available)\n",
      "  Added 3 rows for 'United Kingdom, pound sterling' (out of 43 available)\n",
      "  Added 3 rows for 'Japan, yen' (out of 19 available)\n",
      "\n",
      "Sampling for column 'Project_PRF_Currency_multiple'...\n",
      "  Added 3 rows for 'Yes 1,000' (out of 4 available)\n",
      "\n",
      "Removed 693 duplicate rows\n",
      "\n",
      "=== SUMMARY ===\n",
      "Original sample size: 78\n",
      "Additional rows added: 1673\n",
      "Final dataset size: 1751\n",
      "Size increase: 2144.9%\n",
      "Enhanced dataset shape: (1751, 52)\n",
      "\n",
      "7. Verifying categories coverage...\n",
      "\n",
      "=== CATEGORY COVERAGE VERIFICATION ===\n",
      "\n",
      "Column 'External_EEF_Data Quality Rating':\n",
      "  Before: 4 categories\n",
      "  After:  4 categories\n",
      "\n",
      "Column 'Project_PRF_Year of Project':\n",
      "  Before: 9 categories\n",
      "  After:  27 categories\n",
      "  New categories added: [1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2006, 2007]\n",
      "\n",
      "Column 'External_EEF_Industry Sector':\n",
      "  Before: 10 categories\n",
      "  After:  17 categories\n",
      "  New categories added: ['Construction', 'Communication', 'Logistics', 'Professional Services', 'Insurance', 'Mining', 'Defence']\n",
      "\n",
      "Column 'External_EEF_Organisation Type':\n",
      "  Before: 23 categories\n",
      "  After:  193 categories\n",
      "  New categories added: ['Recreation & Personnel Services;Professional Services;Computers & Software;', 'Electronics;', 'Government;Electricity, Gas, Water;Communications;Community Services;Professional Services;Electronics;', 'Wholesale & Retail Trade;Consumer Goods;', 'Government;Financial, Property & Business Services;', 'Agriculture, Forestry, Fishing, Hunting;Government;', 'Medical and Health Care;Public Administration;Insurance;', 'Public Administration;', 'Agriculture, Forestry, Fishing, Hunting;', 'IT Services;', 'Agriculture, Forestry, Fishing, Hunting;Chemicals;Computers & Software;Construction;Defence;Electricity, Gas, Water;Electronics;Food Processing;Government;generic application;', 'Software products;', 'Coronial Services;', 'Oil & Petroleum;', 'Government;Local administration and counties;', 'Professional Services;Environmental Consulting;', 'Art , Events , Ticketing;', 'Manufacturing;Professional Services;', 'Real Estate & Property;Community Services;', 'Occupational Health and Safety;', 'general public (mobile phone end user);', 'All-purpose;', 'Retail;', 'Government;Public Administration (Revenue);', 'Internet;', 'Post/mail services;', 'Telecommunications;', 'Financial, Property & Business Services;(Banking, Insurance, Stock);', 'Chemicals;Energy;', 'Public Administration;Financial, Property & Business Services;', 'Education Institution;Electricity, Gas, Water;University;', 'Advertising;', 'Wholesale & Retail Trade;Transport & Storage;', 'Wholesale & Retail Trade;', 'Wholesale & Retail Trade;Oil;', 'Real Estate & Property;', 'Public Administration;Community Services;Insurance;', 'UniversityEvent Management-involves external users;', 'Transit Corporation;', 'Government;Professional Services;', 'Professional Services;Computers & Software;', 'General;', 'Government;Medical and Health Care;', 'Public Administration;Insurance;', 'Communications;Financial (Banking, Insurance, Stock);Government;Public Administration (Revenue);Manufacturing;Medical and Health Care;Post;Traffic (Aerospace/railway/Automotive);Transport;Logistic (Wholesale & Retail/Storage);Research & Development;Energy', 'Commercial services;', 'Sales;', 'Financial, Property & Business Services;Insurance;', 'Information Technology Services Provider;', 'Marketing;', 'Computers and IT business;', 'Environmental Monitoring;Public Administration;', 'Oil;', 'Manufacturing;Oil;', 'Media;', 'Construction;Financial, Property & Business Services;Government;Real Estate & Property;Transport & Storage;Housing;', 'Manufacturing;Computers & Software;', 'Service;Recreation, Personnel & Other Services;', 'Data Provisioning;', 'Engineering;', 'Content Management;', 'Voice Provisioning;', 'Computers & Software;Citizens of DK;', 'Virtual Assistants (Lingubots);', 'Public Administration;Community Services;', 'Manufacturing;Computers;Diversified Corp;', 'Government;Municipal Services;', 'Government;Health Sciences;', 'Government;Electricity, Gas, Water;', 'Tax administration;', 'Citizens and the Municipalities;', 'Manufacturing;Wholesale & Retail Trade;Transport & Storage;', 'Post;', 'Communications;Telecom;', 'Government;Public Administration;', 'Engineering;Research & Development;Software Development;Client/Server architecture for Language Services;', 'Chemicals;', 'Mining;', 'Government, Public Administration (Revenue);', 'Publishing;', 'Aerospace / Automotive;Chemicals;Defence;Electronics;Food Processing;Government;Manufacturing;Medical and Health Care;Mining;Oil & Petroleum;Transport & Storage;Generic application;', 'Agriculture, Forestry, Fishing, Hunting;Manufacturing;', 'Communications;', 'Human Resource (HR) Domain;', 'Manufacturing;Computers;Diversified corporation;', 'Any organization which counts function points;', 'Exhibition Management;', 'Government;Real Estate & Property;', 'Community Services;Invoice-handling;', 'Airport;', 'Research & development;', 'Aerospace / Automotive;Computers & Software;', 'Mining;Manufacturing;Chemicals;', 'Public Administration;Aerospace / Automotive;Computers & Software;Insurance;', 'Wholesale & Retail Trade;Computers & Software;', 'Credit Card Processor;', 'Service;', 'Education Institution;Research;', 'Transport & Storage;Media;', 'Finance;', 'IS-Metrics collection system;', 'Manufacturing;Transport & Storage;', 'Government;Danish citizens;', 'Computers & Software;Consumer Goods;Electronics;', 'Financial (Banking, Insurance, Stock);', 'Utilities;', 'Defence;Aerospace / Automotive;', 'Imaging;', 'Universal;', 'Traffic (Aerospace/Railway/Automotive);Transport;', 'Telecom;', 'Chemicals;Community Services;Electricity, Gas, Water;Government;', 'Energy Sources (Oil & Petroleum/Electricity etc);', 'Recreation & Personnel Services;', 'Revenue;', 'Consultancy;', 'Communications;Electronics;', 'E-Business;', 'Education;', 'Amusement/Game Center;', 'Construction;', 'Manufacturing;Consumer Goods;', 'Security;', 'Manufacturing;', 'Communications;Computers & Software;', 'Sales & Marketing;', 'Warehouse Management;', 'Communications;Telecom & Networking;', 'Travel;', 'Logistics;', 'Computers & Software;', 'Defence;', 'Distribution;', 'Local;', 'Billing;', 'Government;Defence;', 'Professional Services;', 'Car Rental;', 'Agriculture, Forestry, Fishing, Hunting;Transport & Storage;', 'Community Services;Municipality;', 'Transport & Storage;Professional Services;', 'Government;Defence;Aerospace / Automotive;', 'Medical and Health Care;Professional Services;', 'Building Automation;', 'Manufacturing;Manufacture of steel products;', 'Revenue collection;', 'Financial, Property & Business Services;Banking;', 'Manufacturing;Wholesale & Retail Trade;', 'Insurance;', 'Air Traffic Management;', 'Government;Public administration;', 'Agriculture, Forestry, Fishing, Hunting;Banking;', 'Business Services;', 'Computers & Software;Human Ressources;', 'Information Technology;Human Resource (HR) Domain;', 'Logistic (Wholesale & Retail/Storage);', 'Computer Consultants;', 'Ordering;', 'Restaurant;', 'Government;Municipal;', 'Computer Systems Consultant;Public Administration;', 'Telecommunication;', 'Government;Municipality;', 'Electricity, Gas, Water;', 'Developing global software solutions;', 'Wholesale & Retail Trade;Financial, Property & Business Services;', 'Transport & Storage;Aerospace / Automotive;', 'Maintenance;', 'Transport & Storage;Public Administration;', 'Services;']\n",
      "\n",
      "Column 'Project_PRF_Application Group':\n",
      "  Before: 4 categories\n",
      "  After:  6 categories\n",
      "  New categories added: ['Mathematically intensive application', 'Business Application; Infrastructure Software;']\n",
      "\n",
      "Column 'Project_PRF_Application Type':\n",
      "  Before: 31 categories\n",
      "  After:  568 categories\n",
      "  New categories added: ['Financial;', 'ERP;', 'Transportation;', 'Factory parts follow up;', 'Document management;Online analysis and reporting;Workflow support & management;Complex process control;', 'Decision Support System;', 'Document management;Financial transaction process/accounting;', 'Catalogue/register of things or events;Customer billing/relationship management;Document management;Geographic or spatial information system;Mathematical modelling (finance or eng.);Electronic Data Interchange;', 'Workflow support & management;Management Information System;', 'Spare parts management;', 'International;', 'Customer billing;', 'Workflow support & management;', 'Document management;Logistic or supply planning & control;', 'MultiMedia;', 'Internet Banking;', 'Mainframe;', 'Management system;', 'Transaction/Production System;Artificial Intelligence;', 'Condemnation proceedings;', 'Catalogue/register of things or events;Data or database management;', 'Retailler sells reporting;', 'Energy Reporting;', 'Device or interface driver;', 'Telecommunications;', 'Parts database for conception;', 'Reparation management;', 'Team Management;', 'Catalogue/register of things or events;Customer billing/relationship management;Electronic Data Interchange;', 'Inventory Control;', 'Performance monitoring;', 'Test Equipment;', 'Call Center Management;', 'Production process documentation;', 'Chemical Risks Information System;', 'Strategic planning;', 'Data Warehouse;', 'Micro Marketing;', 'Production management system;', 'Marketing Info System;', 'Sales promotion tool;', 'Decision Support System;Management Information System;Office Information System;', 'Process of factory management;', 'Equipment Management;', 'Website;', 'Car Documentation management;', 'Catalogue/register of things or events;Document management;Electronic Data Interchange;', 'Logistic tracking;', 'Network management;', 'Catalogue/register of things or events;Customer billing/relationship management;', 'Telecom Data Circuits;', 'Stock factory manegement;', 'Scientific/Math;', 'Corporate Taxation;', 'Customer billing/relationship management;Contact Management;', 'Analysis and Environmental Risk Assessment;', 'Catalogue/register of things or events;Online analysis and reporting;', 'Class Management;', 'Catalogue/register of things or events;Customer billing/relationship management;Document management;Administrative system for daycare;', 'Translation;', 'Factory follow up;', 'Automate exchange between two IT Systems;', 'System conversion;', 'Technical Support  Information System;', 'Web-based App. J2EE;', 'Building Automation;Embedded software - simple device control;Protocol Linux ARM9;Device or interface driver;', 'Tools management;', 'Quality Management;', 'Salaries Reporting;', 'Fault Tolerance;Management Information System;Fault Management;', 'Supply Management;', 'Device or interface driver;Financial transaction process/accounting;Complex process control;', 'Provider Management;', 'Rules documentation management;', 'Management Information System;EDI;', 'Catalogue/register of things or events;Document management;Online analysis and reporting;', 'Vehicle Systems Software;', 'Project Risk management;', 'Human resource;', 'MiddleWare Telecom Switching;', 'Health Management;', 'MiddleWare;', 'Providing Management;', 'Quality Factory Reporting;', 'Business;Catalogue/register of things or events;', 'Catalogue/register of things or events;Document management;Job, case, incident, project management;Logistic or supply planning & control;Online analysis and reporting;Personal productivity (e.g. spreadsheet);Electronic Data Interchange;', 'Financial transaction process/accounting;Online analysis and reporting;', 'Financial transaction process/accounting;Job, case, incident, project management;Personal productivity (e.g. spreadsheet);Workflow support & management;', 'Part management in factory;', 'Catalogue/register of things or events;Document management;Customer relationship management;', 'Telecom;Network Management;', 'Computing of the thermodynamic process;', 'Selling reporting;', 'POS;', 'Sales calculation (DRP);', 'E-Business;', 'Catalogue/register of things or events;Document management;Online analysis and reporting;Workflow support & management;', 'Customer Billing;', 'Instant Messaging client;', 'Calculation, quotation, insurance policy issue;', 'web;', 'Number of Hosting Solution;', 'Financial transaction process/accounting;Management or performance reporting;', 'Catalogue/register of things or events;Document management;Workflow support & management;', 'Human Ressources;', 'Msg.Switch/cel phone;', 'Marketing systems;', 'Online analysis and reporting;Personal productivity (e.g. spreadsheet);', 'Logistic or supply planning & control;Stock control & order processing;', 'Rules documentation;', 'Operating system or software utility;(Re-usable component);', 'Customer Resource Management;', 'Trading;', 'IT management;', 'Online System for University fraternities;', 'Job, case, incident, project management;Online analysis and reporting;', 'Accounting;', 'Executive Information System;Management Information System;', 'Financial transaction process/accounting;Customer billing;Customer relationship management;', 'Management or performance reporting;', 'Other;', 'Software for machine control;Complex process control;', 'Management of Licences and Permits;', 'Management of registration number;', 'Job, case, incident, project management;Online analysis and reporting;Personal productivity (e.g. spreadsheet);', 'Management or performance reporting;Complex process control;', \"Project's management;\", 'Customer billing/relationship management;CRM;', 'Transaction/Production System;Office Automation System;Decision Support System;', 'Follow up of car failure;', 'IP Contact Centers;', 'GUI Interface Application;', 'Network Management;Telecom & Networking;', 'Providing management;', 'Telecom Data Circuits and Revenue;', 'Fault Tolerance;', 'Management of car distribution;', 'Human ressources management;', 'Customs Informations management;', 'Office Information System;', 'Factory Reporting;', 'Manufacturing process management;', 'Sensor Ctl. + presentation;', 'Cost logistic Computing;', 'Logistic or supply planning & control;Stock control & order processing;Electronic Data Interchange;', 'Warranty Management;', 'Engineering Software;', 'Inventory Management;', 'Dealer management;', 'Marketing management;', 'Customisation (Add-ons) to a Product Data Management System;', 'Catalogue/register of things or events;Document management;Financial transaction process/accounting;Job, case, incident, project management;Logistic or supply planning & control;Management or performance reporting;Online analysis and reporting;Stock contr', 'Catalogue/register of things or events;Electronic Data Interchange;Online analysis and reporting;Legislation and consideration of building cases;', 'Catalogue/register of things or events;Operating system or software utility;', 'Car design tool;', 'Cars selling;', 'Supplier Warranty Charge Back;', 'Algorithmic + DB;', 'Printing Documentation Design;', 'resources Management;', 'After sales Documentation;', 'Customer billing/relationship management;Billing management - Batch processing;', 'Document management;Job, case, incident, project management;Management or performance reporting;Online analysis and reporting;Operating system or software utility;Workflow support & management;Telecom & network management;', 'GUI for Protocol;Protocol Enhancement;', 'Financial transaction process/accounting;Client Server;', 'Reporting on factoring process;', 'Diagnostic distribution  management;', 'Knowledge Based Multimedia;', 'Transaction/Production System;EDI front-end for order processing system;', 'Online analysis and reporting;Embedded software - simple device control;Telecom & network management;', 'Job, case, incident, project management;Management or performance reporting;Operating system or software utility;Workflow support & management;Telecom & network management;', 'Document management;Financial transaction process/accounting;Image, video or sound processing;', 'Design management;', 'Catalogue/register of things or events;Processing application for public subsidies;', 'Data Provisioning;', 'Voice Provisioning;', 'Parts catalogue management;', 'Test vehicles Reporting;', 'After Sales Management Contract service;', 'To determine which IVR credit card refresh used;', 'Office Information System;Functional Specification System;', 'Knowledge-based App. w/ Interactive & Batch dbs;', 'Suppliers Follow up;', 'Computer Integrated Manufactuaring system;', 'Reconciliation;', 'Web Content;', 'Management or performance reporting;Online analysis and reporting;', 'Scheduling of work orders assembly lines;', 'Management Information System;Office Information System;Transaction/Production System;', 'Management of manufacturing needs additional;', 'VIrtual Synthesis for Acoustic;', 'MS Billing;', 'Spec/Document Management;', 'Motor simulator;', 'Catalogue/register of things or events;Financial transaction process/accounting;Electronic Data Interchange;', 'website for Parts selling;', 'Car renting;', 'Geometric design;', 'Quality of factory;', 'Document management;', 'Protocols;', 'Fault Tolerance;Process Control;Call Centre;', 'Catalogue/register of things or events;Document management;Online analysis and reporting;Workflow support & management;Complex process control;', 'human resources organisation in the factories;', 'Customer management;', 'Parts reporting IS;', 'Real-time System;', 'Management Information System;Linguistic Software;', 'CIS;', 'Tax system;', 'Document management;Financial transaction process/accounting;Online analysis and reporting;Stock control & order processing;Workflow support & management;Customer billing;Reservation system (eg. Airline, hotel);', 'Web;', \"Parts requirement's calculation (DRP);\", 'Airport Weather Observation Systems;Meteorological  events detection;', 'Security management;', 'Utility;', 'Internal Telecom Ordering Application;', 'Cost Tools Computing;', 'Trading? (procurement management);', 'Client Server;', 'Personal system;', 'Client Server and Mainframe;', 'Enterprise Management;', 'Sales statistics;', 'Fixed asset;', 'Financial transaction process/accounting;Online analysis and reporting;Space management of schools;', 'Information systems (Web);', 'Optimisation for Industrial Scenarios;', 'Data protection;', 'Suppliers Management;', 'Car logistic management;', 'Telecom & network management;', 'Car embedded Computer Management;', 'Switching;', 'IT project Management;', 'eCommerce;', 'Reporting;', 'University Admission Application Portal;', 'insurance quotation;', 'Interface;', 'Card Administration  INCAS & Fault Assurance CAPRA;', 'Employee self-service system;', 'DB Serch system;', 'Electronic Data Interchange;Reusable component;', 'Graphical Modeling;', 'Vendors management;', 'Process management;', 'Sales and Logistics Standard Application;', 'Stock control & order processing;', 'Commercial Web site;', 'System Software;', 'Parts management;', 'Production programming;', 'Customer Management;', 'Document management;Workflow support & management;', 'Automated Customer Statements;', 'Service Order & Activation Management;', 'Selling application;', 'Mission-critical system;', 'Capacity management;', 'After sales parts contract management;', 'Financial transaction process/accounting;Geographic or spatial information system;Online analysis and reporting;Stock control & order processing;Workflow support & management;', 'Document management;Financial transaction process/accounting;Personal productivity (e.g. spreadsheet);Workflow support & management;Complex process control;Electronic Data Interchange;', 'Car Database for factory;', 'Business system;', 'Track test management;', 'Financial transaction process/accounting;Management or performance reporting;Customer billing;', 'Job, case, incident, project management;Management or performance reporting;', 'Mathematical modelling (finance or eng.);Online analysis and reporting;', 'Application Security Control;', 'Maintenance;', 'After selling reporting;', 'Follow up of the production in  factories;', 'Purchaser performance management;', 'Billing and ERP;', 'Knowledge Based;', 'Document management;Job, case, incident, project management;', 'Selling programming;', 'Business;Stock control & order processing;', 'GPS Portal;', 'Customer billing/relationship management;Logistic or supply planning & control;', 'Monitoring of the factoring process;', 'Catalogue for IT products and IT services;', 'Technical administrative system;', 'Inventory gathering and Managing;', 'Electronic Banking;', 'New Screen Design;', 'Parts Database;', 'Geographic or spatial information system;Management or performance reporting;Telecom & network management;', 'Services Selling;', 'Pay;', 'Insurance quotation;', 'Retailler sells follow up;', 'Catalogue/register of things or events;Document management;', 'Customer billing/relationship management;Stock control & order processing;', 'GEO Information Management;', 'Mixed;', 'Financial transaction processing & Accounting;', 'Financial transaction process/accounting;Logistic or supply planning & control;Complex process control;', 'Selling Organisation;', 'Geographic or spatial information system;Complex process control;', 'Process documentation;', 'Operating system or software utility;', 'Workflow support & management;Precedents System;', 'European homologation management;', 'Shrink-wrap;', 'Document Management & Catalogue;', 'Handling payment of social pensions within government;', 'Operating system or software utility;Electronic Data Interchange;', 'Complex process control;', 'Pollution statistics;', 'Document management;Operating system or software utility;', 'Customer billing/relationship management;Document management;Trading;', 'suppliers management;', 'Factory change programming;', 'Logistic or supply planning & control;Management or performance reporting;', 'Management of parts buying;', 'Management or performance reporting;Online analysis and reporting;Telecom & network management;', 'Document management;Management or performance reporting;Online analysis and reporting;Workflow support & management;', 'HR;', 'Accounting of stock;', 'Document management;Logistic or supply planning & control;Online analysis and reporting;Personal productivity (e.g. spreadsheet);', 'Web based fullfilment tool for Advertising;', 'Change Management Tool;', 'Integration;', 'Logistic or supply planning & control;Stock control & order processing;Complex process control;', 'Forecastselling;', 'CAD;', 'Datawarehouse/ Business Intelligence;', 'Product Order management;', 'Administrative Support System;', 'Optimisation of the production;', 'Car test management;', 'Tax Legislative;', 'Mathematical modelling (finance or eng.);', 'Course management system;Dynamic website;', 'Central cmd./ctl of sensors;', 'Healthcare;', 'Office Automation;', 'Geographic or spatial information system;Image, video or sound processing;Job, case, incident, project management;Online analysis and reporting;Electronic Data Interchange;', 'Exchange system;', 'Customer billing;e-commerce;', 'Financial transaction process/accounting;Graphics & publishing tools or system;Management or performance reporting;Online analysis and reporting;Personal productivity (e.g. spreadsheet);', 'training Management;', 'Network Switch Provisioning;', 'Artifical Intelligence based engine;', 'Tools or system;', 'relatively complex application;', 'Simulator;', 'Management or performance reporting;Electronic Data Interchange;', 'Customer Data repository with applicatin interface;', 'Purchasing;', 'DSP;', 'Catalogue/register of things or events;Online analysis and reporting;Electronic Data Interchange;', 'Financial transaction process/accounting;Logistic or supply planning & control;', 'Interface database;', 'Packaging Visibility System;', 'Management and follow up of the parts;', 'Accounting system;', 'web EC site;', 'Printing Document Design;', 'Geographic or spatial information system;', 'Handling payment of social pensions in government;', 'IT projet Management;', 'Gaming & Wagering;', 'Information systems;', 'Access Control;', 'Template for data-exchange;', 'Quality of purchasing;', 'Case management;', 'Dynamic calculation accessory drive and distribution;', 'Graphics & publishing tools or system;', 'Simulation of the behaviour of vehicles on the road;', 'Security;', 'European Warranty Management;', 'After sales Follow up;', 'Document management;Image, video or sound processing;', 'Supporting of the commercial network;', 'Premium Paid Certificate;', 'Central database;', 'After Sales management Contract service;', 'Image, video or sound processing;', 'Job, case, incident, project management;Workflow support & management;', 'Distribution;', 'Support for parts documentation;', 'Local;', 'Advertising/Mailing Campaign;', 'Personal productivity (e.g. spreadsheet);', 'Billing;', 'Internet Banking for personal customers;', 'Database customers for Parts;', 'Geographic Information System;', 'Dealer network management;', 'Management of customs activities;', 'Sales contact management;', 'Qualty Factory Reporting;', 'Executive Information System;', 'Stock control & order processing;Workflow support & management;Electronic Data Interchange;', 'Process Control;Workflow support & management;The tool is Used By Employees of this Organization;', 'Case Management Study;', 'Insurance annities;Online user interface;', 'Video Game;', 'Car design;', 'Operating system or software utility;Synchronization of Outlook and Application;', 'Financial transaction process/accounting;Electronic Data Interchange;', 'Ordering;', 'Catalogue/register of things or events;Job, case, incident, project management;', 'Management of selling conditions to society;', 'Car Design;', 'Data Warehouse system;', 'Client/Server Customer Service application;', 'Financial transaction process/accounting;Workflow support & management;', 'Car Sales;', 'Defect Tracking System;', 'Stock factory management;', 'Sales;', 'Parts selling;', 'Factory process follow up;', 'Post exchange;', 'Infrastructure;', 'Car selling;', 'Software for machine control;Mathematical modelling (finance or eng.);', 'Parts Selling website;', 'Car electronic design;', 'Software for machine control;', 'Car Database;', 'website;', 'Unknown;', 'Directory Assistance;', 'Online. eSales;', 'Cards and Payments;', 'Company car management;', 'Financial transaction process/accounting;Job, case, incident, project management;Management or performance reporting;Online analysis and reporting;Workflow support & management;', 'Car pricing;', 'Web-based application;', 'Mobile Application;', 'Logistic or supply planning & control;Management or performance reporting;Personal productivity (e.g. spreadsheet);Workflow support & management;', 'Management of the centre activities;', 'Immobility & Facilities Management;', 'e-commerce;', 'Business;Customer billing/relationship management;', 'Financial transaction process/accounting;', 'Catalogue/register of things or events;Management or performance reporting;', 'Scientific;', 'Office Automation System;', 'Calculation and quotation of casualty insurance;', 'Network Management;Migration tool;', 'Web Content & Middleware;', 'Identity Card Emission;Data or database management;', 'Workflow support & management;Proposal creation and submission;', 'Government;', 'Ordering & provisioning system;', 'Provider management;', 'Parts logistic management;', 'Logistic or supply planning & control;', 'Production management;', 'IT cost project management;', 'Packaged software;', 'Products management;', 'Catalogue/register of things or events;Customer relationship management;', 'Logistic or supply planning & control;Workflow support & management;', 'Human Resources;', 'Technical support for diagnostic and repair;', 'Business;', 'Training;', 'Trading;Electronic Data Interchange;', 'Embedded system/real-time application;', 'Stock Management;', 'Business;Workflow support & management;', 'not recorded;', 'MS Business Platform;', 'Online analysis and reporting;Workflow support & management;', 'Job, case, incident, project management;', 'Company hierarchy and staff directory;', 'Network Management;', 'Office Information System;Case Management System;', 'Job, case, incident, project management;Software for communities to support administration;', 'Geographic or spatial information system;Online analysis and reporting;', 'Taxation;', 'Catalogue/register of things or events;Workflow support & management;', 'Web-based App. DOTNet;', 'Operating system or software utility;Workflow support & management;', 'Cost Computing;', 'Personnel system;', 'Factory reporting;', 'Remote Banking;', 'For credit collection;', 'Mathematical modelling (finance or engineering);', 'Customer billing/relationship management;Financial transaction process/accounting;Online analysis and reporting;Trading;Workflow support & management;Complex process control;Electronic Data Interchange;', 'Document management;Management or performance reporting;', 'Contract management After Sales;', 'Cars documentation;', 'Financial transaction process/accounting;Data Warehouse;', 'Decision Support System;Management Information System;', 'Idea/Patent Information System;', 'Interactive Voice Response;', 'Protocol in Building automation;Protocol Enhancement;', 'Database  Parts;', 'Broadband application;', 'Car production;', 'Military;', 'Project management;', 'Business enabling service;', 'Extranet application;', 'Embedded Systems;', 'Cost analysis;', 'diagnostic tools;', 'Workplace Savings;', 'Device or interface driver;Financial transaction process/accounting;Online analysis and reporting;Complex process control;', 'Document management;Logistic or supply planning & control;Online analysis and reporting;Personal productivity (e.g. spreadsheet);Electronic Data Interchange;', 'Transaction/Production System;', 'Software development tool;', 'Catalogue/register of things or events;Electronic Data Interchange;', 'Catalogue/register of things or events;Workflow support & management;Electronic Data Interchange;', 'After sales Parts documentation;', 'Type 1 Function Point Counting Tool;', 'Business;Network Management;', 'Logistic indicators;', 'Communication systrem;', 'Online analysis and reporting;Software development tool;', 'Quality management;', 'Order Processing System;', 'Management or performance reporting;Workflow support & management;', 'Air Traffic Management;', 'Technical Information System;', 'Customer billing/relationship management;Trading;', 'Financial application area;', 'Online Insurance product comparision tool;', 'Back-Office;', 'Parts documentation;', 'Workflow support & management;Ordering tool enhancements for telecom components;', \"Factory's process management;\", 'Client-Server Application;', 'Retailer sales reporting;', 'Robot;', 'Network Management;Telecom and Networking;', 'Customer billing/relationship management;Financial transaction process/accounting;Electronic Data Interchange;']\n",
      "\n",
      "Column 'Project_PRF_Development Type':\n",
      "  Before: 3 categories\n",
      "  After:  7 categories\n",
      "  New categories added: ['Porting', 'POC', 'Other', 'Not Defined']\n",
      "\n",
      "Column 'Tech_TF_Development Platform':\n",
      "  Before: 4 categories\n",
      "  After:  6 categories\n",
      "  New categories added: ['Hand Held', 'MF']\n",
      "\n",
      "Column 'Tech_TF_Language Type':\n",
      "  Before: 3 categories\n",
      "  After:  6 categories\n",
      "  New categories added: ['ApG', '2GL', 'APG']\n",
      "\n",
      "Column 'Tech_TF_Primary Programming Language':\n",
      "  Before: 9 categories\n",
      "  After:  128 categories\n",
      "  New categories added: ['Unix', 'VisualFoxPro', 'ColdFusion', 'Data base language', 'Access', 'BEA Weblogic', 'ASAP', 'Centura', 'NCR teradata scripting', 'VisualAge', 'Perl', 'IEF', 'MAPPER', 'BO', 'Adobe Flex', 'Enablon', 'CSP', 'C/AL', 'Informatica PowerCenter', 'IDEAL', 'Caa', 'C', 'PL/SQL', 'ABF', 'LEX', 'DELPHI', 'COGNOS', 'LISP', 'ASP.Net', 'Smalltalk', 'Lotus Notes', 'Periproducer', 'PowerPlay', 'BPM', 'AB INITIO', 'A:G', 'OutlookVBA', 'RPL', 'Must Modeller', 'FORTRAN', 'RALLY', 'Siebel', 'NATURAL', 'Pega Workflows', 'Huron/Object Star', 'DRIFT', 'REXX', 'SLEL', 'INGRES', 'ADS/Online', 'SAPIENS', 'iPlanet Netscape Application Server', 'gcc', 'BRE', 'Jam', 'IIS', 'Spreadsheet', 'AppBuilder', 'PowerBuilder', 'Visual C++', 'ACCEL', 'XML', 'COOL:Gen', 'STAFFWARE', 'Visual Basic', 'SQL', 'TIBCO', 'Visual FoxPro', 'Assembler', 'ASP', 'PHP', 'Formspath', 'Object oriented language', 'CLIPPER', 'Express', 'SAS', 'RPG', 'iOS', 'Mendix', 'Shell', 'HLL/WB', 'PYTHON', 'FOCUS', 'Unix Shell', 'TELON', 'Shell, C', 'ADO.Net', 'PERIPHONICS', 'MANTIS', 'UNIFACE', 'MS-Navision Properitory Language', 'Pro*C', 'Jdeveloper', 'ARBOR/BP', 'Brightware proprietary', 'EASYTRIEVE', 'Azure', 'IBM WTX', 'Magic', 'HPS', 'BASIC', 'XGML', 'Ada', 'EJB', 'Visual Studio .Net', 'MATLAB', 'SLOGAN', 'APPS', 'CICS', 'Script Language', 'PASCAL', 'COBOL', 'Delphi', 'Upfront', 'TNSDL', 'Doc1 Designer (Entorno visual)', 'J2EE', 'Datastage', 'HTML']\n",
      "\n",
      "Column 'Project_PRF_Relative Size':\n",
      "  Before: 7 categories\n",
      "  After:  9 categories\n",
      "  New categories added: ['XXL', 'XXXL']\n",
      "\n",
      "Column 'Project_PRF_Team Size Group':\n",
      "  Before: 8 categories\n",
      "  After:  15 categories\n",
      "  New categories added: ['31-40', '15-20', '91-100', '101+', '71-80', '81-90', '51-60']\n",
      "\n",
      "Column 'Project_PRF_CASE Tool Used':\n",
      "  Before: 2 categories\n",
      "  After:  3 categories\n",
      "  New categories added: [\"Don't Know\"]\n",
      "\n",
      "Column 'Process_PMF_Development Methodologies':\n",
      "  Before: 8 categories\n",
      "  After:  39 categories\n",
      "  New categories added: ['Joint Application Development (JAD);Timeboxing;', 'Joint Application Development (JAD);Rapid Application Development (RAD);', 'IT Unified Process (ITUP);', 'Multifunctional Teams;Rapid Application Development (RAD);', 'Waterfall (incl Linear Processing & SSADM);', 'Joint Application Development (JAD);Multifunctional Teams;', 'Interactive;', 'Joint Application Development (JAD);Multifunctional Teams;Timeboxing;', 'Multifunctional Teams;Unified Process;', 'OCE;', 'Joint Application Development (JAD);Rapid Application Development (RAD);Timeboxing;', 'Unified Process;', 'Personal Software Process (PSP);', 'Joint Application Development (JAD);Multifunctional Teams;Rapid Application Development (RAD);Timeboxing;', 'Timeboxing;', 'Joint Application Development (JAD);Multifunctional Teams;Rapid Application Development (RAD);', 'Rapid Application Development (RAD);Timeboxing;', 'Rapid Application Development (RAD);', 'Iterative;', 'Extreme Programming (XP);', 'Multifunctional Teams;Rapid Application Development (RAD);Timeboxing;', 'Scrum;', 'Spiral;', 'Multifunctional Teams;Timeboxing;', 'Joint Application Development (JAD);', 'Incremental;', 'Multifunctional Teams;Waterfall (incl Linear Processing & SSADM);', 'Lean;', 'Personal Software Process (PSP);Unified Process;', 'Multifunctional Teams;', 'Iterative;Unified Process;']\n",
      "\n",
      "Column 'Process_PMF_Prototyping Used':\n",
      "  Before: 1 categories\n",
      "  After:  1 categories\n",
      "\n",
      "Column 'Tech_TF_Architecture':\n",
      "  Before: 3 categories\n",
      "  After:  7 categories\n",
      "  New categories added: ['Stand-alone', 'Multi-tier with web interface', 'Multi-tier', 'Multi-tier / Client server']\n",
      "\n",
      "Column 'Tech_TF_Client_Server':\n",
      "  Before: 2 categories\n",
      "  After:  4 categories\n",
      "  New categories added: ['Not Applicable', \"Don't Know\"]\n",
      "\n",
      "Column 'Tech_TF_Client_Roles':\n",
      "  Before: 10 categories\n",
      "  After:  61 categories\n",
      "  New categories added: ['Data retrieval & presentation;Web/HTML browser;', 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;', 'HandHeld Device;', 'Data entry & validation;Web/HTML browser;', 'Data entry & validation;Data retrieval & presentation;Web/HTML browser;Web public interface;', 'Run a computer-human interface;Data retrieval & presentation;', 'Device/equipment interface;', 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;', 'Run a computer-human interface;', 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;Web public interface;', 'Run a computer-human interface;Data entry & validation;Web/HTML browser;', 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;Security;', 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;Web public interface;Security;', 'Run a computer-human interface;Web/HTML browser;', 'Run a computer-human interface;Data entry & validation;', 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Device/equipment interface;', 'Data entry & validation;', 'Business logic or rule processing;Web/HTML browser;', 'Query and update data;', 'Business logic or rule processing;Data retrieval & presentation;Device/equipment interface;Security;', 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Device/equipment interface;Web/HTML browser;', 'Run a computer-human interface;Data retrieval & presentation;Web/HTML browser;', 'Business logic or rule processing;Data retrieval & presentation;', 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Device/equipment interface;Terminal emulation;Provide some calculations;', 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;', 'Run a computer-human interface;Data retrieval & presentation;Web/HTML browser;Security;', 'Business logic or rule processing;Data retrieval & presentation;Web public interface;', 'Run a computer-human interface;Data retrieval & presentation;Web/HTML browser;Web public interface;', 'Data entry & validation;Data retrieval & presentation;', 'Run a computer-human interface;Business logic or rule processing;Web/HTML browser;', 'mobile app;', 'Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Data extraction, transformation and loading;', 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Device/equipment interface;Web/HTML browser;', 'Run a computer-human interface;Business logic or rule processing;Data retrieval & presentation;', 'Web/HTML browser;Web public interface;', 'front-end;', 'Data retrieval & presentation;Web/HTML browser;Security;', 'Business logic or rule processing;Data retrieval & presentation;Web/HTML browser;', 'Business logic or rule processing;', 'Terminal emulation;', 'Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;', 'Run a computer-human interface;Business logic or rule processing;Data retrieval & presentation;Device/equipment interface;', 'Business logic or rule processing;Data entry & validation;Device/equipment interface;Terminal emulation;', 'Business logic or rule processing;Data entry & validation;', 'Run a computer-human interface;Data entry & validation;Device/equipment interface;Web/HTML browser;', 'Data entry & validation;Device/equipment interface;Web/HTML browser;', 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Web/HTML browser;', 'Business logic or rule processing;Data entry & validation;Device/equipment interface;Web/HTML browser;', 'Data retrieval & presentation;', 'Business logic or rule processing;Data retrieval & presentation;Web/HTML browser;Web public interface;', 'Run a computer-human interface;Business logic or rule processing;']\n",
      "\n",
      "Column 'Tech_TF_Server_Roles':\n",
      "  Before: 11 categories\n",
      "  After:  85 categories\n",
      "  New categories added: ['Browser/server;Database server;FTP server;HTML/web server;Multi-user legacy application;Security/authentication;', 'Database server;Multi-user legacy application;Object/component server;', 'Database server;Mail server;Security/authentication;', 'Database server;File &/or print server;HTML/web server;Mail server;', 'FTP server;HTML/web server;Multi-user legacy application;', 'Database server;Messaging server;Security/authentication;', 'Database server;HTML/web server;Object/component server;Business logic;', 'Database server;FTP server;Messaging server;', 'Messaging server;', 'File &/or print server;', 'Database server;HTML/web server;Security/authentication;Exchange Server;', 'Database server;Multi-user legacy application;', 'Database server;File &/or print server;FTP server;HTML/web server;Mail server;Multi-user legacy application;Object/component server;Security/authentication;', 'Database server;Security/authentication;Delivery server for end products, f.e.Cognos Cubes;', 'Database server;Object/component server;', 'Mail server;Messaging server;', 'Object/component server;', 'Database server;File &/or print server;FTP server;Mail server;Security/authentication;', 'Database server;HTML/web server;Multi-user legacy application;Object/component server;', 'Database server;File &/or print server;Object/component server;Security/authentication;', 'Database server;FTP server;Messaging server;Security/authentication;', 'HTML/web server;Messaging server;', 'Database server;HTML/web server;Messaging server;Security/authentication;', 'Database server;File &/or print server;Security/authentication;', 'Database server;File &/or print server;Mail server;Messaging server;Security/authentication;', 'Database server;FTP server;HTML/web server;Object/component server;', 'Database server;Multi-user legacy application;Security/authentication;', 'Database server;HTML/web server;Mail server;Object/component server;Security/authentication;', 'FTP server;HTML/web server;Multi-user legacy application;Security/authentication;', 'Mail server;Multi-user legacy application;', 'Database server;HTML/web server;Multi-user legacy application;Security/authentication;', 'Database server;HTML/web server;Mail server;WAS Server;', 'Database server;File &/or print server;HTML/web server;Security/authentication;', 'Database server;HTML/web server;Multi-user legacy application;Object/component server;Security/authentication;', 'Database server;HTML/web server;Mail server;Object/component server;', 'HTML/web server;Mail server;Security/authentication;', 'Database server;File &/or print server;FTP server;HTML/web server;', 'Database server;Security/authentication;Law-based business logic;', 'HTML/web server;virtualisation server API;', 'Database server;File &/or print server;HTML/web server;Mail server;Messaging server;Object/component server;Security/authentication;', 'webserver;', 'Database server;File &/or print server;HTML/web server;Mail server;Messaging server;', 'Database server;File &/or print server;Security/authentication;Data entry & validation, business logic;', 'Database server;FTP server;HTML/web server;Mail server;', 'Database server;FTP server;Security/authentication;', 'Database server;HTML/web server;Mail server;', 'Database server;HTML/web server;Messaging server;Object/component server;Security/authentication;Application Server;', 'Database server;File &/or print server;HTML/web server;Object/component server;Security/authentication;', 'Database server;Object/component server;Security/authentication;Business logic;', 'HTML/web server;Object/component server;', 'Database server;File &/or print server;HTML/web server;', 'HTML/web server;', 'Database server;Object/component server;Security/authentication;', 'Database server;FTP server;Messaging server;Object/component server;', 'Database server;File &/or print server;HTML/web server;Messaging server;Multi-user legacy application;', 'Database server;Security/authentication;', 'Database server;File &/or print server;FTP server;Multi-user legacy application;', 'Database server;Mail server;', 'Database server;File &/or print server;Multi-user legacy application;Security/authentication;', 'Database server;HTML/web server;Security/authentication;', 'back-end;', 'Database server;FTP server;HTML/web server;Security/authentication;', 'Database server;HTML/web server;Security/authentication;ETL Server;', 'Database server;HTML/web server;Mail server;Multi-user legacy application;Object/component server;Security/authentication;', 'Multi-user legacy application;Security/authentication;', 'FTP server;Messaging server;Object/component server;', 'Database server;Security/authentication;Business logic;', 'Database server;HTML/web server;Messaging server;Object/component server;Security/authentication;DR;', 'Database server;File &/or print server;', 'Database server;HTML/web server;Object/component server;', 'Database server;FTP server;HTML/web server;Object/component server;Security/authentication;', 'Database server;FTP server;HTML/web server;Mail server;Security/authentication;', 'Database server;FTP server;HTML/web server;Mail server;Messaging server;Object/component server;Security/authentication;', 'Database server;HTML/web server;Object/component server;Security/authentication;']\n",
      "\n",
      "Column 'Tech_TF_Type_of_Server':\n",
      "  Before: 0 categories\n",
      "  After:  9 categories\n",
      "  New categories added: ['LAN Based;', 'Multi-tier with web public interface;', 'Stand alone;', 'Mainframe;', 'Unix;', 'back-end;', 'Client server;', 'Proprietary Midrange;', 'webserver;']\n",
      "\n",
      "Column 'Tech_TF_Client/Server_Description':\n",
      "  Before: 0 categories\n",
      "  After:  26 categories\n",
      "  New categories added: ['Client Server;', 'Client: presentation, processing, data;', 'Embedded;', 'Presentation & Logic on server;', 'Client presentation & processing, data on server;', 'not assessed;', '25%;', 'Client: presentation, processing;', '20%;', '50%;', 'Client: presentation; Server: processing;', 'Client: presentation, processing; Server: data;', 'Client-server Architecture;Browser-server Architecture;', 'Unknown;', '100%;', 'C/S;', 'Browser-server Architecture;', 'Client-server Architecture/P2P;', 'Web;', 'Client-server Architecture;', 'Presentation and logic on client;', '90%;', '30%;', 'Dynamic Link Library;', '10%;', 'Stand-alone;']\n",
      "\n",
      "Column 'Tech_TF_Web_Development':\n",
      "  Before: 1 categories\n",
      "  After:  2 categories\n",
      "  New categories added: ['Web?']\n",
      "\n",
      "Column 'Tech_TF_DBMS_Used':\n",
      "  Before: 1 categories\n",
      "  After:  2 categories\n",
      "  New categories added: ['No']\n",
      "\n",
      "Column 'Tech_TF_Tools_Used':\n",
      "  Before: 9 categories\n",
      "  After:  13 categories\n",
      "  New categories added: [8, 10, 12, 13]\n",
      "\n",
      "Column 'People_PRF_Project_user_involvement':\n",
      "  Before: 0 categories\n",
      "  After:  5 categories\n",
      "  New categories added: ['Best', 'No', 'Low', 'Yes', \"Don't Know\"]\n",
      "\n",
      "Column 'People_PRF_BA_team_experience_less_than_1_yr':\n",
      "  Before: 8 categories\n",
      "  After:  22 categories\n",
      "  New categories added: [4.0, 7.0, 9.0, 10.0, 13.0, 14.0, 15.0, 16.0, 17.0, 19.0, 23.0, 27.0, 30.0, 31.0]\n",
      "\n",
      "Column 'People_PRF_BA_team_experience_1_to_3_yr':\n",
      "  Before: 8 categories\n",
      "  After:  19 categories\n",
      "  New categories added: [6.0, 7.0, 40.0, 9.0, 10.0, 11.0, 13.0, 15.0, 17.0, 23.0, 25.0]\n",
      "\n",
      "Column 'People_PRF_BA_team_experience_great_than_3_yr':\n",
      "  Before: 9 categories\n",
      "  After:  20 categories\n",
      "  New categories added: [4.0, 7.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 18.0, 20.0]\n",
      "\n",
      "Column 'People_PRF_IT_experience_less_than_1_yr':\n",
      "  Before: 0 categories\n",
      "  After:  12 categories\n",
      "  New categories added: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 9.0, 10.0, 16.0, 17.0, 24.0]\n",
      "\n",
      "Column 'People_PRF_IT_experience_1_to_3_yr':\n",
      "  Before: 0 categories\n",
      "  After:  17 categories\n",
      "  New categories added: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 15.0, 16.0, 17.0, 23.0, 61.0]\n",
      "\n",
      "Column 'People_PRF_IT_experience_great_than_3_yr':\n",
      "  Before: 0 categories\n",
      "  After:  18 categories\n",
      "  New categories added: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 14.0, 15.0, 16.0, 81.0, 22.0, 87.0]\n",
      "\n",
      "Column 'People_PRF_IT_experience_less_than_3_yr':\n",
      "  Before: 8 categories\n",
      "  After:  20 categories\n",
      "  New categories added: [33.0, 3.0, 36.0, 6.0, 7.0, 9.0, 10.0, 11.0, 42.0, 15.0, 20.0, 24.0]\n",
      "\n",
      "Column 'People_PRF_IT_experience_3_to_9_yr':\n",
      "  Before: 9 categories\n",
      "  After:  19 categories\n",
      "  New categories added: [7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 40.0, 15.0, 17.0]\n",
      "\n",
      "Column 'People_PRF_IT_experience_great_than_9_yr':\n",
      "  Before: 7 categories\n",
      "  After:  22 categories\n",
      "  New categories added: [5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 17.0, 20.0, 21.0, 25.0]\n",
      "\n",
      "Column 'People_PRF_Project_manage_changes':\n",
      "  Before: 3 categories\n",
      "  After:  5 categories\n",
      "  New categories added: [3.0, 4.0]\n",
      "\n",
      "Column 'People_PRF_Personnel_changes':\n",
      "  Before: 5 categories\n",
      "  After:  16 categories\n",
      "  New categories added: [4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 15.0, 16.0, 21.0]\n",
      "\n",
      "Column 'Project_PRF_Cost_currency':\n",
      "  Before: 3 categories\n",
      "  After:  19 categories\n",
      "  New categories added: ['South Africa, rand', 'Sweden, krona', 'Australia, dollar', 'India, Rupees', 'Switzerland, franc', 'Malaysia, Renggette', 'Ecuador', 'Chinese, RMB', 'Germany, Mark', 'Netherlands, florin', 'TRL', 'Brazil, real', 'New Zealand, dollar', 'India, rupee', 'United Kingdom, pound sterling', 'Japan, yen']\n",
      "\n",
      "Column 'Project_PRF_Currency_multiple':\n",
      "  Before: 2 categories\n",
      "  After:  3 categories\n",
      "  New categories added: ['Yes 1,000']\n",
      "\n",
      "8. Checking for duplicate columns...\n",
      "\n",
      "9. Applying final preprocessing...\n",
      "============================================================\n",
      "ISBSG Data Preprocessing Pipeline\n",
      "============================================================\n",
      "Processing file: ../data\\temp_enhanced_sample.xlsx\n",
      "Target column (standardized): project_prf_normalised_work_effort\n",
      "Timestamp: 2025-06-01 16:19:25.058869\n",
      "Loading data from: ../data\\temp_enhanced_sample.xlsx\n",
      "Loaded data with shape: (1751, 52)\n",
      "Target column found: 'Project_PRF_Normalised Work Effort' -> will be standardized to 'project_prf_normalised_work_effort'\n",
      "Target column 'Project_PRF_Normalised Work Effort' -> 'project_prf_normalised_work_effort'\n",
      "Standardized 52 column names\n",
      "\n",
      "Missing value analysis:\n",
      "Columns with >50% missing: 28\n",
      "Columns with >70% missing: 21\n",
      "Dropping 21 columns with >70.0% missing values\n",
      "Filled project_prf_functional_size missing values with median: 193.0\n",
      "Filled project_prf_normalised_work_effort_level_1 missing values with median: 2260.0\n",
      "Filled project_prf_normalised_work_effort missing values with median: 2187.0\n",
      "Filled project_prf_normalised_level_1_pdr_ufp missing values with median: 9.9\n",
      "Filled project_prf_normalised_pdr_ufp missing values with median: 10.8\n",
      "Filled project_prf_defect_density missing values with median: 2.9\n",
      "Filled project_prf_speed_of_delivery missing values with median: 30.25\n",
      "Filled project_prf_manpower_delivery_rate missing values with median: 4.8\n",
      "Filled project_prf_project_elapsed_time missing values with median: 7.0\n",
      "Filled project_prf_max_team_size missing values with median: 7.0\n",
      "Filled people_prf_personnel_changes missing values with median: 0.0\n",
      "Data shape after missing value handling: (1751, 31)\n",
      "Found 4 columns with semicolons: ['external_eef_organisation_type', 'project_prf_application_group', 'project_prf_application_type', 'process_pmf_development_methodologies']\n",
      "Encoding 1 multi-value columns: ['project_prf_application_group']\n",
      "Encoded project_prf_application_group into 6 binary columns\n",
      "/nOne-hot encoding 9 categorical columns: ['external_eef_data_quality_rating', 'project_prf_development_type', 'tech_tf_development_platform', 'tech_tf_language_type', 'project_prf_relative_size', 'project_prf_case_tool_used', 'tech_tf_architecture', 'tech_tf_client_server', 'tech_tf_dbms_used']\n",
      "\n",
      "Unique values for each categorical column before one-hot encoding:\n",
      "  - external_eef_data_quality_rating: ['a', 'b', 'c', 'd']\n",
      "  - project_prf_development_type: ['enhancement', 'new development', 'not defined', 'other', 'poc', 'porting', 're-development']\n",
      "  - tech_tf_development_platform: ['Missing', 'hand held', 'mf', 'mr', 'multi', 'pc', 'proprietary']\n",
      "  - tech_tf_language_type: ['2gl', '3gl', '4gl', '5gl', 'Missing', 'apg']\n",
      "  - project_prf_relative_size: ['Missing', 'l', 'm1', 'm2', 's', 'xl', 'xs', 'xxl', 'xxs', 'xxxl']\n",
      "  - project_prf_case_tool_used: ['Missing', \"don't know\", 'no', 'yes']\n",
      "  - tech_tf_architecture: ['Missing', 'client server', 'multi-tier', 'multi-tier / client server', 'multi-tier with web interface', 'multi-tier with web public interface', 'stand alone', 'stand-alone']\n",
      "  - tech_tf_client_server: ['Missing', \"don't know\", 'no', 'not applicable', 'yes']\n",
      "  - tech_tf_dbms_used: ['Missing', 'no', 'yes']\n",
      "No duplicate column names after fixing\n",
      "Fixed 20 column names for PyCaret compatibility\n",
      "\n",
      "=== Final Data Validation ===\n",
      "Final shape: (1751, 72)\n",
      "Target column: project_prf_normalised_work_effort\n",
      "Total missing values: 0\n",
      "Total infinite values: 0\n",
      "\n",
      "Data types:\n",
      "  Numeric columns: 21\n",
      "  Categorical columns: 6\n",
      "\n",
      "Target variable 'project_prf_normalised_work_effort' statistics:\n",
      "  Mean: 6058.51\n",
      "  Std: 15032.85\n",
      "  Min: 6.00\n",
      "  Max: 266946.00\n",
      "  Missing: 0\n",
      "\n",
      "Processed data saved to: ../data\\temp_enhanced_sample_preprocessed.csv\n",
      "Pipeline saved to: ../data\\temp_enhanced_sample_preprocessing_pipeline.pkl\n",
      "Metadata saved to: ../data\\temp_enhanced_sample_preprocessing_metadata.txt\n",
      "\n",
      "============================================================\n",
      "Preprocessing completed successfully!\n",
      "============================================================\n",
      "\n",
      "10. Final validation and duplicate check...\n",
      "Original sample shape: (78, 52)\n",
      "Final processed shape: (1751, 72)\n",
      "Columns added: 20\n",
      "Rows added: 1673\n",
      "\n",
      "Warning: Found potentially duplicate columns:\n",
      "  - 'project_prf_application_group_mathematically_intensive_application' and 'project_prf_application_group_mathematically_intensive_application_1'\n",
      "  - 'tech_tf_architecture_stand_alone' and 'tech_tf_architecture_stand_alone_1'\n",
      "Consider reviewing your preprocessing functions to avoid double processing.\n",
      "\n",
      "============================================================\n",
      "PIPELINE COMPLETED SUCCESSFULLY!\n",
      "============================================================\n",
      "Final dataset saved to: ../data\\enhanced_sample_final.csv\n",
      "Final shape: (1751, 72)\n",
      "Ready for PyCaret setup!\n",
      "\n",
      "SUMMARY:\n",
      "- Original sample rows: 78\n",
      "- Rows added from full dataset: 1673\n",
      "- Final rows: 1751\n",
      "- Original columns: 52\n",
      "- Final columns: 72\n",
      "Cell executed at: 2025-06-01 16:19:26.780577\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    final_df, metadata = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9901f5-b172-4910-9012-1b41f1613c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c188e-6b75-4594-884b-041e49ff40c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5c8df-c459-477a-9eb8-c86337e16a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a1359-5996-453f-a314-22551e0efe97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c40def56-4dad-4aab-aee3-2520a2a5d72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== QUICK VALIDATION SUMMARY ===\n",
      "\n",
      "\n",
      "Dataset size: 7518 â†’ 7518 rows\n",
      "Column count: 52 â†’ 52\n",
      "Original columns: 52\n",
      "Processed columns: 52\n",
      "New columns created: 2\n",
      "Validation functions ready to use!\n"
     ]
    }
   ],
   "source": [
    "# Handling multi-value categorical cols\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load original data\n",
    "    df_original = pd.read_excel(f\"{DATA_FOLDER}/{FULL_FILE}\")\n",
    "    \n",
    "    # Identify your high-cardinality multi-value columns\n",
    "    high_card_columns = ['external_eef_organisation_type', 'project_prf_application_type']  # Updated with actual columns\n",
    "    \n",
    "    # Analyze each column\n",
    "    for col in high_card_columns:\n",
    "        if col in df_original.columns:\n",
    "            recommend_strategy(df_original, col, separator=';')\n",
    "            print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # 2. Process with recommended strategy\n",
    "    df_processed, col_mapping = handle_high_cardinality_multivalue(\n",
    "        df_original,\n",
    "        multi_value_columns=high_card_columns,\n",
    "        separator=';',\n",
    "        strategy='top_k',  # Choose based on recommendations\n",
    "        k=20  # Keep top 20 most frequent values\n",
    "    )\n",
    "\n",
    "    # 3. Quick validation\n",
    "    quick_validation_summary(df_original, df_processed, col_mapping)\n",
    "    \n",
    "    # 4. Detailed validation for specific columns\n",
    "    for original_col, new_cols in col_mapping.items():\n",
    "         validate_multivalue_processing(\n",
    "             df_original, df_processed, original_col, new_cols, \n",
    "             separator=';', strategy='top_k'\n",
    "         )\n",
    "    \n",
    "    print(f\"Original columns: {len(df_original.columns)}\")\n",
    "    print(f\"Processed columns: {len(df_processed.columns)}\")\n",
    "    print(f\"New columns created: {len(df_processed.columns) - len(df_original.columns) + len(high_card_columns)}\")\n",
    "\n",
    "    print(\"Validation functions ready to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8679ca1-43cd-40fb-87d2-cca7a018f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your datasets from Excel files\n",
    "    sample_df = pd.read_excel(f\"{DATA_FOLDER} / {SAMPLE_FILE}\")  # Your limited sample\n",
    "    full_df = pd.read_excel(f\"{DATA_FOLDER} / {FULL_FILE}\")  # Your complete dataset\n",
    "    \n",
    "   \n",
    "    # Auto-detect categorical columns\n",
    "    categorical_columns = []\n",
    "    for col in sample_df.columns:\n",
    "        if sample_df[col].dtype == 'object' or sample_df[col].nunique() < 20:\n",
    "            categorical_columns.append(col)\n",
    "    \n",
    "    print(\"Categorical columns to process:\", categorical_columns)\n",
    "    \n",
    "    # Enhance the sample with missing categories\n",
    "    enhanced_df = add_missing_categories_from_full_dataset(\n",
    "        sample_df=sample_df,\n",
    "        full_df=full_df,\n",
    "        categorical_columns=categorical_columns,\n",
    "        samples_per_category=3  # Add 3 examples per missing category\n",
    "    )\n",
    "    \n",
    "    # Verify the results\n",
    "    verify_categories_coverage(sample_df, enhanced_df, categorical_columns)\n",
    "    \n",
    "    # Save the enhanced dataset\n",
    "    enhanced_df.to_csv('../data/sample_enhanced_with_missing_categories.csv', index=False)\n",
    "    print(f\"\\nEnhanced dataset saved to: '../data/sample_enhanced_with_missing_categories.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760772b7-c194-4a70-9f14-03303ebb1868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c183a-3940-4b3c-9d71-914a50df3549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22958d39-aeca-4006-8801-d9c03ff40d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f3790-f8ab-4ae6-9dff-7ed5a29fc7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62895741-3d44-4748-982b-811d038539e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ISBSG Data Preprocessing Pipeline\n",
      "============================================================\n",
      "Processing file: ../data\\sample_clean_a_agile_only.xlsx\n",
      "Target column (standardized): Project_PRF_Normalised_Work_Effort\n",
      "Timestamp: 2025-05-31 17:32:41.635778\n",
      "Loading data from: ../data\\sample_clean_a_agile_only.xlsx\n",
      "Loaded data with shape: (78, 52)\n",
      "Target column found: 'Project_PRF_Normalised Work Effort' -> will be standardized to 'Project_PRF_Normalised_Work_Effort'\n",
      "Target column 'Project_PRF_Normalised Work Effort' -> 'Project_PRF_Normalised_Work_Effort'\n",
      "Standardized 52 column names\n",
      "\n",
      "Missing value analysis:\n",
      "Columns with >50% missing: 25\n",
      "Columns with >70% missing: 18\n",
      "Dropping 18 columns with >70.0% missing values\n",
      "Filled project_prf_functional_size missing values with median: 82.0\n",
      "Filled project_prf_normalised_level_1_pdr_ufp missing values with median: 3.5\n",
      "Filled project_prf_normalised_pdr_ufp missing values with median: 3.5\n",
      "Filled project_prf_defect_density missing values with median: 0.0\n",
      "Filled project_prf_speed_of_delivery missing values with median: 28.6\n",
      "Filled project_prf_manpower_delivery_rate missing values with median: 2.1\n",
      "Filled project_prf_project_elapsed_time missing values with median: 5.0\n",
      "Filled project_prf_max_team_size missing values with median: 2.0\n",
      "Filled people_prf_project_manage_changes missing values with median: 0.0\n",
      "Filled people_prf_personnel_changes missing values with median: 0.0\n",
      "Filled project_prf_total_project_cost missing values with median: 60775.0\n",
      "Data shape after missing value handling: (78, 34)\n",
      "Found 3 columns with semicolons: ['external_eef_organisation_type', 'project_prf_application_type', 'process_pmf_development_methodologies']\n",
      "Encoding 0 multi-value columns: []\n",
      "One-hot encoding 13 categorical columns: ['external_eef_data_quality_rating', 'project_prf_application_group', 'project_prf_development_type', 'tech_tf_development_platform', 'tech_tf_language_type', 'tech_tf_primary_programming_language', 'project_prf_relative_size', 'project_prf_team_size_group', 'tech_tf_architecture', 'tech_tf_client_server', 'tech_tf_web_development', 'tech_tf_dbms_used', 'project_prf_cost_currency']\n",
      "No duplicate column names after fixing\n",
      "Fixed 19 column names for PyCaret compatibility\n",
      "\n",
      "=== Final Data Validation ===\n",
      "Final shape: (78, 69)\n",
      "Target column: Project_PRF_Normalised_Work_Effort\n",
      "Total missing values: 0\n",
      "Total infinite values: 0\n",
      "\n",
      "Data types:\n",
      "  Numeric columns: 17\n",
      "  Categorical columns: 4\n",
      "\n",
      "Target variable 'Project_PRF_Normalised_Work_Effort' statistics:\n",
      "  Mean: 3362.71\n",
      "  Std: 10643.13\n",
      "  Min: 6.00\n",
      "  Max: 60047.00\n",
      "  Missing: 0\n",
      "\n",
      "Processed data saved to: ../data\\sample_clean_a_agile_only_preprocessed.csv\n",
      "Pipeline saved to: ../data\\sample_clean_a_agile_only_preprocessing_pipeline.pkl\n",
      "Metadata saved to: ../data\\sample_clean_a_agile_only_preprocessing_metadata.txt\n",
      "\n",
      "============================================================\n",
      "Preprocessing completed successfully!\n",
      "============================================================\n",
      "\n",
      "Final dataset shape: (78, 69)\n",
      "Columns: ['isbsg_project_id', 'project_prf_year_of_project', 'external_eef_industry_sector', 'external_eef_organisation_type', 'project_prf_application_type', 'project_prf_functional_size', 'project_prf_normalised_work_effort_level_1', 'Project_PRF_Normalised_Work_Effort', 'project_prf_normalised_level_1_pdr_ufp', 'project_prf_normalised_pdr_ufp']...\n",
      "\n",
      "Dataset is now ready for PyCaret setup!\n"
     ]
    }
   ],
   "source": [
    "# Execution: usage and testing\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # File path\n",
    "    file_path = os.path.join(DATA_FOLDER, SAMPLE_FILE)\n",
    "    \n",
    "    # Custom configuration\n",
    "    cols_to_keep = [\n",
    "        'Project_PRF_CASE_Tool_Used', \n",
    "        'Process_PMF_Prototyping_Used',\n",
    "        'Tech_TF_Client_Roles', \n",
    "        'Tech_TF_Type_of_Server', \n",
    "        'Tech_TF_ClientServer_Description'\n",
    "    ]\n",
    "    \n",
    "    # Specific standardization rules for individual components (after cleaning)\n",
    "    standardization_map = {\n",
    "        'stand alone': 'stand-alone',\n",
    "        'client server': 'client-server',\n",
    "        'mathematically intensive': 'mathematically-intensive',\n",
    "        'mathematically intensive application': 'mathematically-intensive application',\n",
    "        \"file &/or print server\": \"file/print server\",\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Run preprocessing\n",
    "        df_processed, metadata = preprocess_isbsg_data(\n",
    "            file_path=file_path,\n",
    "            target_col=TARGET_COL,\n",
    "            output_dir=DATA_FOLDER,\n",
    "            cols_to_keep=cols_to_keep,\n",
    "            max_categorical_cardinality=10,\n",
    "            standardization_mapping=standardization_map,\n",
    "            high_missing_threshold=0.7\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nFinal dataset shape: {df_processed.shape}\")\n",
    "        print(f\"Columns: {list(df_processed.columns[:10])}...\")  # Show first 10 columns\n",
    "        \n",
    "        # Ready for PyCaret setup\n",
    "        print(\"\\nDataset is now ready for PyCaret setup!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during preprocessing: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47df44c0-f73a-479d-98f1-3e7886cef03f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
