{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f30650-ed19-4abf-bb03-5ef4005a32cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e08f925-be6c-46dc-92b4-da99269eda09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Complete Scikit-Learn Preprocessing Pipeline for ISBSG Data\\n    ===========================================================\\n\\n    This module provides a comprehensive preprocessing pipeline that handles:\\n    1. Data loading and initial cleaning\\n    2. Column name standardization\\n    3. Missing value handling\\n    4. Semicolon-separated value processing\\n    5. One-hot encoding for categorical variables\\n    6. Multi-label binarization for multi-value columns\\n    7. Feature selection and filtering\\n    8. Data validation and export\\n\\n    Based on the preprocessing steps from the provided notebooks.\\n   '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Complete Scikit-Learn Preprocessing Pipeline for ISBSG Data\n",
    "    ===========================================================\n",
    "    \n",
    "    This module provides a comprehensive preprocessing pipeline that handles:\n",
    "    1. Data loading and initial cleaning\n",
    "    2. Column name standardization\n",
    "    3. Missing value handling\n",
    "    4. Semicolon-separated value processing\n",
    "    5. One-hot encoding for categorical variables\n",
    "    6. Multi-label binarization for multi-value columns\n",
    "    7. Feature selection and filtering\n",
    "    8. Data validation and export\n",
    "    \n",
    "    Based on the preprocessing steps from the provided notebooks.\n",
    "   \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2848fe58-b966-47fe-9339-6eea3764c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Dict, Any, Tuple\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b649e731-d0f9-4bf8-95ed-428c9c818aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_FOLDER = \"../data\"\n",
    "CONFIG_FOLDER = \"../config\"\n",
    "SAMPLE_FILE = \"ISBSG2016R1_1_financial_industry_seed.xlsx\"\n",
    "FULL_FILE = \"ISBSG2016R1_1_full_dataset.xlsx\"\n",
    "TARGET_COL = \"project_prf_normalised_work_effort\"  # be careful about case sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9986b36b-4364-4284-9381-c6ae3d99abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def analyze_high_cardinality_multivalue(df, column, separator=';'):\n",
    "    \"\"\"\n",
    "    Analyze high-cardinality multi-value columns to choose best strategy\n",
    "    \"\"\"\n",
    "    print(f\"=== ANALYSIS FOR HIGH-CARDINALITY COLUMN: '{column}' ===\\n\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    non_null_data = df[column].dropna().astype(str)\n",
    "    split_values = non_null_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    # Get all unique values\n",
    "    all_values = []\n",
    "    for values_list in split_values:\n",
    "        all_values.extend(values_list)\n",
    "    \n",
    "    value_counts = Counter(all_values)\n",
    "    unique_values = list(value_counts.keys())\n",
    "    \n",
    "    print(f\"Total unique values: {len(unique_values)}\")\n",
    "    print(f\"Total value occurrences: {len(all_values)}\")\n",
    "    print(f\"Average values per row: {len(all_values) / len(split_values):.2f}\")\n",
    "    \n",
    "    # Show most common values\n",
    "    print(f\"\\nTop 15 most common values:\")\n",
    "    for value, count in value_counts.most_common(15):\n",
    "        percentage = (count / len(non_null_data)) * 100\n",
    "        print(f\"  '{value}': {count} times ({percentage:.1f}% of rows)\")\n",
    "    \n",
    "    # Show distribution of value frequencies\n",
    "    frequency_dist = Counter(value_counts.values())\n",
    "    print(f\"\\nFrequency distribution:\")\n",
    "    for freq, count in sorted(frequency_dist.items(), reverse=True)[:10]:\n",
    "        print(f\"  {count} values appear {freq} time(s)\")\n",
    "    \n",
    "    # Values per row distribution\n",
    "    values_per_row = split_values.apply(len)\n",
    "    print(f\"\\nValues per row:\")\n",
    "    print(f\"  Min: {values_per_row.min()}\")\n",
    "    print(f\"  Max: {values_per_row.max()}\")\n",
    "    print(f\"  Mean: {values_per_row.mean():.2f}\")\n",
    "    print(f\"  Median: {values_per_row.median():.2f}\")\n",
    "    \n",
    "    return value_counts, unique_values\n",
    "\n",
    "\n",
    "def handle_high_cardinality_multivalue(df, multi_value_columns, separator=';', strategy='top_k', **kwargs):\n",
    "    \"\"\"\n",
    "    Handle high-cardinality multi-value columns with various strategies\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    strategy options:\n",
    "    - 'top_k': Keep only top K most frequent values (k=kwargs['k'])\n",
    "    - 'frequency_threshold': Keep values that appear in at least X% of rows (threshold=kwargs['threshold'])\n",
    "    - 'tfidf': Use TF-IDF vectorization with dimensionality reduction (n_components=kwargs['n_components'])\n",
    "    - 'count_features': Simple counting features (count, unique_count, most_common)\n",
    "    - 'embedding': Create category embeddings (requires pre-trained embeddings)\n",
    "    \"\"\"\n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    new_columns_mapping = {}\n",
    "    \n",
    "    for col in multi_value_columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing high-cardinality column '{col}' with strategy '{strategy}'...\")\n",
    "        \n",
    "        # Clean and split values\n",
    "        split_values = df[col].fillna('').astype(str).apply(\n",
    "            lambda x: [val.strip() for val in x.split(separator) if val.strip()]\n",
    "        )\n",
    "        \n",
    "        # Get value counts\n",
    "        all_values = []\n",
    "        for values_list in split_values:\n",
    "            all_values.extend(values_list)\n",
    "        value_counts = Counter(all_values)\n",
    "        \n",
    "        if strategy == 'top_k':\n",
    "            k = kwargs.get('k', 20)  # Default to top 20\n",
    "            top_values = [val for val, count in value_counts.most_common(k)]\n",
    "            \n",
    "            new_col_names = []\n",
    "            for value in top_values:\n",
    "                new_col_name = f\"{col}_top_{value}\".replace(' ', '_').replace('-', '_')\n",
    "                df_processed[new_col_name] = split_values.apply(lambda x: 1 if value in x else 0)\n",
    "                new_col_names.append(new_col_name)\n",
    "            \n",
    "            # Add \"other\" category for remaining values\n",
    "            other_col_name = f\"{col}_other\"\n",
    "            df_processed[other_col_name] = split_values.apply(\n",
    "                lambda x: 1 if any(val not in top_values for val in x) else 0\n",
    "            )\n",
    "            new_col_names.append(other_col_name)\n",
    "            \n",
    "            new_columns_mapping[col] = new_col_names\n",
    "            print(f\"  Created {len(new_col_names)} columns (top {k} + other)\")\n",
    "            \n",
    "        elif strategy == 'frequency_threshold':\n",
    "            threshold = kwargs.get('threshold', 0.05)  # Default 5%\n",
    "            min_occurrences = int(len(df) * threshold)\n",
    "            \n",
    "            frequent_values = [val for val, count in value_counts.items() if count >= min_occurrences]\n",
    "            \n",
    "            new_col_names = []\n",
    "            for value in frequent_values:\n",
    "                new_col_name = f\"{col}_freq_{value}\".replace(' ', '_').replace('-', '_')\n",
    "                df_processed[new_col_name] = split_values.apply(lambda x: 1 if value in x else 0)\n",
    "                new_col_names.append(new_col_name)\n",
    "            \n",
    "            # Add rare category\n",
    "            rare_col_name = f\"{col}_rare\"\n",
    "            df_processed[rare_col_name] = split_values.apply(\n",
    "                lambda x: 1 if any(val not in frequent_values for val in x) else 0\n",
    "            )\n",
    "            new_col_names.append(rare_col_name)\n",
    "            \n",
    "            new_columns_mapping[col] = new_col_names\n",
    "            print(f\"  Created {len(new_col_names)} columns ({len(frequent_values)} frequent + rare)\")\n",
    "            \n",
    "        elif strategy == 'count_features':\n",
    "            # Create aggregate features instead of individual columns\n",
    "            new_col_names = []\n",
    "            \n",
    "            # Total count of values\n",
    "            count_col = f\"{col}_count\"\n",
    "            df_processed[count_col] = split_values.apply(len)\n",
    "            new_col_names.append(count_col)\n",
    "            \n",
    "            # Unique count (in case of duplicates)\n",
    "            unique_count_col = f\"{col}_unique_count\"\n",
    "            df_processed[unique_count_col] = split_values.apply(lambda x: len(set(x)))\n",
    "            new_col_names.append(unique_count_col)\n",
    "            \n",
    "            # Most common value in the dataset appears in this row\n",
    "            most_common_value = value_counts.most_common(1)[0][0] if value_counts else None\n",
    "            if most_common_value:\n",
    "                most_common_col = f\"{col}_has_most_common\"\n",
    "                df_processed[most_common_col] = split_values.apply(lambda x: 1 if most_common_value in x else 0)\n",
    "                new_col_names.append(most_common_col)\n",
    "            \n",
    "            # Average frequency of values in this row\n",
    "            avg_freq_col = f\"{col}_avg_frequency\"\n",
    "            df_processed[avg_freq_col] = split_values.apply(\n",
    "                lambda x: np.mean([value_counts[val] for val in x]) if x else 0\n",
    "            )\n",
    "            new_col_names.append(avg_freq_col)\n",
    "            \n",
    "            new_columns_mapping[col] = new_col_names\n",
    "            print(f\"  Created {len(new_col_names)} aggregate feature columns\")\n",
    "            \n",
    "        elif strategy == 'tfidf':\n",
    "            n_components = kwargs.get('n_components', 10)  # Default to 10 components\n",
    "            \n",
    "            # Convert to text format for TF-IDF\n",
    "            text_data = split_values.apply(lambda x: ' '.join(x))\n",
    "            \n",
    "            # Apply TF-IDF\n",
    "            tfidf = TfidfVectorizer(max_features=100, stop_words=None)\n",
    "            tfidf_matrix = tfidf.fit_transform(text_data)\n",
    "            \n",
    "            # Reduce dimensionality\n",
    "            pca = PCA(n_components=n_components)\n",
    "            tfidf_reduced = pca.fit_transform(tfidf_matrix.toarray())\n",
    "            \n",
    "            # Create new columns\n",
    "            new_col_names = []\n",
    "            for i in range(n_components):\n",
    "                new_col_name = f\"{col}_tfidf_comp_{i+1}\"\n",
    "                df_processed[new_col_name] = tfidf_reduced[:, i]\n",
    "                new_col_names.append(new_col_name)\n",
    "            \n",
    "            new_columns_mapping[col] = new_col_names\n",
    "            print(f\"  Created {len(new_col_names)} TF-IDF component columns\")\n",
    "            print(f\"  Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "            \n",
    "        elif strategy == 'hierarchical':\n",
    "            # Group similar values into higher-level categories\n",
    "            # This requires domain knowledge - example implementation\n",
    "            hierarchy = kwargs.get('hierarchy', {})  # Dictionary mapping values to categories\n",
    "            \n",
    "            if not hierarchy:\n",
    "                print(\"  Warning: No hierarchy provided for hierarchical strategy\")\n",
    "                continue\n",
    "            \n",
    "            # Create columns for each high-level category\n",
    "            categories = set(hierarchy.values())\n",
    "            new_col_names = []\n",
    "            \n",
    "            for category in categories:\n",
    "                category_values = [val for val, cat in hierarchy.items() if cat == category]\n",
    "                new_col_name = f\"{col}_category_{category}\".replace(' ', '_')\n",
    "                df_processed[new_col_name] = split_values.apply(\n",
    "                    lambda x: 1 if any(val in category_values for val in x) else 0\n",
    "                )\n",
    "                new_col_names.append(new_col_name)\n",
    "            \n",
    "            new_columns_mapping[col] = new_col_names\n",
    "            print(f\"  Created {len(new_col_names)} hierarchical category columns\")\n",
    "        \n",
    "        # Remove original column\n",
    "        df_processed = df_processed.drop(columns=[col])\n",
    "    \n",
    "    return df_processed, new_columns_mapping\n",
    "\n",
    "\n",
    "def recommend_strategy(df, column, separator=';'):\n",
    "    \"\"\"\n",
    "    Recommend the best strategy based on data characteristics\n",
    "    \"\"\"\n",
    "    value_counts, unique_values = analyze_high_cardinality_multivalue(df, column, separator)\n",
    "    \n",
    "    total_unique = len(unique_values)\n",
    "    total_rows = len(df[column].dropna())\n",
    "    \n",
    "    print(f\"\\n=== STRATEGY RECOMMENDATIONS FOR '{column}' ===\")\n",
    "    \n",
    "    if total_unique > 100:\n",
    "        print(\"ðŸ”´ VERY HIGH CARDINALITY (100+ unique values)\")\n",
    "        print(\"Recommended strategies:\")\n",
    "        print(\"1. 'count_features' - Create aggregate features (safest)\")\n",
    "        print(\"2. 'top_k' with k=15-25 - Keep only most important values\")\n",
    "        print(\"3. 'tfidf' with n_components=5-10 - If values have semantic meaning\")\n",
    "        \n",
    "    elif total_unique > 50:\n",
    "        print(\"ðŸŸ¡ HIGH CARDINALITY (50+ unique values)\")\n",
    "        print(\"Recommended strategies:\")\n",
    "        print(\"1. 'top_k' with k=20-30 - Keep most frequent values\")\n",
    "        print(\"2. 'frequency_threshold' with threshold=0.02-0.05\")\n",
    "        print(\"3. 'count_features' - If you want aggregate information\")\n",
    "        \n",
    "    else:\n",
    "        print(\"ðŸŸ¢ MODERATE CARDINALITY (<50 unique values)\")\n",
    "        print(\"Recommended strategies:\")\n",
    "        print(\"1. 'frequency_threshold' with threshold=0.01\")\n",
    "        print(\"2. 'top_k' with k=30-40\")\n",
    "        print(\"3. Binary encoding might be acceptable\")\n",
    "    \n",
    "    # Check frequency distribution\n",
    "    freq_values = list(value_counts.values())\n",
    "    if max(freq_values) / min(freq_values) > 100:\n",
    "        print(\"\\nâš ï¸  HIGHLY SKEWED DISTRIBUTION detected\")\n",
    "        print(\"   Consider 'frequency_threshold' or 'top_k' strategies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24140d94-4ab5-4228-aa1f-cc0fc2081b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_multivalue_processing(df_original, df_processed, original_column, new_columns, separator=';', strategy='top_k'):\n",
    "    \"\"\"\n",
    "    Comprehensive validation of multi-value categorical processing\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_original : pd.DataFrame\n",
    "        Original dataset before processing\n",
    "    df_processed : pd.DataFrame  \n",
    "        Processed dataset after handling multi-value columns\n",
    "    original_column : str\n",
    "        Name of original multi-value column\n",
    "    new_columns : list\n",
    "        List of new column names created from the original column\n",
    "    separator : str\n",
    "        Separator used in original data\n",
    "    strategy : str\n",
    "        Strategy used for processing\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"=== VALIDATION REPORT FOR COLUMN '{original_column}' ===\\n\")\n",
    "    \n",
    "    # 1. BASIC CHECKS\n",
    "    print(\"1. BASIC INTEGRITY CHECKS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Check row count consistency\n",
    "    original_rows = len(df_original)\n",
    "    processed_rows = len(df_processed)\n",
    "    print(f\"âœ“ Row count: {original_rows} â†’ {processed_rows} {'âœ“ SAME' if original_rows == processed_rows else 'âš ï¸  DIFFERENT'}\")\n",
    "    \n",
    "    # Check if original column was removed\n",
    "    original_removed = original_column not in df_processed.columns\n",
    "    print(f\"âœ“ Original column removed: {'âœ“ YES' if original_removed else 'âš ï¸  NO'}\")\n",
    "    \n",
    "    # Check if new columns exist\n",
    "    new_cols_exist = all(col in df_processed.columns for col in new_columns)\n",
    "    print(f\"âœ“ New columns created: {'âœ“ YES' if new_cols_exist else 'âŒ NO'} ({len(new_columns)} columns)\")\n",
    "    \n",
    "    if not new_cols_exist:\n",
    "        missing_cols = [col for col in new_columns if col not in df_processed.columns]\n",
    "        print(f\"  Missing columns: {missing_cols}\")\n",
    "        return False\n",
    "    \n",
    "    # 2. DATA CONSISTENCY CHECKS\n",
    "    print(f\"\\n2. DATA CONSISTENCY CHECKS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Parse original data\n",
    "    original_data = df_original[original_column].fillna('').astype(str)\n",
    "    split_original = original_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    # Get all unique values from original\n",
    "    all_original_values = set()\n",
    "    for values_list in split_original:\n",
    "        all_original_values.update(values_list)\n",
    "    all_original_values = sorted([v for v in all_original_values if v and v != 'nan'])\n",
    "    \n",
    "    print(f\"Original unique values: {len(all_original_values)}\")\n",
    "    \n",
    "    if strategy == 'top_k':\n",
    "        # Validate top-k strategy\n",
    "        validate_top_k_strategy(df_original, df_processed, original_column, new_columns, separator)\n",
    "    elif strategy == 'count_features':\n",
    "        validate_count_features_strategy(df_original, df_processed, original_column, new_columns, separator)\n",
    "    elif strategy == 'frequency_threshold':\n",
    "        validate_frequency_threshold_strategy(df_original, df_processed, original_column, new_columns, separator)\n",
    "    \n",
    "    # 3. SAMPLE VALIDATION\n",
    "    print(f\"\\n3. SAMPLE-BY-SAMPLE VALIDATION\")\n",
    "    print(\"-\" * 40)\n",
    "    validate_sample_rows(df_original, df_processed, original_column, new_columns, separator, n_samples=5)\n",
    "    \n",
    "    # 4. STATISTICAL VALIDATION\n",
    "    print(f\"\\n4. STATISTICAL VALIDATION\")\n",
    "    print(\"-\" * 40)\n",
    "    validate_statistics(df_original, df_processed, original_column, new_columns, separator)\n",
    "    \n",
    "    # 5. INFORMATION LOSS ASSESSMENT\n",
    "    print(f\"\\n5. INFORMATION LOSS ASSESSMENT\")\n",
    "    print(\"-\" * 40)\n",
    "    assess_information_loss(df_original, df_processed, original_column, new_columns, separator)\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def validate_top_k_strategy(df_original, df_processed, original_column, new_columns, separator, k=None):\n",
    "    \"\"\"Validate top-k strategy specifically\"\"\"\n",
    "    \n",
    "    # Parse original data\n",
    "    original_data = df_original[original_column].fillna('').astype(str)\n",
    "    split_original = original_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    # Get value counts\n",
    "    all_values = []\n",
    "    for values_list in split_original:\n",
    "        all_values.extend(values_list)\n",
    "    value_counts = Counter(all_values)\n",
    "    \n",
    "    # Determine k if not provided\n",
    "    if k is None:\n",
    "        # Exclude \"other\" column to determine k\n",
    "        non_other_cols = [col for col in new_columns if not col.endswith('_other')]\n",
    "        k = len(non_other_cols)\n",
    "    \n",
    "    top_k_values = [val for val, count in value_counts.most_common(k)]\n",
    "    print(f\"Top {k} values: {top_k_values[:5]}{'...' if len(top_k_values) > 5 else ''}\")\n",
    "    \n",
    "    # Check each top-k column\n",
    "    for col in new_columns:\n",
    "        if col.endswith('_other'):\n",
    "            # Validate \"other\" column\n",
    "            validate_other_column(df_original, df_processed, original_column, col, top_k_values, separator)\n",
    "        else:\n",
    "            # Extract the value name from column name\n",
    "            value_name = col.replace(f\"{original_column}_top_\", \"\").replace(f\"{original_column}_\", \"\")\n",
    "            validate_binary_column(df_original, df_processed, original_column, col, value_name, separator)\n",
    "\n",
    "\n",
    "def validate_binary_column(df_original, df_processed, original_column, new_column, value_name, separator):\n",
    "    \"\"\"Validate a single binary column\"\"\"\n",
    "    \n",
    "    # Parse original data\n",
    "    original_data = df_original[original_column].fillna('').astype(str)\n",
    "    split_original = original_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    # Expected values: 1 if value_name in the list, 0 otherwise\n",
    "    expected = split_original.apply(lambda x: 1 if value_name in x else 0)\n",
    "    actual = df_processed[new_column]\n",
    "    \n",
    "    # Compare\n",
    "    matches = (expected == actual).sum()\n",
    "    total = len(expected)\n",
    "    match_rate = matches / total * 100\n",
    "    \n",
    "    print(f\"  '{new_column}': {matches}/{total} matches ({match_rate:.1f}%)\")\n",
    "    \n",
    "    if match_rate < 100:\n",
    "        mismatches = df_original.loc[expected != actual, original_column].head(3)\n",
    "        print(f\"    Sample mismatches: {list(mismatches)}\")\n",
    "\n",
    "\n",
    "def validate_other_column(df_original, df_processed, original_column, other_column, top_values, separator):\n",
    "    \"\"\"Validate the 'other' category column\"\"\"\n",
    "    \n",
    "    # Parse original data\n",
    "    original_data = df_original[original_column].fillna('').astype(str)\n",
    "    split_original = original_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    # Expected: 1 if any value is NOT in top_values, 0 if all values are in top_values\n",
    "    expected = split_original.apply(lambda x: 1 if any(val not in top_values for val in x) else 0)\n",
    "    actual = df_processed[other_column]\n",
    "    \n",
    "    matches = (expected == actual).sum()\n",
    "    total = len(expected)\n",
    "    match_rate = matches / total * 100\n",
    "    \n",
    "    print(f\"  '{other_column}': {matches}/{total} matches ({match_rate:.1f}%)\")\n",
    "\n",
    "\n",
    "def validate_count_features_strategy(df_original, df_processed, original_column, new_columns, separator):\n",
    "    \"\"\"Validate count features strategy\"\"\"\n",
    "    \n",
    "    # Parse original data\n",
    "    original_data = df_original[original_column].fillna('').astype(str)\n",
    "    split_original = original_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    for col in new_columns:\n",
    "        if col.endswith('_count'):\n",
    "            # Validate total count\n",
    "            expected = split_original.apply(len)\n",
    "            actual = df_processed[col]\n",
    "            matches = (expected == actual).sum()\n",
    "            print(f\"  '{col}': {matches}/{len(expected)} matches ({matches/len(expected)*100:.1f}%)\")\n",
    "            \n",
    "        elif col.endswith('_unique_count'):\n",
    "            # Validate unique count\n",
    "            expected = split_original.apply(lambda x: len(set(x)))\n",
    "            actual = df_processed[col]\n",
    "            matches = (expected == actual).sum()\n",
    "            print(f\"  '{col}': {matches}/{len(expected)} matches ({matches/len(expected)*100:.1f}%)\")\n",
    "\n",
    "\n",
    "def validate_frequency_threshold_strategy(df_original, df_processed, original_column, new_columns, separator):\n",
    "    \"\"\"Validate frequency threshold strategy\"\"\"\n",
    "    \n",
    "    # Parse original data\n",
    "    original_data = df_original[original_column].fillna('').astype(str)\n",
    "    split_original = original_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    # Get value counts\n",
    "    all_values = []\n",
    "    for values_list in split_original:\n",
    "        all_values.extend(values_list)\n",
    "    value_counts = Counter(all_values)\n",
    "    \n",
    "    for col in new_columns:\n",
    "        if col.endswith('_rare'):\n",
    "            # Validate rare column - similar to other column validation\n",
    "            continue\n",
    "        else:\n",
    "            # Extract the value name from column name\n",
    "            value_name = col.replace(f\"{original_column}_freq_\", \"\").replace(f\"{original_column}_\", \"\")\n",
    "            validate_binary_column(df_original, df_processed, original_column, col, value_name, separator)\n",
    "\n",
    "\n",
    "def validate_sample_rows(df_original, df_processed, original_column, new_columns, separator, n_samples=5):\n",
    "    \"\"\"Manually validate a few sample rows\"\"\"\n",
    "    \n",
    "    print(f\"Validating {n_samples} random samples:\")\n",
    "    \n",
    "    # Get random sample indices\n",
    "    sample_indices = np.random.choice(len(df_original), min(n_samples, len(df_original)), replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices, 1):\n",
    "        original_value = df_original.iloc[idx][original_column]\n",
    "        if pd.isna(original_value):\n",
    "            original_values = []\n",
    "        else:\n",
    "            original_values = [v.strip() for v in str(original_value).split(separator) if v.strip()]\n",
    "        \n",
    "        print(f\"\\n  Sample {i} (row {idx}):\")\n",
    "        print(f\"    Original: '{original_value}'\")\n",
    "        print(f\"    Parsed: {original_values}\")\n",
    "        \n",
    "        # Check new columns for this row\n",
    "        for col in new_columns[:5]:  # Show first 5 columns only\n",
    "            processed_value = df_processed.iloc[idx][col]\n",
    "            print(f\"    {col}: {processed_value}\")\n",
    "\n",
    "\n",
    "def validate_statistics(df_original, df_processed, original_column, new_columns, separator):\n",
    "    \"\"\"Validate statistical properties\"\"\"\n",
    "    \n",
    "    # Parse original data\n",
    "    original_data = df_original[original_column].fillna('').astype(str)\n",
    "    split_original = original_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    # Original statistics\n",
    "    values_per_row = split_original.apply(len)\n",
    "    print(f\"Original values per row - Mean: {values_per_row.mean():.2f}, Std: {values_per_row.std():.2f}\")\n",
    "    \n",
    "    # New data statistics\n",
    "    if any('_count' in col for col in new_columns):\n",
    "        count_col = [col for col in new_columns if col.endswith('_count')][0]\n",
    "        new_counts = df_processed[count_col]\n",
    "        print(f\"Processed counts - Mean: {new_counts.mean():.2f}, Std: {new_counts.std():.2f}\")\n",
    "        \n",
    "        # They should match!\n",
    "        correlation = np.corrcoef(values_per_row, new_counts)[0, 1]\n",
    "        print(f\"Correlation between original and processed counts: {correlation:.4f}\")\n",
    "    \n",
    "    # Check for any impossible values\n",
    "    binary_cols = [col for col in new_columns if not col.endswith(('_count', '_frequency', '_avg_frequency'))]\n",
    "    for col in binary_cols:\n",
    "        unique_vals = df_processed[col].unique()\n",
    "        if not set(unique_vals).issubset({0, 1, np.nan}):\n",
    "            print(f\"âš ï¸  Warning: Non-binary values in '{col}': {unique_vals}\")\n",
    "\n",
    "\n",
    "def assess_information_loss(df_original, df_processed, original_column, new_columns, separator):\n",
    "    \"\"\"Assess how much information was lost in the transformation\"\"\"\n",
    "    \n",
    "    # Parse original data\n",
    "    original_data = df_original[original_column].fillna('').astype(str)\n",
    "    split_original = original_data.apply(lambda x: [v.strip() for v in x.split(separator) if v.strip()])\n",
    "    \n",
    "    # Get all unique values\n",
    "    all_original_values = set()\n",
    "    for values_list in split_original:\n",
    "        all_original_values.update(values_list)\n",
    "    all_original_values = sorted([v for v in all_original_values if v and v != 'nan'])\n",
    "    \n",
    "    # Count how many unique values are captured by new columns\n",
    "    captured_values = set()\n",
    "    for col in new_columns:\n",
    "        if not col.endswith(('_other', '_count', '_unique_count', '_frequency', '_avg_frequency', '_rare')):\n",
    "            # Extract value name from column name\n",
    "            value_parts = col.replace(f\"{original_column}_\", \"\").replace(\"top_\", \"\").replace(\"freq_\", \"\")\n",
    "            captured_values.add(value_parts)\n",
    "    \n",
    "    capture_rate = len(captured_values) / len(all_original_values) * 100 if all_original_values else 0\n",
    "    print(f\"Value capture rate: {len(captured_values)}/{len(all_original_values)} ({capture_rate:.1f}%)\")\n",
    "    \n",
    "    if len(all_original_values) - len(captured_values) > 0:\n",
    "        lost_values = set(all_original_values) - captured_values\n",
    "        print(f\"Lost values (first 10): {list(lost_values)[:10]}\")\n",
    "    \n",
    "    # Estimate row-level information preservation\n",
    "    if any('_other' in col for col in new_columns):\n",
    "        other_col = [col for col in new_columns if col.endswith('_other')][0]\n",
    "        rows_with_other = df_processed[other_col].sum()\n",
    "        print(f\"Rows with 'other' values: {rows_with_other}/{len(df_processed)} ({rows_with_other/len(df_processed)*100:.1f}%)\")\n",
    "\n",
    "\n",
    "def quick_validation_summary(df_original, df_processed, column_mapping):\n",
    "    \"\"\"Quick validation summary for all processed columns\"\"\"\n",
    "    \n",
    "    print(\"=== QUICK VALIDATION SUMMARY ===\\n\")\n",
    "    \n",
    "    for original_col, new_cols in column_mapping.items():\n",
    "        print(f\"âœ“ {original_col} â†’ {len(new_cols)} new columns\")\n",
    "        \n",
    "        # Check for obvious issues\n",
    "        issues = []\n",
    "        \n",
    "        for col in new_cols:\n",
    "            if col not in df_processed.columns:\n",
    "                issues.append(f\"Missing column: {col}\")\n",
    "            else:\n",
    "                # Check for unexpected values in binary columns\n",
    "                if not col.endswith(('_count', '_frequency', '_avg_frequency')):\n",
    "                    unique_vals = set(df_processed[col].dropna().unique())\n",
    "                    if not unique_vals.issubset({0, 1, 0.0, 1.0}):\n",
    "                        issues.append(f\"Non-binary values in {col}: {unique_vals}\")\n",
    "        \n",
    "        if issues:\n",
    "            print(f\"  âš ï¸  Issues: {issues}\")\n",
    "        else:\n",
    "            print(f\"  âœ“ Looks good\")\n",
    "    \n",
    "    print(f\"\\nDataset size: {len(df_original)} â†’ {len(df_processed)} rows\")\n",
    "    print(f\"Column count: {len(df_original.columns)} â†’ {len(df_processed.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c7dfe5f-5eb6-4191-bcac-6e5370f5cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_missing_categories_from_full_dataset(\n",
    "    sample_df, \n",
    "    full_df, \n",
    "    categorical_columns, \n",
    "    samples_per_category=2,\n",
    "    exclude_columns=None  # Alternative parameter at this level\n",
    "):\n",
    "    \"\"\"\n",
    "    Add missing categorical values to sample dataset by sampling from full dataset\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    sample_df : pd.DataFrame\n",
    "        Your limited sample dataset\n",
    "    full_df : pd.DataFrame  \n",
    "        Your complete dataset\n",
    "    categorical_columns : list\n",
    "        List of categorical column names\n",
    "    samples_per_category : int\n",
    "        Number of examples to add for each missing category\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Enhanced dataset with missing categories included\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Analyzing missing categories...\")\n",
    "\n",
    "    # Apply exclusions if provided at this level\n",
    "    if exclude_columns:\n",
    "        categorical_columns = [col for col in categorical_columns \n",
    "                              if col not in exclude_columns]\n",
    "        print(f\"Excluded columns: {exclude_columns}\")\n",
    "    \n",
    "    \n",
    "    # Find missing categories in sample compared to full dataset\n",
    "    missing_categories = {}\n",
    "    category_stats = {}\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col not in sample_df.columns or col not in full_df.columns:\n",
    "            print(f\"Warning: Column '{col}' not found in one of the datasets\")\n",
    "            continue\n",
    "            \n",
    "        full_categories = set(full_df[col].dropna().unique())\n",
    "        sample_categories = set(sample_df[col].dropna().unique())\n",
    "        missing = full_categories - sample_categories\n",
    "        \n",
    "        if missing:\n",
    "            missing_categories[col] = missing\n",
    "            category_stats[col] = {\n",
    "                'total_in_full': len(full_categories),\n",
    "                'in_sample': len(sample_categories),\n",
    "                'missing_count': len(missing)\n",
    "            }\n",
    "            print(f\"Column '{col}': Missing {len(missing)} out of {len(full_categories)} categories\")\n",
    "            print(f\"  Missing categories: {list(missing)[:5]}{'...' if len(missing) > 5 else ''}\")\n",
    "        else:\n",
    "            print(f\"Column '{col}': All categories present in sample\")\n",
    "    \n",
    "    if not missing_categories:\n",
    "        print(\"No missing categories found! Your sample already contains all category values.\")\n",
    "        return sample_df.copy()\n",
    "    \n",
    "    # Collect additional rows for missing categories\n",
    "    additional_rows = []\n",
    "    rows_added_by_category = defaultdict(int)\n",
    "    \n",
    "    for col, missing_vals in missing_categories.items():\n",
    "        print(f\"\\nSampling for column '{col}'...\")\n",
    "        \n",
    "        for val in missing_vals:\n",
    "            # Find all rows in full dataset with this category value\n",
    "            matching_rows = full_df[full_df[col] == val]\n",
    "            \n",
    "            if len(matching_rows) == 0:\n",
    "                print(f\"  Warning: No rows found for {col}='{val}' in full dataset\")\n",
    "                continue\n",
    "            \n",
    "            # Sample requested number of rows (or all available if fewer)\n",
    "            n_samples = min(samples_per_category, len(matching_rows))\n",
    "            sampled_rows = matching_rows.sample(n=n_samples, random_state=42)\n",
    "            \n",
    "            additional_rows.append(sampled_rows)\n",
    "            rows_added_by_category[f\"{col}='{val}'\"] = n_samples\n",
    "            print(f\"  Added {n_samples} rows for '{val}' (out of {len(matching_rows)} available)\")\n",
    "    \n",
    "    # Combine all additional rows\n",
    "    if additional_rows:\n",
    "        df_additional = pd.concat(additional_rows, ignore_index=True)\n",
    "        \n",
    "        # Remove potential duplicates (in case same row satisfies multiple missing categories)\n",
    "        initial_additional_count = len(df_additional)\n",
    "        df_additional = df_additional.drop_duplicates()\n",
    "        final_additional_count = len(df_additional)\n",
    "        \n",
    "        if initial_additional_count != final_additional_count:\n",
    "            print(f\"\\nRemoved {initial_additional_count - final_additional_count} duplicate rows\")\n",
    "        \n",
    "        # Combine with original sample\n",
    "        df_enhanced = pd.concat([sample_df, df_additional], ignore_index=True)\n",
    "        \n",
    "        print(f\"\\n=== SUMMARY ===\")\n",
    "        print(f\"Original sample size: {len(sample_df)}\")\n",
    "        print(f\"Additional rows added: {len(df_additional)}\")\n",
    "        print(f\"Final dataset size: {len(df_enhanced)}\")\n",
    "        print(f\"Size increase: {len(df_additional)/len(sample_df)*100:.1f}%\")\n",
    "        \n",
    "        return df_enhanced\n",
    "    \n",
    "    else:\n",
    "        print(\"No additional rows could be sampled\")\n",
    "        return sample_df.copy()\n",
    "\n",
    "\n",
    "def verify_categories_coverage(df_before, df_after, categorical_columns):\n",
    "    \"\"\"\n",
    "    Verify that the enhanced dataset now covers all categories\n",
    "    \"\"\"\n",
    "    print(\"\\n=== CATEGORY COVERAGE VERIFICATION ===\")\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col not in df_before.columns:\n",
    "            continue\n",
    "            \n",
    "        before_cats = set(df_before[col].dropna().unique())\n",
    "        after_cats = set(df_after[col].dropna().unique())\n",
    "        new_cats = after_cats - before_cats\n",
    "        \n",
    "        print(f\"\\nColumn '{col}':\")\n",
    "        print(f\"  Before: {len(before_cats)} categories\")\n",
    "        print(f\"  After:  {len(after_cats)} categories\")\n",
    "        if new_cats:\n",
    "            print(f\"  New categories added: {list(new_cats)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "502733c3-ec2e-41a2-ab19-1f449f514473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# === 1. DataLoader: Load data and check target column ===\n",
    "\n",
    "class DataLoader(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Load and perform initial data validation whether the target col exists:\n",
    "        - Handles both .xlsx and .csv.\n",
    "        - Stores the original shape of the data.\n",
    "        - Raises an error if the target column is missing.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path, target_col='project_prf_normalised_work_effort'):\n",
    "        self.file_path = file_path\n",
    "        self.target_col = target_col  # This should be the standardized form\n",
    "        self.original_shape = None\n",
    "        self.original_target_col = None  # Store what we actually found\n",
    "        \n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _standardize_column_name(self, col_name):\n",
    "        \"\"\"Convert column name to standardized format\"\"\"\n",
    "        return col_name.strip().lower().replace(' ', '_')\n",
    "    \n",
    "    def _find_target_column(self, df_columns):\n",
    "        \"\"\"\n",
    "        Smart target column finder - handles various formats\n",
    "        Returns the actual column name from the dataframe\n",
    "        \"\"\"\n",
    "        target_standardized = self.target_col.lower().replace(' ', '_')\n",
    "        \n",
    "        # Try exact match first\n",
    "        if self.target_col in df_columns:\n",
    "            return self.target_col\n",
    "            \n",
    "        # Try standardized versions of all columns\n",
    "        for col in df_columns:\n",
    "            col_standardized = self._standardize_column_name(col)\n",
    "            if col_standardized == target_standardized:\n",
    "                return col\n",
    "                \n",
    "        # If still not found, look for partial matches (for debugging)\n",
    "        similar_cols = []\n",
    "        target_words = set(target_standardized.split('_'))\n",
    "        for col in df_columns:\n",
    "            col_words = set(self._standardize_column_name(col).split('_'))\n",
    "            if len(target_words.intersection(col_words)) >= 2:  # At least 2 words match\n",
    "                similar_cols.append(col)\n",
    "                \n",
    "        return None, similar_cols\n",
    "    \n",
    "    def transform(self, X=None):\n",
    "        \"\"\"Load data from file with smart column handling\"\"\"\n",
    "\n",
    "        print(f\"Loading data from: {self.file_path}\")\n",
    "        \n",
    "        # Determine file type and load accordingly; support for Excel or CSV\n",
    "        if self.file_path.endswith('.xlsx'):\n",
    "            df = pd.read_excel(self.file_path)\n",
    "        elif self.file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(self.file_path)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Use .xlsx or .csv\")\n",
    "        \n",
    "        self.original_shape = df.shape\n",
    "        print(f\"Loaded data with shape: {df.shape}\")\n",
    "        \n",
    "        # Smart target column finding\n",
    "        result = self._find_target_column(df.columns)\n",
    "        \n",
    "        if isinstance(result, tuple):  # Not found, got similar columns\n",
    "            actual_col, similar_cols = result\n",
    "            error_msg = f\"Target column '{self.target_col}' not found in data.\"\n",
    "            if similar_cols:\n",
    "                error_msg += f\" Similar columns found: {similar_cols}\"\n",
    "            else:\n",
    "                error_msg += f\" Available columns: {list(df.columns)}\"\n",
    "            raise ValueError(error_msg)\n",
    "        else:\n",
    "            actual_col = result\n",
    "            \n",
    "        # Store the original column name we found\n",
    "        self.original_target_col = actual_col\n",
    "        \n",
    "        if actual_col != self.target_col:\n",
    "            print(f\"Target column found: '{actual_col}' -> will be standardized to '{self.target_col}'\")\n",
    "            \n",
    "        return df\n",
    "\n",
    "# === 2. ColumnNameStandardizer: Clean and standardize column names ===\n",
    "class ColumnNameStandardizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Standardize column names for consistency (lowercase, underscores, removes odd chars):\n",
    "        - Strips spaces, lowercases, replaces & with _&_, removes special chars.\n",
    "        - Useful for later steps and compatibility with modeling libraries.)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_col=None, original_target_col=None):\n",
    "        self.column_mapping = {}\n",
    "        self.target_col = target_col\n",
    "        self.original_target_col = original_target_col\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _standardize_columns(self, columns):\n",
    "        \"\"\"Standardize column names\"\"\"\n",
    "        return [col.strip().lower().replace(' ', '_') for col in columns]\n",
    "    \n",
    "    def _clean_column_names(self, columns):\n",
    "        \"\"\"Clean column names for compatibility\"\"\"\n",
    "        cleaned_cols = []\n",
    "        for col in columns:\n",
    "            # Replace ampersands with _&_ to match expected transformations\n",
    "            col_clean = col.replace(' & ', '_&_')\n",
    "            # Remove special characters except underscores and ampersands\n",
    "            col_clean = re.sub(r'[^\\w\\s&]', '', col_clean)\n",
    "            # Replace spaces with underscores\n",
    "            col_clean = col_clean.replace(' ', '_')\n",
    "            cleaned_cols.append(col_clean)\n",
    "        return cleaned_cols\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Apply column name standardization\"\"\"\n",
    "        df = X.copy()\n",
    "        \n",
    "        # Store original column names\n",
    "        original_columns = df.columns.tolist()\n",
    "        \n",
    "        # Apply standardization\n",
    "        standardized_cols = self._standardize_columns(original_columns)\n",
    "        cleaned_cols = self._clean_column_names(standardized_cols)\n",
    "\n",
    "        # Special handling for target column\n",
    "        if self.original_target_col and self.target_col:\n",
    "            target_index = None\n",
    "            try:\n",
    "                target_index = original_columns.index(self.original_target_col)\n",
    "                cleaned_cols[target_index] = self.target_col\n",
    "                print(f\"Target column '{self.original_target_col}' -> '{self.target_col}'\")\n",
    "            except ValueError:\n",
    "                pass  # Original target col not found, proceed normally\n",
    "        \n",
    "        \n",
    "        # Create mapping\n",
    "        self.column_mapping = dict(zip(original_columns, cleaned_cols))\n",
    "        \n",
    "        # Apply new column names\n",
    "        df.columns = cleaned_cols\n",
    "        \n",
    "        # Report changes\n",
    "        changed_cols = sum(1 for orig, new in self.column_mapping.items() if orig != new)\n",
    "        print(f\"Standardized {changed_cols} column names\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "# === 3. MissingValueAnalyzer: Analyze and handle missing values ===\n",
    "class MissingValueAnalyzer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Analyze and handle missing values\n",
    "        - Reports number of columns with >50% and >70% missing.\n",
    "        - Drops columns with a high proportion of missing data, except those you want to keep.\n",
    "        - Fills remaining missing values:\n",
    "            - Categorical: Fills with \"Missing\".\n",
    "            - Numeric: Fills with column median.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, high_missing_threshold=0.7, cols_to_keep=None):\n",
    "        self.high_missing_threshold = high_missing_threshold\n",
    "        self.cols_to_keep = cols_to_keep or []\n",
    "        self.high_missing_cols = []\n",
    "        self.missing_stats = {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Analyze and handle missing values\"\"\"\n",
    "        df = X.copy()\n",
    "        \n",
    "        # Calculate missing percentages\n",
    "        missing_pct = df.isnull().mean()\n",
    "        self.missing_stats = missing_pct.sort_values(ascending=False)\n",
    "        \n",
    "        print(f\"\\nMissing value analysis:\")\n",
    "        print(f\"Columns with >50% missing: {sum(missing_pct > 0.5)}\")\n",
    "        print(f\"Columns with >70% missing: {sum(missing_pct > self.high_missing_threshold)}\")\n",
    "        \n",
    "        # Identify high missing columns\n",
    "        self.high_missing_cols = missing_pct[missing_pct > self.high_missing_threshold].index.tolist()\n",
    "        \n",
    "        # Filter out columns we want to keep\n",
    "        final_high_missing_cols = [col for col in self.high_missing_cols if col not in self.cols_to_keep]\n",
    "        \n",
    "        print(f\"Dropping {len(final_high_missing_cols)} columns with >{self.high_missing_threshold*100}% missing values\")\n",
    "        \n",
    "        # Drop high missing columns\n",
    "        df_clean = df.drop(columns=final_high_missing_cols)\n",
    "        \n",
    "        # Fill remaining missing values in categorical columns\n",
    "        cat_cols = df_clean.select_dtypes(include=['object', 'category']).columns\n",
    "        for col in cat_cols:\n",
    "            df_clean[col] = df_clean[col].fillna('Missing')\n",
    "        \n",
    "        # Fill remaining missing values in numerical columns with median\n",
    "        num_cols = df_clean.select_dtypes(include=['number']).columns\n",
    "        for col in num_cols:\n",
    "            if df_clean[col].isnull().sum() > 0:\n",
    "                median_val = df_clean[col].median()\n",
    "                df_clean[col] = df_clean[col].fillna(median_val)\n",
    "                print(f\"Filled {col} missing values with median: {median_val}\")\n",
    "        \n",
    "        print(f\"Data shape after missing value handling: {df_clean.shape}\")\n",
    "        return df_clean\n",
    "\n",
    "# === 4. SemicolonProcessor: Process multi-value columns (semicolon-separated) ===\n",
    "class SemicolonProcessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Process semicolon-separated values in columns (e.g., \"Python; Java; SQL\")\n",
    "        - Identifies columns with semicolons.\n",
    "        - Cleans: lowercases, strips, deduplicates, sorts, optionally standardizes values (e.g., \"stand alone\" â†’ \"stand-alone\").\n",
    "        - Useful for multi-value categorical features.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, standardization_mapping=None):\n",
    "        self.semicolon_cols = []\n",
    "        self.standardization_mapping = standardization_mapping or {\n",
    "            \"scrum\": \"agile development\",\n",
    "            \"file &/or print server\": \"file/print server\",\n",
    "        }\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _clean_and_sort_semicolon(self, val, apply_standardization=False, mapping=None):\n",
    "        \"\"\"Clean, deduplicate, sort, and standardize semicolon-separated values\"\"\"\n",
    "        if pd.isnull(val) or val == '':\n",
    "            return val\n",
    "        \n",
    "        parts = [x.strip().lower() for x in str(val).split(';') if x.strip()]\n",
    "        \n",
    "        if apply_standardization and mapping is not None:\n",
    "            parts = [mapping.get(part, part) for part in parts]\n",
    "        \n",
    "        unique_cleaned = sorted(set(parts))\n",
    "        return '; '.join(unique_cleaned)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Process semicolon-separated columns\"\"\"\n",
    "        df = X.copy()\n",
    "        \n",
    "        # Identify columns with semicolons\n",
    "        self.semicolon_cols = [\n",
    "            col for col in df.columns\n",
    "            if df[col].dropna().astype(str).str.contains(';').any()\n",
    "        ]\n",
    "        \n",
    "        print(f\"Found {len(self.semicolon_cols)} columns with semicolons: {self.semicolon_cols}\")\n",
    "        \n",
    "        # Process each semicolon column\n",
    "        for col in self.semicolon_cols:\n",
    "            # Apply mapping for specific columns\n",
    "            apply_mapping = col in ['process_pmf_development_methodologies', 'tech_tf_server_roles']\n",
    "            mapping = self.standardization_mapping if apply_mapping else None\n",
    "            \n",
    "            # Clean the column\n",
    "            df[col] = df[col].apply(\n",
    "                lambda x: self._clean_and_sort_semicolon(x, apply_standardization=apply_mapping, mapping=mapping)\n",
    "            )\n",
    "        \n",
    "        return df\n",
    "\n",
    "# === 5. MultiValueEncoder: Encode semicolon columns using MultiLabelBinarizer ===\n",
    "class MultiValueEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Handle multi-value columns using MultiLabelBinarizer\n",
    "        - Only processes columns with a manageable number of unique values (max_cardinality).\n",
    "        - Each semicolon column becomes several binary columns (e.g., \"lang__python\", \"lang__java\", ...).     \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_cardinality=10):\n",
    "        # Ensure max_cardinality is always an integer\n",
    "        self.max_cardinality = int(max_cardinality) if max_cardinality is not None else 10\n",
    "        self.multi_value_cols = []\n",
    "        self.mlb_transformers = {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Encode multi-value columns\"\"\"\n",
    "        df = X.copy()\n",
    "        \n",
    "        # Identify semicolon columns (multi-value)\n",
    "        semicolon_cols = [\n",
    "            col for col in df.columns\n",
    "            if df[col].dropna().astype(str).str.contains(';').any()\n",
    "        ]\n",
    "        \n",
    "        # Filter for low cardinality multi-value columns\n",
    "        self.multi_value_cols = []\n",
    "        for col in semicolon_cols:\n",
    "            # Get unique values across all entries\n",
    "            all_values = set()\n",
    "            for val in df[col].dropna().astype(str):\n",
    "                values = [v.strip() for v in val.split(';') if v.strip()]\n",
    "                all_values.update(values)\n",
    "            \n",
    "            # Check cardinality (max_cardinality is already an integer from __init__)\n",
    "            if len(all_values) <= self.max_cardinality:\n",
    "                self.multi_value_cols.append(col)\n",
    "        \n",
    "        print(f\"Encoding {len(self.multi_value_cols)} multi-value columns: {self.multi_value_cols}\")\n",
    "        \n",
    "        # Process each multi-value column\n",
    "        for col in self.multi_value_cols:\n",
    "            # Prepare data for MultiLabelBinarizer\n",
    "            values = df[col].dropna().astype(str).apply(\n",
    "                lambda x: [item.strip() for item in x.split(';') if item.strip()]\n",
    "            )\n",
    "            \n",
    "            # Handle empty values - fill with empty list for MultiLabelBinarizer\n",
    "            if len(values) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Fit and transform\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            \n",
    "            # Convert to list of lists, handling NaN/empty cases\n",
    "            values_list = []\n",
    "            for idx in df.index:\n",
    "                if idx in values.index and values[idx]:\n",
    "                    values_list.append(values[idx])\n",
    "                else:\n",
    "                    values_list.append([])  # Empty list for missing values\n",
    "            \n",
    "            onehot = pd.DataFrame(\n",
    "                mlb.fit_transform(values_list),\n",
    "                columns=[f\"{col}__{cat}\" for cat in mlb.classes_],\n",
    "                index=df.index\n",
    "            )\n",
    "            \n",
    "            # Store transformer for later use\n",
    "            self.mlb_transformers[col] = mlb\n",
    "            \n",
    "            # Join with main dataframe\n",
    "            df = df.join(onehot, how='left')\n",
    "            \n",
    "            print(f\"Encoded {col} into {len(mlb.classes_)} binary columns\")\n",
    "        \n",
    "        # Remove original multi-value columns\n",
    "        df = df.drop(columns=self.multi_value_cols)\n",
    "        \n",
    "        return df\n",
    "\n",
    "# === 6. CategoricalEncoder: One-hot encode regular categorical columns ===\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Handle single-value categorical columns\n",
    "        - Ignores semicolon columns.\n",
    "        - Only encodes columns with a number of categories â‰¤ max_cardinality (to avoid high-dimensional explosion).\n",
    "        - Can drop the first category for each variable to avoid multicollinearity.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_cardinality=10, drop_first=True):\n",
    "        self.max_cardinality = max_cardinality\n",
    "        self.drop_first = drop_first\n",
    "        self.categorical_cols = []\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Encode categorical columns\"\"\"\n",
    "        df = X.copy()\n",
    "        \n",
    "        # Identify categorical columns\n",
    "        cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        \n",
    "        # Identify semicolon columns to exclude\n",
    "        semicolon_cols = [\n",
    "            col for col in df.columns\n",
    "            if df[col].dropna().astype(str).str.contains(';').any()\n",
    "        ]\n",
    "        \n",
    "        # Filter for low cardinality single-value categorical columns\n",
    "        self.categorical_cols = [\n",
    "            col for col in cat_cols \n",
    "            if col not in semicolon_cols and df[col].nunique() <= self.max_cardinality\n",
    "        ]\n",
    "        \n",
    "        print(f\"One-hot encoding {len(self.categorical_cols)} categorical columns: {self.categorical_cols}\")\n",
    "        \n",
    "        # Apply one-hot encoding\n",
    "        if self.categorical_cols:\n",
    "            df = pd.get_dummies(df, columns=self.categorical_cols, drop_first=self.drop_first)\n",
    "        \n",
    "        return df\n",
    "\n",
    "# === 7. ColumnNameFixer: Final column name cleanup for PyCaret etc ===\n",
    "class ColumnNameFixer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Fix column names for PyCaret compatibility (removes illegal characters, replaces spaces/ampersands, handles duplicates):\n",
    "        - No duplicate column names after encoding.\n",
    "        - Only alphanumeric and underscores. \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.column_transformations = {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Fix problematic column names\"\"\"\n",
    "        df = X.copy()\n",
    "        original_cols = df.columns.tolist()\n",
    "        fixed_columns = []\n",
    "        seen_columns = set()\n",
    "        \n",
    "        for col in original_cols:\n",
    "            # Replace spaces with underscores\n",
    "            fixed_col = col.replace(' ', '_')\n",
    "            # Replace ampersands\n",
    "            fixed_col = fixed_col.replace('&', 'and')\n",
    "            # Remove other problematic characters\n",
    "            fixed_col = ''.join(c if c.isalnum() or c == '_' else '_' for c in fixed_col)\n",
    "            # Remove multiple consecutive underscores\n",
    "            fixed_col = re.sub('_+', '_', fixed_col)\n",
    "            # Remove leading/trailing underscores\n",
    "            fixed_col = fixed_col.strip('_')\n",
    "            \n",
    "            # Handle duplicates\n",
    "            base_col = fixed_col\n",
    "            suffix = 1\n",
    "            while fixed_col in seen_columns:\n",
    "                fixed_col = f\"{base_col}_{suffix}\"\n",
    "                suffix += 1\n",
    "            \n",
    "            seen_columns.add(fixed_col)\n",
    "            fixed_columns.append(fixed_col)\n",
    "        \n",
    "        # Store transformations\n",
    "        self.column_transformations = dict(zip(original_cols, fixed_columns))\n",
    "        \n",
    "        # Apply new column names\n",
    "        df.columns = fixed_columns\n",
    "        \n",
    "        # Check for duplicates\n",
    "        dup_check = [item for item, count in pd.Series(fixed_columns).value_counts().items() if count > 1]\n",
    "        if dup_check:\n",
    "            print(f\"WARNING: Found {len(dup_check)} duplicate column names: {dup_check}\")\n",
    "        else:\n",
    "            print(\"No duplicate column names after fixing\")\n",
    "        \n",
    "        n_changed = sum(1 for old, new in self.column_transformations.items() if old != new)\n",
    "        print(f\"Fixed {n_changed} column names for PyCaret compatibility\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "# === 8. DataValidator: Final summary and checks ===\n",
    "class DataValidator(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Validate final dataset\n",
    "        - Shape, missing values, infinities.\n",
    "        - Data types (numeric, categorical).\n",
    "        - Stats on the target column (mean, std, min, max, missing).\n",
    "        - Report issues if any.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_col):\n",
    "        self.target_col = target_col\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Validate the processed dataset\"\"\"\n",
    "        df = X.copy()\n",
    "        \n",
    "        print(f\"\\n=== Final Data Validation ===\")\n",
    "        print(f\"Final shape: {df.shape}\")\n",
    "        print(f\"Target column: {self.target_col}\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_count = df.isnull().sum().sum()\n",
    "        print(f\"Total missing values: {missing_count}\")\n",
    "        \n",
    "        # Check for infinite values\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        inf_count = np.isinf(df[numeric_cols].values).sum()\n",
    "        print(f\"Total infinite values: {inf_count}\")\n",
    "        \n",
    "        # Data types summary\n",
    "        print(f\"\\nData types:\")\n",
    "        print(f\"  Numeric columns: {len(df.select_dtypes(include=[np.number]).columns)}\")\n",
    "        print(f\"  Categorical columns: {len(df.select_dtypes(include=['object', 'category']).columns)}\")\n",
    "        \n",
    "        # Target variable summary\n",
    "        if self.target_col in df.columns:\n",
    "            target_stats = df[self.target_col].describe()\n",
    "            print(f\"\\nTarget variable '{self.target_col}' statistics:\")\n",
    "            print(f\"  Mean: {target_stats['mean']:.2f}\")\n",
    "            print(f\"  Std: {target_stats['std']:.2f}\")\n",
    "            print(f\"  Min: {target_stats['min']:.2f}\")\n",
    "            print(f\"  Max: {target_stats['max']:.2f}\")\n",
    "            print(f\"  Missing: {df[self.target_col].isnull().sum()}\")\n",
    "        else:\n",
    "            print(f\"WARNING: Target column '{self.target_col}' not found!\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "# === Pipeline creation function: returns the Scikit-learn pipeline ===\n",
    "def create_isbsg_preprocessing_pipeline(\n",
    "    target_col='project_prf_normalised_work_effort',\n",
    "    original_target_col=None,\n",
    "    high_missing_threshold=0.7,\n",
    "    cols_to_keep=None,\n",
    "    max_categorical_cardinality=10,\n",
    "    standardization_mapping=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create complete preprocessing pipeline with smart target column handling\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    target_col : str\n",
    "        Name of target column\n",
    "    original_target_col : str\n",
    "        Original target column name found in data\n",
    "    high_missing_threshold : float\n",
    "        Threshold for dropping columns with high missing values\n",
    "    cols_to_keep : list\n",
    "        Columns to keep even if they have high missing values\n",
    "    max_categorical_cardinality : int\n",
    "        Maximum number of unique values for categorical encoding\n",
    "    standardization_mapping : dict\n",
    "        Custom mapping for standardizing semicolon-separated values\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    sklearn.pipeline.Pipeline\n",
    "        Complete preprocessing pipeline\n",
    "    \"\"\"\n",
    "    \n",
    "    if cols_to_keep is None:\n",
    "        cols_to_keep = [\n",
    "            'project_prf_case_tool_used', \n",
    "            'process_pmf_prototyping_used',\n",
    "            'tech_tf_client_roles', \n",
    "            'tech_tf_type_of_server', \n",
    "            'tech_tf_clientserver_description'\n",
    "        ]\n",
    "    \n",
    "    # Ensure max_categorical_cardinality is an integer\n",
    "    if not isinstance(max_categorical_cardinality, int):\n",
    "        max_categorical_cardinality = 10\n",
    "        print(f\"Warning: max_categorical_cardinality was not an integer, defaulting to {max_categorical_cardinality}\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('column_standardizer', ColumnNameStandardizer(target_col, original_target_col)),\n",
    "        ('missing_handler', MissingValueAnalyzer(\n",
    "            high_missing_threshold=high_missing_threshold,\n",
    "            cols_to_keep=cols_to_keep\n",
    "        )),\n",
    "        ('semicolon_processor', SemicolonProcessor(standardization_mapping=standardization_mapping)),\n",
    "        ('multi_value_encoder', MultiValueEncoder(max_cardinality=max_categorical_cardinality)),\n",
    "        ('categorical_encoder', CategoricalEncoder(max_cardinality=max_categorical_cardinality)),\n",
    "        ('column_fixer', ColumnNameFixer()),\n",
    "        ('validator', DataValidator(target_col))\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# === Full workflow function: orchestrates loading, pipeline, and saving ===\n",
    "def preprocess_isbsg_data(\n",
    "    file_path,\n",
    "    target_col='project_prf_normalised_work_effort',  # Always use standardized form\n",
    "    output_dir='../data',\n",
    "    save_intermediate=True,\n",
    "    **pipeline_kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete preprocessing workflow for ISBSG data: loads the data, runs \n",
    "      the full preprocessing pipeline, saves processed data, pipeline \n",
    "      object, and a metadata report to disk, and returns the processed \n",
    "      DataFrame and metadata\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        Path to input data file\n",
    "    target_col : str\n",
    "        Name of target column\n",
    "    output_dir : str\n",
    "        Directory to save processed data\n",
    "    save_intermediate : bool\n",
    "        Whether to save intermediate processing steps\n",
    "    **pipeline_kwargs : dict\n",
    "        Additional arguments for pipeline creation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Processed dataframe ready for modeling\n",
    "    dict\n",
    "        Processing metadata and statistics\n",
    "    \"\"\"\n",
    "\n",
    "    # print pipeline header\n",
    "    print(\"=\"*60)\n",
    "    print(\"ISBSG Data Preprocessing Pipeline\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    print(f\"Target column (standardized): {target_col}\")\n",
    "    print(f\"Timestamp: {datetime.now()}\")\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load data with smart column detection\n",
    "    loader = DataLoader(file_path, target_col)\n",
    "    df_raw = loader.transform(X = None)\n",
    "    \n",
    "    # Create and fit preprocessing pipeline\n",
    "    pipeline = create_isbsg_preprocessing_pipeline(\n",
    "        target_col=target_col,\n",
    "        original_target_col=loader.original_target_col,  # Pass the found column name\n",
    "        **pipeline_kwargs\n",
    "    )\n",
    "    \n",
    "    # Apply preprocessing in order of ColumnNameStandardizer=> MissingValueAnalyzer =>\n",
    "    # SemicolonProcessor=> MultiValueEncoder=> CategoricalEncoder => ColumnNameFixer\n",
    "\n",
    "    # Apply preprocessing\n",
    "    df_processed = pipeline.fit_transform(df_raw)\n",
    "    \n",
    "    # Prepare metadata\n",
    "    metadata = {\n",
    "        'original_shape': loader.original_shape,\n",
    "        'processed_shape': df_processed.shape,\n",
    "        'processing_timestamp': datetime.now().isoformat(),\n",
    "        'target_column_standardized': target_col,\n",
    "        'target_column_original': loader.original_target_col,\n",
    "        'pipeline_steps': [step[0] for step in pipeline.steps]\n",
    "    }\n",
    "    \n",
    "    # Save processed data\n",
    "    file_stem = Path(file_path).stem\n",
    "    output_path = os.path.join(output_dir, f\"{file_stem}_preprocessed.csv\")\n",
    "    df_processed.to_csv(output_path, index=False)\n",
    "    print(f\"\\nProcessed data saved to: {output_path}\")\n",
    "    \n",
    "    # Save pipeline\n",
    "    pipeline_path = os.path.join(output_dir, f\"{file_stem}_preprocessing_pipeline.pkl\")\n",
    "    joblib.dump(pipeline, pipeline_path)\n",
    "    print(f\"Pipeline saved to: {pipeline_path}\")\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata_path = os.path.join(output_dir, f\"{file_stem}_preprocessing_metadata.txt\")\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        f.write(\"ISBSG Data Preprocessing Metadata\\n\")\n",
    "        f.write(\"=\"*40 + \"\\n\")\n",
    "        for key, value in metadata.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    print(f\"Metadata saved to: {metadata_path}\")\n",
    "\n",
    "    # Print completion & return results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Preprocessing completed successfully!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return df_processed, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a67d417-a269-414e-9944-fc954d659ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def integrated_categorical_preprocessing(\n",
    "    sample_file_path: str,\n",
    "    full_file_path: str,\n",
    "    target_col: str,\n",
    "    output_dir: str,\n",
    "    cols_to_keep: List[str] = None,\n",
    "    high_card_columns: List[str] = None,\n",
    "    max_categorical_cardinality: int = 10,\n",
    "    samples_per_category: int = 3,\n",
    "    standardization_mapping: Dict[str, str] = None,\n",
    "    high_missing_threshold: float = 0.7,\n",
    "    separator: str = ';',\n",
    "    strategy: str = 'top_k',\n",
    "    k: int = 20,\n",
    "    exclude_from_enhancement: List[str] = None \n",
    ") -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Integrated pipeline to:\n",
    "    1. Load sample and full datasets\n",
    "    2. Auto-detect categorical columns\n",
    "    3. Handle high-cardinality multi-value columns\n",
    "    4. Enhance sample with missing categories from full dataset\n",
    "    5. Apply standardization and final preprocessing\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    exclude_from_enhancement : List[str]\n",
    "        List of column names to exclude from getting additional categories from full dataset\n",
    "    \n",
    "    Returns:\n",
    "        - Enhanced and processed DataFrame\n",
    "        - Metadata about the processing steps\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"INTEGRATED CATEGORICAL PREPROCESSING PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Initialize exclude list if not provided\n",
    "    if exclude_from_enhancement is None:\n",
    "        exclude_from_enhancement = []\n",
    "    \n",
    "    # Step 1: Load datasets\n",
    "    print(\"\\n1. Loading datasets...\")\n",
    "    sample_df = pd.read_excel(sample_file_path)\n",
    "    full_df = pd.read_excel(full_file_path)\n",
    "\n",
    "    # Lowercase all column names in both DataFrames independently\n",
    "    sample_df.columns = [col1.lower() for col1 in sample_df.columns]\n",
    "    full_df.columns   = [col2.lower() for col2 in full_df.columns]\n",
    "\n",
    "    \n",
    "    print(f\"Sample dataset shape: {sample_df.shape}\")\n",
    "    print(f\"Full dataset shape: {full_df.shape}\")\n",
    "    \n",
    "    # Step 2: Auto-detect categorical columns\n",
    "    print(\"\\n2. Auto-detecting categorical columns...\")\n",
    "    categorical_columns = []\n",
    "    for col in sample_df.columns:\n",
    "        if sample_df[col].dtype == 'object' or sample_df[col].nunique() < 20:\n",
    "            categorical_columns.append(col)\n",
    "\n",
    "    # Convert categorical list to lowercase for case-insensitive comparison\n",
    "    categorical_columns = [col.lower() for col in categorical_columns]\n",
    "    \n",
    "    print(f\"Detected categorical columns: {categorical_columns}\")\n",
    "    \n",
    "    # Step 3: Identify high-cardinality multi-value columns\n",
    "    print(\"\\n3. Processing high-cardinality multi-value columns...\")\n",
    "    if high_card_columns is None:\n",
    "        high_card_columns = ['external_eef_organisation_type', 'project_prf_application_type']\n",
    "    \n",
    "    # Analyze and process high-cardinality columns in full dataset first\n",
    "    full_df_processed = full_df.copy()\n",
    "    col_mapping = {}\n",
    "    \n",
    "    for col in high_card_columns:\n",
    "        if col in full_df.columns:\n",
    "            print(f\"\\nProcessing high-cardinality column: {col}\")\n",
    "            # Recommend strategy for this column\n",
    "            recommend_strategy(full_df, col, separator=separator)\n",
    "            \n",
    "            # Process the column\n",
    "            full_df_processed, temp_mapping = handle_high_cardinality_multivalue(\n",
    "                full_df_processed,\n",
    "                multi_value_columns=[col],\n",
    "                separator=separator,\n",
    "                strategy=strategy,\n",
    "                k=k\n",
    "            )\n",
    "            col_mapping.update(temp_mapping)\n",
    "    \n",
    "    # Step 4: Apply same processing to sample dataset\n",
    "    print(\"\\n4. Applying same processing to sample dataset...\")\n",
    "    sample_df_processed = sample_df.copy()\n",
    "    \n",
    "    for col in high_card_columns:\n",
    "        if col in sample_df.columns:\n",
    "            sample_df_processed, _ = handle_high_cardinality_multivalue(\n",
    "                sample_df_processed,\n",
    "                multi_value_columns=[col],\n",
    "                separator=separator,\n",
    "                strategy=strategy,\n",
    "                k=k\n",
    "            )\n",
    "    \n",
    "    # Step 5: Update categorical columns list after processing\n",
    "    print(\"\\n5. Updating categorical columns after high-cardinality processing...\")\n",
    "    updated_categorical_columns = []\n",
    "    for col in sample_df_processed.columns:\n",
    "        if sample_df_processed[col].dtype == 'object' or sample_df_processed[col].nunique() < max_categorical_cardinality:\n",
    "            updated_categorical_columns.append(col)\n",
    "\n",
    "    # Convert categorical list to lowercase for case-insensitive comparison\n",
    "    updated_categorical_columns = [col.lower() for col in updated_categorical_columns]\n",
    "    \n",
    "    print(f\"Updated categorical columns: {len(updated_categorical_columns)} columns\")\n",
    "    \n",
    "    # Step 6: Enhanced category sampling with exclusions\n",
    "    print(\"\\\\n6. Enhancing sample with missing categories from full dataset...\")\n",
    "    print(f\"Excluding columns from enhancement: {exclude_from_enhancement}\")\n",
    "    \n",
    "    # Filter out excluded columns before enhancement\n",
    "    columns_to_enhance = [col for col in updated_categorical_columns \n",
    "                         if col not in exclude_from_enhancement]\n",
    "    \n",
    "    print(f\"Columns that will be enhanced: {len(columns_to_enhance)} out of {len(updated_categorical_columns)}; Cols are : {columns_to_enhance}\")\n",
    "    \n",
    "    enhanced_df = add_missing_categories_from_full_dataset(\n",
    "        sample_df=sample_df_processed,\n",
    "        full_df=full_df_processed,\n",
    "        categorical_columns=columns_to_enhance,  # Use filtered list\n",
    "        samples_per_category=samples_per_category\n",
    "    )\n",
    "    \n",
    "    print(f\"Enhanced dataset shape: {enhanced_df.shape}\")\n",
    "    \n",
    "    # Step 7: Verify categories coverage\n",
    "    print(\"\\n7. Verifying categories coverage...\")\n",
    "    verify_categories_coverage(sample_df_processed, enhanced_df, updated_categorical_columns)\n",
    "    \n",
    "    # Step 8: Check for and handle duplicate columns before final preprocessing\n",
    "    print(\"\\n8. Checking for duplicate columns...\")\n",
    "    duplicate_cols = enhanced_df.columns[enhanced_df.columns.duplicated()].tolist()\n",
    "    if duplicate_cols:\n",
    "        print(f\"Warning: Found duplicate columns: {duplicate_cols}\")\n",
    "        # Remove duplicates, keeping the first occurrence\n",
    "        enhanced_df = enhanced_df.loc[:, ~enhanced_df.columns.duplicated()]\n",
    "        print(\"Removed duplicate columns\")\n",
    "    \n",
    "    # Step 9: Apply final preprocessing using safe wrapper\n",
    "    print(\"\\n9. Applying final preprocessing...\")\n",
    "    final_df, preprocessing_metadata = safe_preprocess_with_fallback(\n",
    "        enhanced_df=enhanced_df,\n",
    "        target_col=target_col,\n",
    "        output_dir=output_dir,\n",
    "        cols_to_keep=cols_to_keep,\n",
    "        max_categorical_cardinality=max_categorical_cardinality,\n",
    "        standardization_mapping=standardization_mapping,\n",
    "        high_missing_threshold=high_missing_threshold\n",
    "    )\n",
    "    \n",
    "    # Step 10: Final validation and duplicate check\n",
    "    print(\"\\n10. Final validation and duplicate check...\")\n",
    "    \n",
    "    # Check for any remaining duplicates after all processing\n",
    "    final_duplicate_cols = final_df.columns[final_df.columns.duplicated()].tolist()\n",
    "    if final_duplicate_cols:\n",
    "        print(f\"Warning: Found duplicate columns in final dataset: {final_duplicate_cols}\")\n",
    "        # Remove duplicates, keeping the first occurrence\n",
    "        final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "        print(\"Removed final duplicate columns\")\n",
    "    \n",
    "    print(f\"Original sample shape: {sample_df.shape}\")\n",
    "    print(f\"Final processed shape: {final_df.shape}\")\n",
    "    print(f\"Columns added: {final_df.shape[1] - sample_df.shape[1]}\")\n",
    "    print(f\"Rows added: {final_df.shape[0] - sample_df.shape[0]}\")\n",
    "    \n",
    "    # Check for columns with similar names (potential duplicates)\n",
    "    similar_cols = []\n",
    "    for col in final_df.columns:\n",
    "        if col.endswith('_1') or col.endswith('_2'):\n",
    "            base_name = col.rsplit('_', 1)[0]\n",
    "            if base_name in final_df.columns:\n",
    "                similar_cols.append((base_name, col))\n",
    "    \n",
    "    if similar_cols:\n",
    "        print(f\"\\nWarning: Found potentially duplicate columns:\")\n",
    "        for base, duplicate in similar_cols:\n",
    "            print(f\"  - '{base}' and '{duplicate}'\")\n",
    "        print(\"Consider reviewing your preprocessing functions to avoid double processing.\")\n",
    "    \n",
    "    # Compile metadata\n",
    "    metadata = {\n",
    "        'original_sample_shape': sample_df.shape,\n",
    "        'original_full_shape': full_df.shape,\n",
    "        'final_shape': final_df.shape,\n",
    "        'categorical_columns_detected': categorical_columns,\n",
    "        'updated_categorical_columns': updated_categorical_columns,\n",
    "        'high_cardinality_columns_processed': high_card_columns,\n",
    "        'column_mapping': col_mapping,\n",
    "        'preprocessing_metadata': preprocessing_metadata,\n",
    "        'rows_added_from_full_dataset': final_df.shape[0] - sample_df.shape[0]\n",
    "    }\n",
    "    \n",
    "    return final_df, metadata\n",
    "\n",
    "def safe_preprocess_with_fallback(\n",
    "    enhanced_df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    output_dir: str,\n",
    "    cols_to_keep: List[str] = None,\n",
    "    max_categorical_cardinality: int = 10,\n",
    "    standardization_mapping: Dict[str, str] = None,\n",
    "    high_missing_threshold: float = 0.7\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Safe preprocessing function that handles the file_path requirement\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save enhanced dataset to temporary file\n",
    "    temp_enhanced_path = os.path.join(output_dir, 'temp_enhanced_sample.xlsx')\n",
    "    enhanced_df.to_excel(temp_enhanced_path, index=False)\n",
    "    \n",
    "    try:\n",
    "        # Apply preprocessing using existing function\n",
    "        final_df, preprocessing_metadata = preprocess_isbsg_data(\n",
    "            file_path=temp_enhanced_path,\n",
    "            target_col=target_col,\n",
    "            output_dir=output_dir,\n",
    "            cols_to_keep=cols_to_keep,\n",
    "            max_categorical_cardinality=max_categorical_cardinality,\n",
    "            standardization_mapping=standardization_mapping,\n",
    "            high_missing_threshold=high_missing_threshold\n",
    "        )\n",
    "        \n",
    "        return final_df, preprocessing_metadata\n",
    "        \n",
    "    finally:\n",
    "        # Clean up temporary file\n",
    "        try:\n",
    "            os.remove(temp_enhanced_path)\n",
    "        except:\n",
    "            print(f\"Warning: Could not remove temporary file {temp_enhanced_path}\")\n",
    "    \n",
    "    return enhanced_df, {'error': 'Preprocessing failed'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54df81cd-5503-4931-a2b8-2666049d5f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATA_FOLDER = ../data, SAMPLE_FILE = ISBSG2016R1_1_financial_industry_seed.xlsx, FULL_FILE = ISBSG2016R1_1_full_dataset.xlsx, TARGET_COL = project_prf_normalised_work_effort\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Configuration constants (define these at module level)\n",
    "#DATA_FOLDER = \"../data\"  # Update this path as needed\n",
    "#SAMPLE_FILE = \"sample_data.xlsx\"  # Update this filename as needed\n",
    "#FULL_FILE = \"full_data.xlsx\"  # Update this filename as needed\n",
    "#TARGET_COL = \"project_prf_normalised_work_effort\"\n",
    "\n",
    "print(f\"\\nDATA_FOLDER = {DATA_FOLDER}, SAMPLE_FILE = {SAMPLE_FILE}, FULL_FILE = {FULL_FILE}, TARGET_COL = {TARGET_COL}\")\n",
    "\n",
    "# Main execution function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the integrated pipeline\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    sample_file_path = os.path.join(CONFIG_FOLDER, SAMPLE_FILE)\n",
    "    full_file_path = os.path.join(DATA_FOLDER, FULL_FILE)\n",
    "    FINANCE = \"finance\"\n",
    "    \n",
    "\n",
    "        # Columns to exclude (customize as needed)\n",
    "    cols_to_exclude_add_category = [\n",
    "        'external_eef_industry_sector', \n",
    "        'external_eef_organisation_type',\n",
    "        'project_prf_application_type', \n",
    "     ]\n",
    "    \n",
    "    # Columns to keep (customize as needed)\n",
    "    cols_to_keep = [\n",
    "        'Project_PRF_CASE_Tool_Used', \n",
    "        'Process_PMF_Prototyping_Used',\n",
    "        'Tech_TF_Client_Roles', \n",
    "        'Tech_TF_Type_of_Server', \n",
    "        'Tech_TF_ClientServer_Description'\n",
    "    ]\n",
    "    \n",
    "    # High-cardinality multi-value columns\n",
    "    high_card_columns = [\n",
    "        'external_eef_organisation_type', \n",
    "        'project_prf_application_type'\n",
    "    ]\n",
    "    \n",
    "    # Standardization rules\n",
    "    standardization_map = {\n",
    "        'stand alone': 'stand-alone',\n",
    "        'client server': 'client-server',\n",
    "        'mathematically intensive': 'mathematically-intensive',\n",
    "        #'mathematically intensive application': 'mathematically-intensive application',\n",
    "        \"file &/or print server\": \"file/print server\",\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Run integrated pipeline\n",
    "        final_df, metadata = integrated_categorical_preprocessing(\n",
    "            sample_file_path=sample_file_path,\n",
    "            full_file_path=full_file_path,\n",
    "            target_col=TARGET_COL,\n",
    "            output_dir=DATA_FOLDER,\n",
    "            cols_to_keep=cols_to_keep,\n",
    "            high_card_columns=high_card_columns,\n",
    "            max_categorical_cardinality=10,\n",
    "            samples_per_category=3,\n",
    "            standardization_mapping=standardization_map,\n",
    "            high_missing_threshold=0.7,\n",
    "            separator=';',\n",
    "            strategy='top_k',\n",
    "            k=20,\n",
    "            exclude_from_enhancement=cols_to_exclude_add_category\n",
    "        )\n",
    "        \n",
    "        # Save results\n",
    "        if FINANCE in sample_file_path:\n",
    "            output_path = os.path.join(DATA_FOLDER, f\"{FINANCE}_enhanced_sample_final.csv\")\n",
    "        else:\n",
    "            output_path = os.path.join(DATA_FOLDER, 'enhanced_sample_final.csv')\n",
    "            \n",
    "        final_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Final dataset saved to: {output_path}\")\n",
    "        print(f\"Final shape: {final_df.shape}\")\n",
    "        print(f\"Ready for PyCaret setup!\")\n",
    "        \n",
    "        # Print summary of changes\n",
    "        print(f\"\\nSUMMARY:\")\n",
    "        print(f\"- Original sample rows: {metadata['original_sample_shape'][0]}\")\n",
    "        print(f\"- Rows added from full dataset: {metadata['rows_added_from_full_dataset']}\")\n",
    "        print(f\"- Final rows: {metadata['final_shape'][0]}\")\n",
    "        print(f\"- Original columns: {metadata['original_sample_shape'][1]}\")\n",
    "        print(f\"- Final columns: {metadata['final_shape'][1]}\")\n",
    "        \n",
    "        return final_df, metadata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in integrated pipeline: {e}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bf03c5-31b5-4093-916e-9ca5efc4702b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fa1ff42-b05a-4697-b88a-390c4fac38f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INTEGRATED CATEGORICAL PREPROCESSING PIPELINE\n",
      "============================================================\n",
      "\n",
      "1. Loading datasets...\n",
      "Sample dataset shape: (939, 51)\n",
      "Full dataset shape: (7518, 52)\n",
      "\n",
      "2. Auto-detecting categorical columns...\n",
      "Detected categorical columns: ['external_eef_data quality rating', 'external_eef_industry sector', 'external_eef_organisation type', 'project_prf_application group', 'project_prf_application type', 'project_prf_development type', 'tech_tf_development platform', 'tech_tf_language type', 'tech_tf_primary programming language', 'project_prf_relative size', 'project_prf_team size group', 'project_prf_case tool used', 'process_pmf_prototyping used', 'process_pmf_docs', 'tech_tf_architecture', 'tech_tf_client_server', 'tech_tf_client_roles', 'tech_tf_server_roles', 'tech_tf_type_of_server', 'tech_tf_client/server_description', 'tech_tf_web_development', 'tech_tf_dbms_used', 'tech_tf_tools_used', 'people_prf_project_user_involvement', 'people_prf_ba_team_experience_less_than_1_yr', 'people_prf_ba_team_experience_1_to_3_yr', 'people_prf_ba_team_experience_great_than_3_yr', 'people_prf_it_experience_less_than_1_yr', 'people_prf_it_experience_1_to_3_yr', 'people_prf_it_experience_great_than_3_yr', 'people_prf_it_experience_less_than_3_yr', 'people_prf_it_experience_3_to_9_yr', 'people_prf_it_experience_great_than_9_yr', 'people_prf_project_manage_experience', 'people_prf_project_manage_changes', 'people_prf_personnel_changes', 'project_prf_cost_currency', 'project_prf_currency_multiple']\n",
      "\n",
      "3. Processing high-cardinality multi-value columns...\n",
      "\n",
      "4. Applying same processing to sample dataset...\n",
      "\n",
      "5. Updating categorical columns after high-cardinality processing...\n",
      "Updated categorical columns: 30 columns\n",
      "\\n6. Enhancing sample with missing categories from full dataset...\n",
      "Excluding columns from enhancement: ['external_eef_industry_sector', 'external_eef_organisation_type', 'project_prf_application_type']\n",
      "Columns that will be enhanced: 30 out of 30\n",
      "Analyzing missing categories...\n",
      "Column 'external_eef_data quality rating': All categories present in sample\n",
      "Column 'external_eef_industry sector': Missing 15 out of 17 categories\n",
      "  Missing categories: ['Wholesale & Retail', 'Education', 'Communication', 'Logistics', 'Service Industry']...\n",
      "Column 'external_eef_organisation type': Missing 178 out of 193 categories\n",
      "  Missing categories: ['Medical and Health Care;Professional Services;', 'Computers & Software;Citizens of DK;', 'Content Management;', 'Wholesale & Retail Trade;Oil;', 'Wholesale & Retail Trade;Financial, Property & Business Services;']...\n",
      "Column 'project_prf_application group': Missing 2 out of 6 categories\n",
      "  Missing categories: ['Mathematically intensive application', 'Business Application; Infrastructure Software;']\n",
      "Column 'project_prf_application type': Missing 518 out of 568 categories\n",
      "  Missing categories: ['Stock control & order processing;Workflow support & management;Electronic Data Interchange;', 'MiddleWare Telecom Switching;', 'Car test management;', 'Device or interface driver;', 'Management or performance reporting;Electronic Data Interchange;']...\n",
      "Column 'project_prf_development type': Missing 2 out of 7 categories\n",
      "  Missing categories: ['Porting', 'Other']\n",
      "Column 'tech_tf_development platform': Missing 1 out of 6 categories\n",
      "  Missing categories: ['Hand Held']\n",
      "Column 'tech_tf_language type': Missing 1 out of 6 categories\n",
      "  Missing categories: ['APG']\n",
      "Column 'tech_tf_primary programming language': Missing 80 out of 128 categories\n",
      "  Missing categories: ['gcc', 'MATLAB', 'PHP', 'Azure', 'Delphi']...\n",
      "Column 'project_prf_relative size': Missing 1 out of 9 categories\n",
      "  Missing categories: ['XXXL']\n",
      "Column 'project_prf_team size group': Missing 4 out of 15 categories\n",
      "  Missing categories: ['101+', '71-80', '51-60', '91-100']\n",
      "Column 'project_prf_case tool used': All categories present in sample\n",
      "Column 'process_pmf_prototyping used': All categories present in sample\n",
      "Column 'tech_tf_architecture': Missing 2 out of 7 categories\n",
      "  Missing categories: ['Multi-tier with web interface', 'Stand-alone']\n",
      "Column 'tech_tf_client_server': All categories present in sample\n",
      "Column 'tech_tf_client_roles': Missing 43 out of 61 categories\n",
      "  Missing categories: ['Data entry & validation;Device/equipment interface;Web/HTML browser;', 'Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;', 'Web/HTML browser;Web public interface;', 'Run a computer-human interface;Data retrieval & presentation;Web/HTML browser;Security;', 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Device/equipment interface;Web/HTML browser;']...\n",
      "Column 'tech_tf_server_roles': Missing 70 out of 85 categories\n",
      "  Missing categories: ['Database server;FTP server;Messaging server;', 'Database server;File &/or print server;HTML/web server;Mail server;Messaging server;', 'Database server;File &/or print server;HTML/web server;Mail server;Messaging server;Object/component server;Security/authentication;', 'Database server;File &/or print server;FTP server;Multi-user legacy application;', 'Database server;Multi-user legacy application;Object/component server;']...\n",
      "Column 'tech_tf_type_of_server': Missing 4 out of 9 categories\n",
      "  Missing categories: ['Stand alone;', 'Client server;', 'Multi-tier with web public interface;', 'webserver;']\n",
      "Column 'tech_tf_client/server_description': Missing 16 out of 26 categories\n",
      "  Missing categories: ['not assessed;', 'Stand-alone;', '25%;', 'Presentation & Logic on server;', 'Client-server Architecture/P2P;']...\n",
      "Column 'tech_tf_web_development': All categories present in sample\n",
      "Column 'tech_tf_dbms_used': All categories present in sample\n",
      "Column 'people_prf_project_user_involvement': Missing 2 out of 5 categories\n",
      "  Missing categories: ['Best', 'Low']\n",
      "Column 'people_prf_ba_team_experience_less_than_1_yr': Missing 14 out of 22 categories\n",
      "  Missing categories: [5.0, 7.0, 8.0, 9.0, 10.0]...\n",
      "Column 'people_prf_it_experience_less_than_1_yr': Missing 4 out of 12 categories\n",
      "  Missing categories: [16.0, 9.0, 10.0, 24.0]\n",
      "Column 'people_prf_it_experience_less_than_3_yr': Missing 11 out of 20 categories\n",
      "  Missing categories: [33.0, 36.0, 7.0, 8.0, 9.0]...\n",
      "Column 'people_prf_it_experience_great_than_9_yr': Missing 15 out of 22 categories\n",
      "  Missing categories: [5.0, 6.0, 9.0, 10.0, 11.0]...\n",
      "Column 'people_prf_project_manage_changes': Missing 1 out of 5 categories\n",
      "  Missing categories: [4.0]\n",
      "Column 'people_prf_personnel_changes': Missing 11 out of 16 categories\n",
      "  Missing categories: [4.0, 5.0, 6.0, 7.0, 8.0]...\n",
      "Column 'project_prf_cost_currency': Missing 11 out of 19 categories\n",
      "  Missing categories: ['South Africa, rand', 'New Zealand, dollar', 'India, Rupees', 'Germany, Mark', 'India, rupee']...\n",
      "Column 'project_prf_currency_multiple': Missing 2 out of 3 categories\n",
      "  Missing categories: ['Yes 1,000', 'Yes 10,000']\n",
      "\n",
      "Sampling for column 'external_eef_industry sector'...\n",
      "  Added 3 rows for 'Wholesale & Retail' (out of 134 available)\n",
      "  Added 3 rows for 'Education' (out of 23 available)\n",
      "  Added 3 rows for 'Communication' (out of 1410 available)\n",
      "  Added 3 rows for 'Logistics' (out of 39 available)\n",
      "  Added 3 rows for 'Service Industry' (out of 190 available)\n",
      "  Added 3 rows for 'Utilities' (out of 69 available)\n",
      "  Added 3 rows for 'Electronics & Computers' (out of 192 available)\n",
      "  Added 3 rows for 'Insurance' (out of 1100 available)\n",
      "  Added 3 rows for 'Manufacturing' (out of 822 available)\n",
      "  Added 3 rows for 'Medical & Health Care' (out of 512 available)\n",
      "  Added 3 rows for 'Professional Services' (out of 63 available)\n",
      "  Added 3 rows for 'Government' (out of 658 available)\n",
      "  Added 3 rows for 'Construction' (out of 42 available)\n",
      "  Added 3 rows for 'Defence' (out of 21 available)\n",
      "  Added 3 rows for 'Mining' (out of 16 available)\n",
      "\n",
      "Sampling for column 'external_eef_organisation type'...\n",
      "  Added 2 rows for 'Medical and Health Care;Professional Services;' (out of 2 available)\n",
      "  Added 1 rows for 'Computers & Software;Citizens of DK;' (out of 1 available)\n",
      "  Added 1 rows for 'Content Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Wholesale & Retail Trade;Oil;' (out of 1 available)\n",
      "  Added 1 rows for 'Wholesale & Retail Trade;Financial, Property & Business Services;' (out of 1 available)\n",
      "  Added 3 rows for 'Electronics;' (out of 12 available)\n",
      "  Added 3 rows for 'Engineering;' (out of 15 available)\n",
      "  Added 1 rows for 'Manufacturing;Consumer Goods;' (out of 1 available)\n",
      "  Added 3 rows for 'Ordering;' (out of 23 available)\n",
      "  Added 1 rows for 'Manufacturing;Wholesale & Retail Trade;' (out of 1 available)\n",
      "  Added 1 rows for 'Travel;' (out of 1 available)\n",
      "  Added 3 rows for 'Community Services;' (out of 43 available)\n",
      "  Added 1 rows for 'Service;Recreation, Personnel & Other Services;' (out of 1 available)\n",
      "  Added 3 rows for 'Electricity, Gas, Water;' (out of 57 available)\n",
      "  Added 3 rows for 'Art , Events , Ticketing;' (out of 3 available)\n",
      "  Added 3 rows for 'Telecommunication;' (out of 134 available)\n",
      "  Added 3 rows for 'E-Business;' (out of 6 available)\n",
      "  Added 2 rows for 'High Tech;' (out of 2 available)\n",
      "  Added 2 rows for 'Recreation & Personnel Services;Professional Services;Computers & Software;' (out of 2 available)\n",
      "  Added 3 rows for 'Professional Services;Computers & Software;' (out of 3 available)\n",
      "  Added 1 rows for 'Government;Municipal;' (out of 1 available)\n",
      "  Added 1 rows for 'Wholesale & Retail Trade;Computers & Software;' (out of 1 available)\n",
      "  Added 2 rows for 'Government;Professional Services;' (out of 2 available)\n",
      "  Added 3 rows for 'Aerospace / Automotive;' (out of 73 available)\n",
      "  Added 2 rows for 'Computer Systems Consultant;Public Administration;' (out of 2 available)\n",
      "  Added 1 rows for 'Government;Electricity, Gas, Water;Communications;Community Services;Professional Services;Electronics;' (out of 1 available)\n",
      "  Added 2 rows for 'general public (mobile phone end user);' (out of 2 available)\n",
      "  Added 1 rows for 'Real Estate & Property;Community Services;' (out of 1 available)\n",
      "  Added 3 rows for 'Telecommunications;' (out of 516 available)\n",
      "  Added 2 rows for 'Public Administration;Aerospace / Automotive;Computers & Software;Insurance;' (out of 2 available)\n",
      "  Added 1 rows for 'Chemicals;Community Services;Electricity, Gas, Water;Government;' (out of 1 available)\n",
      "  Added 1 rows for 'Transport & Storage;Public Administration;' (out of 1 available)\n",
      "  Added 3 rows for 'Local;' (out of 14 available)\n",
      "  Added 1 rows for 'Citizens and the Municipalities;' (out of 1 available)\n",
      "  Added 1 rows for 'Chemicals;Energy;' (out of 1 available)\n",
      "  Added 2 rows for 'Surveillance & Security;' (out of 2 available)\n",
      "  Added 2 rows for 'Manufacturing;Oil;' (out of 2 available)\n",
      "  Added 1 rows for 'Manufacturing;Manufacture of steel products;' (out of 1 available)\n",
      "  Added 2 rows for 'Computers & Software;Consumer Goods;Electronics;' (out of 2 available)\n",
      "  Added 1 rows for 'Construction;Financial, Property & Business Services;Government;Real Estate & Property;Transport & Storage;Housing;' (out of 1 available)\n",
      "  Added 3 rows for 'Oil;' (out of 6 available)\n",
      "  Added 1 rows for 'Transport & Storage;Aerospace / Automotive;' (out of 1 available)\n",
      "  Added 1 rows for 'Restaurant;' (out of 1 available)\n",
      "  Added 3 rows for 'Food Processing;' (out of 7 available)\n",
      "  Added 1 rows for 'Coronial Services;' (out of 1 available)\n",
      "  Added 2 rows for 'Car Rental;' (out of 2 available)\n",
      "  Added 3 rows for 'Government;Public Administration (Revenue);' (out of 5 available)\n",
      "  Added 2 rows for 'Publishing;' (out of 2 available)\n",
      "  Added 3 rows for 'Software products;' (out of 8 available)\n",
      "  Added 2 rows for 'Sales;' (out of 2 available)\n",
      "  Added 1 rows for 'Manufacturing;Professional Services;' (out of 1 available)\n",
      "  Added 2 rows for 'Public Administration;Community Services;' (out of 2 available)\n",
      "  Added 2 rows for 'Air Traffic Management;' (out of 2 available)\n",
      "  Added 3 rows for 'Consumer Goods;' (out of 15 available)\n",
      "  Added 1 rows for 'Agriculture, Forestry, Fishing, Hunting;Government;' (out of 1 available)\n",
      "  Added 1 rows for 'Professional Services;Environmental Consulting;' (out of 1 available)\n",
      "  Added 3 rows for 'Energy;' (out of 9 available)\n",
      "  Added 3 rows for 'Information Technology;' (out of 10 available)\n",
      "  Added 3 rows for 'Marketing;' (out of 3 available)\n",
      "  Added 1 rows for 'Community Services;Institutions eg. Kindergartens;' (out of 1 available)\n",
      "  Added 3 rows for 'Utilities;' (out of 7 available)\n",
      "  Added 1 rows for 'Government, Public Administration (Revenue);' (out of 1 available)\n",
      "  Added 3 rows for 'Mining;Manufacturing;Chemicals;' (out of 3 available)\n",
      "  Added 3 rows for 'Retail;' (out of 3 available)\n",
      "  Added 1 rows for 'Developing global software solutions;' (out of 1 available)\n",
      "  Added 3 rows for 'Chemicals;' (out of 18 available)\n",
      "  Added 3 rows for 'Transport & Storage;' (out of 48 available)\n",
      "  Added 1 rows for 'Security;' (out of 1 available)\n",
      "  Added 1 rows for 'Education;' (out of 1 available)\n",
      "  Added 1 rows for 'Transport & Storage;Media;' (out of 1 available)\n",
      "  Added 1 rows for 'Research & development;' (out of 1 available)\n",
      "  Added 1 rows for 'Government;Danish citizens;' (out of 1 available)\n",
      "  Added 1 rows for 'Any organization which counts function points;' (out of 1 available)\n",
      "  Added 1 rows for 'Government;Defence;Aerospace / Automotive;' (out of 1 available)\n",
      "  Added 3 rows for 'Public Administration;' (out of 174 available)\n",
      "  Added 3 rows for 'Manufacturing;' (out of 699 available)\n",
      "  Added 3 rows for 'Wholesale & Retail Trade;' (out of 54 available)\n",
      "  Added 1 rows for 'Manufacturing;Computers;Diversified Corp;' (out of 1 available)\n",
      "  Added 1 rows for 'Government;Real Estate & Property;Education Institution;Manufacturing;Construction;Wholesale & Retail Trade;Transport & Storage;Communications;Medical and Health Care;Community Services;Defence;Financial, Property & Business Services;Banking;Professional' (out of 1 available)\n",
      "  Added 3 rows for 'Communications;' (out of 708 available)\n",
      "  Added 3 rows for 'Defence;' (out of 17 available)\n",
      "  Added 3 rows for 'Wholesale & Retail Trade;Transport & Storage;' (out of 4 available)\n",
      "  Added 1 rows for 'Government;Local administration and counties;' (out of 1 available)\n",
      "  Added 3 rows for 'Agriculture, Forestry, Fishing, Hunting;Manufacturing;' (out of 5 available)\n",
      "  Added 1 rows for 'Telecom;' (out of 1 available)\n",
      "  Added 3 rows for 'Professional Services;' (out of 23 available)\n",
      "  Added 3 rows for 'Business Services;' (out of 5 available)\n",
      "  Added 3 rows for 'Government;' (out of 334 available)\n",
      "  Added 1 rows for 'All industry organization types;' (out of 1 available)\n",
      "  Added 1 rows for 'Energy Sources (Oil & Petroleum/Electricity etc);' (out of 1 available)\n",
      "  Added 1 rows for 'Education Institution;Research;' (out of 1 available)\n",
      "  Added 1 rows for 'Medical and Health Care;Public Administration;Insurance;' (out of 1 available)\n",
      "  Added 1 rows for 'Communications;Financial (Banking, Insurance, Stock);Government;Public Administration (Revenue);Manufacturing;Medical and Health Care;Post;Traffic (Aerospace/railway/Automotive);Transport;Logistic (Wholesale & Retail/Storage);Research & Development;Energy' (out of 1 available)\n",
      "  Added 1 rows for 'Distribution;' (out of 1 available)\n",
      "  Added 3 rows for 'Logistics;' (out of 39 available)\n",
      "  Added 3 rows for 'Communications;Telecom;' (out of 5 available)\n",
      "  Added 3 rows for 'Information Technology Services Provider;' (out of 5 available)\n",
      "  Added 3 rows for 'Government;Community Services;' (out of 23 available)\n",
      "  Added 2 rows for 'Post/mail services;' (out of 2 available)\n",
      "  Added 1 rows for 'Occupational Health and Safety;' (out of 1 available)\n",
      "  Added 3 rows for 'Agriculture, Forestry, Fishing, Hunting;' (out of 5 available)\n",
      "  Added 1 rows for 'IT Services;' (out of 1 available)\n",
      "  Added 1 rows for 'Biotech;' (out of 1 available)\n",
      "  Added 1 rows for 'Community Services;Municipality;' (out of 1 available)\n",
      "  Added 1 rows for 'UniversityEvent Management-involves external users;' (out of 1 available)\n",
      "  Added 3 rows for 'Government;Defence;' (out of 62 available)\n",
      "  Added 1 rows for 'Public Sector;' (out of 1 available)\n",
      "  Added 3 rows for 'Engineering;Research & Development;Software Development;Client/Server architecture for Language Services;' (out of 15 available)\n",
      "  Added 2 rows for 'Real Estate & Property;' (out of 2 available)\n",
      "  Added 3 rows for 'Government;Public Administration;' (out of 7 available)\n",
      "  Added 1 rows for 'Communications;Electronics;' (out of 1 available)\n",
      "  Added 3 rows for 'General;' (out of 4 available)\n",
      "  Added 1 rows for 'Information Technology;Human Resource (HR) Domain;' (out of 1 available)\n",
      "  Added 2 rows for 'Computers and IT business;' (out of 2 available)\n",
      "  Added 2 rows for 'Airport;' (out of 2 available)\n",
      "  Added 2 rows for 'Internet;' (out of 2 available)\n",
      "  Added 3 rows for 'Oil & Petroleum;' (out of 3 available)\n",
      "  Added 3 rows for 'Logistic (Wholesale & Retail/Storage);' (out of 4 available)\n",
      "  Added 1 rows for 'Warehouse Management;' (out of 1 available)\n",
      "  Added 3 rows for 'Media;' (out of 11 available)\n",
      "  Added 3 rows for 'Insurance;' (out of 1096 available)\n",
      "  Added 1 rows for 'Computer Consultants;' (out of 1 available)\n",
      "  Added 3 rows for 'Education Institution;' (out of 10 available)\n",
      "  Added 3 rows for 'Manufacturing;Transport & Storage;' (out of 8 available)\n",
      "  Added 3 rows for 'Medical and Health Care;' (out of 508 available)\n",
      "  Added 1 rows for 'Transit Corporation;' (out of 1 available)\n",
      "  Added 1 rows for 'Computers & Software;Human Ressources;' (out of 1 available)\n",
      "  Added 1 rows for 'Community Services;Invoice-handling;' (out of 1 available)\n",
      "  Added 1 rows for 'IS-Metrics collection system;' (out of 1 available)\n",
      "  Added 1 rows for 'Government;Municipality;' (out of 1 available)\n",
      "  Added 1 rows for 'Manufacturing;Wholesale & Retail Trade;Transport & Storage;' (out of 1 available)\n",
      "  Added 3 rows for 'Billing;' (out of 22 available)\n",
      "  Added 3 rows for 'Construction;' (out of 23 available)\n",
      "  Added 1 rows for 'Agriculture, Forestry, Fishing, Hunting;Transport & Storage;' (out of 1 available)\n",
      "  Added 3 rows for 'Communications;Telecom & Networking;' (out of 3 available)\n",
      "  Added 1 rows for 'Aerospace / Automotive;Chemicals;Defence;Electronics;Food Processing;Government;Manufacturing;Medical and Health Care;Mining;Oil & Petroleum;Transport & Storage;Generic application;' (out of 1 available)\n",
      "  Added 3 rows for 'All-purpose;' (out of 3 available)\n",
      "  Added 3 rows for 'Building Automation;' (out of 4 available)\n",
      "  Added 1 rows for 'Government;Real Estate & Property;' (out of 1 available)\n",
      "  Added 1 rows for 'Tax administration;' (out of 1 available)\n",
      "  Added 1 rows for 'Government;Medical and Health Care;' (out of 1 available)\n",
      "  Added 1 rows for 'Exhibition Management;' (out of 1 available)\n",
      "  Added 3 rows for 'Sales & Marketing;' (out of 7 available)\n",
      "  Added 3 rows for 'Mining;' (out of 4 available)\n",
      "  Added 3 rows for 'Consultancy;' (out of 4 available)\n",
      "  Added 1 rows for 'Virtual Assistants (Lingubots);' (out of 1 available)\n",
      "  Added 1 rows for 'Imaging;' (out of 1 available)\n",
      "  Added 3 rows for 'Government;Public administration;' (out of 4 available)\n",
      "  Added 1 rows for 'Human Resource (HR) Domain;' (out of 1 available)\n",
      "  Added 2 rows for 'Communications;Computers & Software;' (out of 2 available)\n",
      "  Added 3 rows for 'Service;' (out of 4 available)\n",
      "  Added 1 rows for 'Manufacturing;Computers;Diversified corporation;' (out of 1 available)\n",
      "  Added 1 rows for 'Services;' (out of 1 available)\n",
      "  Added 3 rows for 'Recreation & Personnel Services;' (out of 13 available)\n",
      "  Added 1 rows for 'Transport & Storage;Professional Services;' (out of 1 available)\n",
      "  Added 3 rows for 'Public Administration;Insurance;' (out of 6 available)\n",
      "  Added 1 rows for 'Aerospace / Automotive;Computers & Software;' (out of 1 available)\n",
      "  Added 1 rows for 'Universal;' (out of 1 available)\n",
      "  Added 3 rows for 'Education Institution;Electricity, Gas, Water;University;' (out of 5 available)\n",
      "  Added 1 rows for 'Government;Electricity, Gas, Water;' (out of 1 available)\n",
      "  Added 1 rows for 'Government;Health Sciences;' (out of 1 available)\n",
      "  Added 3 rows for 'Education Institution;Electricity, Gas, Water;IEEE;' (out of 6 available)\n",
      "  Added 3 rows for 'Computers & Software;' (out of 122 available)\n",
      "  Added 3 rows for 'Public Administration;Community Services;Insurance;' (out of 45 available)\n",
      "  Added 1 rows for 'Community Services;Government;Public administration;' (out of 1 available)\n",
      "  Added 1 rows for 'Post;' (out of 1 available)\n",
      "  Added 1 rows for 'Traffic (Aerospace/Railway/Automotive);Transport;' (out of 1 available)\n",
      "  Added 1 rows for 'Wholesale & Retail Trade;Consumer Goods;' (out of 1 available)\n",
      "  Added 1 rows for 'Environmental Monitoring;Public Administration;' (out of 1 available)\n",
      "  Added 3 rows for 'Defence;Aerospace / Automotive;' (out of 3 available)\n",
      "  Added 3 rows for 'Maintenance;' (out of 8 available)\n",
      "  Added 1 rows for 'Commercial services;' (out of 1 available)\n",
      "  Added 1 rows for 'Data Provisioning;' (out of 1 available)\n",
      "  Added 3 rows for 'Government;Municipal Services;' (out of 4 available)\n",
      "  Added 1 rows for 'Advertising;' (out of 1 available)\n",
      "  Added 1 rows for 'Agriculture, Forestry, Fishing, Hunting;Chemicals;Computers & Software;Construction;Defence;Electricity, Gas, Water;Electronics;Food Processing;Government;generic application;' (out of 1 available)\n",
      "  Added 3 rows for 'Voice Provisioning;' (out of 17 available)\n",
      "  Added 3 rows for 'Manufacturing;Computers & Software;' (out of 3 available)\n",
      "\n",
      "Sampling for column 'project_prf_application group'...\n",
      "  Added 3 rows for 'Mathematically intensive application' (out of 6 available)\n",
      "  Added 2 rows for 'Business Application; Infrastructure Software;' (out of 2 available)\n",
      "\n",
      "Sampling for column 'project_prf_application type'...\n",
      "  Added 1 rows for 'Stock control & order processing;Workflow support & management;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'MiddleWare Telecom Switching;' (out of 1 available)\n",
      "  Added 1 rows for 'Car test management;' (out of 1 available)\n",
      "  Added 1 rows for 'Device or interface driver;' (out of 1 available)\n",
      "  Added 1 rows for 'Management or performance reporting;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Micro Marketing;' (out of 1 available)\n",
      "  Added 1 rows for 'Web-based App. J2EE;' (out of 1 available)\n",
      "  Added 2 rows for 'After sales Documentation;' (out of 2 available)\n",
      "  Added 1 rows for 'Fault Tolerance;Management Information System;Fault Management;' (out of 1 available)\n",
      "  Added 2 rows for 'Personal productivity (e.g. spreadsheet);' (out of 2 available)\n",
      "  Added 1 rows for 'Car Sales;' (out of 1 available)\n",
      "  Added 1 rows for 'Document management;Workflow support & management;' (out of 1 available)\n",
      "  Added 1 rows for 'Data protection;' (out of 1 available)\n",
      "  Added 1 rows for 'Computer Integrated Manufactuaring system;' (out of 1 available)\n",
      "  Added 1 rows for 'Car embedded Computer Management;' (out of 1 available)\n",
      "  Added 2 rows for 'Manufacturing process management;' (out of 2 available)\n",
      "  Added 1 rows for 'Fault Tolerance;Process Control;Call Centre;' (out of 1 available)\n",
      "  Added 1 rows for 'Telecom Data Circuits;' (out of 1 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Job, case, incident, project management;Personal productivity (e.g. spreadsheet);Workflow support & management;' (out of 1 available)\n",
      "  Added 1 rows for 'Management and follow up of the parts;' (out of 1 available)\n",
      "  Added 1 rows for 'Network management;' (out of 1 available)\n",
      "  Added 1 rows for 'Diagnostic distribution  management;' (out of 1 available)\n",
      "  Added 3 rows for 'MS Business Platform;' (out of 4 available)\n",
      "  Added 1 rows for 'Vehicle Systems Software;' (out of 1 available)\n",
      "  Added 3 rows for 'Tools or system;' (out of 5 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Management or performance reporting;Data Warehouse system;' (out of 1 available)\n",
      "  Added 3 rows for 'Financial application area;' (out of 142 available)\n",
      "  Added 1 rows for 'Operating system or software utility;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 2 rows for 'Client-Server Application;' (out of 2 available)\n",
      "  Added 1 rows for 'e-commerce;' (out of 1 available)\n",
      "  Added 3 rows for 'Local;' (out of 8 available)\n",
      "  Added 2 rows for 'Financial transaction processing & Accounting;' (out of 2 available)\n",
      "  Added 1 rows for 'Operating system or software utility;Workflow support & management;' (out of 1 available)\n",
      "  Added 1 rows for 'Car pricing;' (out of 1 available)\n",
      "  Added 1 rows for 'Taxation;' (out of 1 available)\n",
      "  Added 1 rows for 'Qualty Factory Reporting;' (out of 1 available)\n",
      "  Added 1 rows for 'Web;' (out of 1 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;CRM;' (out of 1 available)\n",
      "  Added 1 rows for 'Pollution statistics;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Document management;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Post exchange;' (out of 1 available)\n",
      "  Added 2 rows for 'Air Traffic Management;' (out of 2 available)\n",
      "  Added 3 rows for 'Network Management;Telecom & Networking;' (out of 3 available)\n",
      "  Added 1 rows for 'Insurance annities;Online user interface;' (out of 1 available)\n",
      "  Added 1 rows for 'Workflow support & management;Management Information System;' (out of 1 available)\n",
      "  Added 1 rows for 'Military;' (out of 1 available)\n",
      "  Added 1 rows for 'Document management;Logistic or supply planning & control;Online analysis and reporting;Personal productivity (e.g. spreadsheet);Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Scientific/Math;' (out of 1 available)\n",
      "  Added 1 rows for 'Test Equipment;' (out of 1 available)\n",
      "  Added 1 rows for 'Technical administrative system;' (out of 1 available)\n",
      "  Added 1 rows for 'Pay;' (out of 1 available)\n",
      "  Added 1 rows for 'HR;' (out of 1 available)\n",
      "  Added 3 rows for 'Business;Workflow support & management;' (out of 3 available)\n",
      "  Added 1 rows for 'Premium Paid Certificate;' (out of 1 available)\n",
      "  Added 3 rows for 'Customer management;' (out of 19 available)\n",
      "  Added 3 rows for 'Image, video or sound processing;' (out of 3 available)\n",
      "  Added 1 rows for 'Communication systrem;' (out of 1 available)\n",
      "  Added 1 rows for 'Template for data-exchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Software for machine control;Complex process control;' (out of 1 available)\n",
      "  Added 2 rows for 'Idea/Patent Information System;' (out of 2 available)\n",
      "  Added 3 rows for 'Parts selling;' (out of 28 available)\n",
      "  Added 3 rows for 'Selling application;' (out of 4 available)\n",
      "  Added 1 rows for 'Document management;Operating system or software utility;' (out of 1 available)\n",
      "  Added 1 rows for 'Logistic tracking;' (out of 1 available)\n",
      "  Added 1 rows for 'Insurance quotation;' (out of 1 available)\n",
      "  Added 1 rows for 'Test vehicles Reporting;' (out of 1 available)\n",
      "  Added 1 rows for 'Number of Hosting Solution;' (out of 1 available)\n",
      "  Added 2 rows for 'Financial transaction process/accounting;Management or performance reporting;' (out of 2 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Document management;' (out of 3 available)\n",
      "  Added 3 rows for 'Website;' (out of 3 available)\n",
      "  Added 1 rows for 'MultiMedia;' (out of 1 available)\n",
      "  Added 3 rows for 'Sales promotion tool;' (out of 5 available)\n",
      "  Added 3 rows for 'Integration;' (out of 41 available)\n",
      "  Added 1 rows for 'Mathematical modelling (finance or eng.);Software development tool;' (out of 1 available)\n",
      "  Added 3 rows for 'Information systems;' (out of 5 available)\n",
      "  Added 3 rows for 'Online. eSales;' (out of 87 available)\n",
      "  Added 3 rows for 'Mixed;' (out of 4 available)\n",
      "  Added 1 rows for 'Central database;' (out of 1 available)\n",
      "  Added 1 rows for 'Graphical Modeling;' (out of 1 available)\n",
      "  Added 1 rows for 'Tools management;' (out of 1 available)\n",
      "  Added 1 rows for 'Corporate Taxation;' (out of 1 available)\n",
      "  Added 3 rows for 'Embedded Systems;' (out of 17 available)\n",
      "  Added 1 rows for 'Administrative Support System;' (out of 1 available)\n",
      "  Added 1 rows for 'suppliers management;' (out of 1 available)\n",
      "  Added 2 rows for 'Technical Support  Information System;' (out of 2 available)\n",
      "  Added 3 rows for 'Document management;Management or performance reporting;' (out of 4 available)\n",
      "  Added 2 rows for 'After sales parts contract management;' (out of 2 available)\n",
      "  Added 2 rows for 'IdM;' (out of 2 available)\n",
      "  Added 1 rows for 'Supply Management;' (out of 1 available)\n",
      "  Added 3 rows for 'IT projet Management;' (out of 3 available)\n",
      "  Added 1 rows for 'Artifical Intelligence based engine;' (out of 1 available)\n",
      "  Added 2 rows for 'Directory Assistance;' (out of 2 available)\n",
      "  Added 2 rows for 'Database customers for Parts;' (out of 2 available)\n",
      "  Added 1 rows for 'GUI Interface Application;' (out of 1 available)\n",
      "  Added 1 rows for 'Customer Resource Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Car Documentation management;' (out of 1 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Online analysis and reporting;' (out of 5 available)\n",
      "  Added 1 rows for 'human resources organisation in the factories;' (out of 1 available)\n",
      "  Added 3 rows for 'Billing;' (out of 22 available)\n",
      "  Added 1 rows for 'Customs Informations management;' (out of 1 available)\n",
      "  Added 1 rows for 'Management of customs activities;' (out of 1 available)\n",
      "  Added 1 rows for 'Supporting of the commercial network;' (out of 1 available)\n",
      "  Added 1 rows for 'Simulator;' (out of 1 available)\n",
      "  Added 1 rows for 'Graphics & publishing tools or system;' (out of 1 available)\n",
      "  Added 1 rows for 'Retailler sells follow up;' (out of 1 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;Logistic or supply planning & control;' (out of 1 available)\n",
      "  Added 1 rows for 'Geographic or spatial information system;Image, video or sound processing;Job, case, incident, project management;Online analysis and reporting;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 2 rows for 'Management Information System;Office Information System;Transaction/Production System;' (out of 2 available)\n",
      "  Added 1 rows for 'Change Management Tool;' (out of 1 available)\n",
      "  Added 1 rows for 'Energy Reporting;' (out of 1 available)\n",
      "  Added 1 rows for 'Infrastructure;' (out of 1 available)\n",
      "  Added 1 rows for 'Car design tool;' (out of 1 available)\n",
      "  Added 2 rows for 'Financial transaction process/accounting;Graphics & publishing tools or system;Management or performance reporting;Online analysis and reporting;Personal productivity (e.g. spreadsheet);' (out of 2 available)\n",
      "  Added 1 rows for 'Motor simulator;' (out of 1 available)\n",
      "  Added 1 rows for 'Logistic or supply planning & control;Stock control & order processing;Complex process control;' (out of 1 available)\n",
      "  Added 1 rows for 'Parts reporting IS;' (out of 1 available)\n",
      "  Added 3 rows for 'After sales Parts documentation;' (out of 6 available)\n",
      "  Added 1 rows for 'New Screen Design;' (out of 1 available)\n",
      "  Added 3 rows for 'Customer billing;' (out of 17 available)\n",
      "  Added 1 rows for 'Building Automation;Embedded software - simple device control;Protocol Linux ARM9;Device or interface driver;' (out of 1 available)\n",
      "  Added 2 rows for 'Job, case, incident, project management;Online analysis and reporting;Personal productivity (e.g. spreadsheet);' (out of 2 available)\n",
      "  Added 3 rows for 'Maintenance;' (out of 9 available)\n",
      "  Added 1 rows for 'Workplace Savings;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Data or database management;' (out of 1 available)\n",
      "  Added 1 rows for 'To determine which IVR credit card refresh used;' (out of 1 available)\n",
      "  Added 1 rows for 'Stock factory manegement;' (out of 1 available)\n",
      "  Added 3 rows for 'Fixed asset;' (out of 3 available)\n",
      "  Added 1 rows for 'Process documentation;' (out of 1 available)\n",
      "  Added 1 rows for 'Purchaser performance management;' (out of 1 available)\n",
      "  Added 1 rows for 'Cost logistic Computing;' (out of 1 available)\n",
      "  Added 2 rows for 'Packaging Visibility System;' (out of 2 available)\n",
      "  Added 1 rows for 'Customer Billing;' (out of 1 available)\n",
      "  Added 2 rows for 'DB Serch system;' (out of 2 available)\n",
      "  Added 2 rows for 'Executive Information System;Management Information System;' (out of 2 available)\n",
      "  Added 1 rows for 'GPS Portal;' (out of 1 available)\n",
      "  Added 2 rows for 'Trading? (procurement management);' (out of 2 available)\n",
      "  Added 1 rows for 'Database  Parts;' (out of 1 available)\n",
      "  Added 1 rows for 'Software for machine control;Mathematical modelling (finance or eng.);' (out of 1 available)\n",
      "  Added 1 rows for 'Transaction/Production System;Artificial Intelligence;' (out of 1 available)\n",
      "  Added 1 rows for 'Forecastselling;' (out of 1 available)\n",
      "  Added 1 rows for 'Ordering;' (out of 1 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;Stock control & order processing;' (out of 1 available)\n",
      "  Added 3 rows for 'Inventory Management;' (out of 3 available)\n",
      "  Added 1 rows for 'Operating system or software utility;Synchronization of Outlook and Application;' (out of 1 available)\n",
      "  Added 3 rows for 'Geographic or spatial information system;' (out of 5 available)\n",
      "  Added 3 rows for 'Products management;' (out of 4 available)\n",
      "  Added 1 rows for 'Spec/Document Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Online System for University fraternities;' (out of 1 available)\n",
      "  Added 1 rows for 'Analysis and Environmental Risk Assessment;' (out of 1 available)\n",
      "  Added 1 rows for 'Reporting on factoring process;' (out of 1 available)\n",
      "  Added 1 rows for 'Geographic or spatial information system;Online analysis and reporting;' (out of 1 available)\n",
      "  Added 1 rows for 'Retailer sales reporting;' (out of 1 available)\n",
      "  Added 3 rows for 'E-Business;' (out of 6 available)\n",
      "  Added 1 rows for 'International;' (out of 1 available)\n",
      "  Added 2 rows for 'Msg.Switch/cel phone;' (out of 2 available)\n",
      "  Added 3 rows for 'MS Billing;' (out of 4 available)\n",
      "  Added 2 rows for 'Customer billing/relationship management;Contact Management;' (out of 2 available)\n",
      "  Added 1 rows for 'Condemnation proceedings;' (out of 1 available)\n",
      "  Added 3 rows for 'Factory parts follow up;' (out of 3 available)\n",
      "  Added 1 rows for 'Customer Data repository with applicatin interface;' (out of 1 available)\n",
      "  Added 3 rows for 'Management of Licences and Permits;' (out of 72 available)\n",
      "  Added 1 rows for 'Parts logistic management;' (out of 1 available)\n",
      "  Added 2 rows for 'Car Database;' (out of 2 available)\n",
      "  Added 3 rows for 'Suppliers Management;' (out of 3 available)\n",
      "  Added 1 rows for 'After selling reporting;' (out of 1 available)\n",
      "  Added 3 rows for 'Business;Customer billing/relationship management;' (out of 24 available)\n",
      "  Added 3 rows for 'Billing and ERP;' (out of 9 available)\n",
      "  Added 3 rows for 'Telecommunications;' (out of 4 available)\n",
      "  Added 1 rows for 'Business enabling service;' (out of 1 available)\n",
      "  Added 3 rows for 'Process of factory management;' (out of 3 available)\n",
      "  Added 3 rows for 'Follow up of car failure;' (out of 7 available)\n",
      "  Added 3 rows for 'Customer relationship management;' (out of 203 available)\n",
      "  Added 1 rows for 'Human ressources management;' (out of 1 available)\n",
      "  Added 1 rows for 'website for Parts selling;' (out of 1 available)\n",
      "  Added 1 rows for 'Performance monitoring;' (out of 1 available)\n",
      "  Added 1 rows for 'Track test management;' (out of 1 available)\n",
      "  Added 1 rows for 'Project Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Workflow support & management;Proposal creation and submission;' (out of 1 available)\n",
      "  Added 2 rows for 'Sales statistics;' (out of 2 available)\n",
      "  Added 1 rows for 'Cost Tools Computing;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue for IT products and IT services;' (out of 1 available)\n",
      "  Added 2 rows for 'Health Management;' (out of 2 available)\n",
      "  Added 1 rows for 'Employee self-service system;' (out of 1 available)\n",
      "  Added 2 rows for 'Management or performance reporting;Complex process control;' (out of 2 available)\n",
      "  Added 1 rows for 'Transaction/Production System;EDI front-end for order processing system;' (out of 1 available)\n",
      "  Added 1 rows for 'Management of the centre activities;' (out of 1 available)\n",
      "  Added 1 rows for 'Course Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Product Order management;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Document management;Customer relationship management;' (out of 1 available)\n",
      "  Added 1 rows for 'Case Management Study;' (out of 1 available)\n",
      "  Added 3 rows for 'MiddleWare;' (out of 12 available)\n",
      "  Added 3 rows for 'Logistic or supply planning & control;' (out of 37 available)\n",
      "  Added 3 rows for 'Trading;' (out of 25 available)\n",
      "  Added 2 rows for 'Instant Messaging client;' (out of 2 available)\n",
      "  Added 3 rows for 'Stock control & order processing;' (out of 73 available)\n",
      "  Added 2 rows for 'Quality management;' (out of 2 available)\n",
      "  Added 1 rows for 'Document management;Online analysis and reporting;Workflow support & management;Complex process control;' (out of 1 available)\n",
      "  Added 1 rows for 'Transportation;' (out of 1 available)\n",
      "  Added 1 rows for 'Information systems (Web);' (out of 1 available)\n",
      "  Added 2 rows for 'Car production;' (out of 2 available)\n",
      "  Added 1 rows for 'Distribution;' (out of 1 available)\n",
      "  Added 1 rows for 'Customer billing;e-commerce;' (out of 1 available)\n",
      "  Added 1 rows for 'Telecom;Network Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Logistic or supply planning & control;Complex process control;' (out of 1 available)\n",
      "  Added 3 rows for 'Protocols;' (out of 8 available)\n",
      "  Added 1 rows for 'Security/Authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'Scheduling of work orders assembly lines;' (out of 1 available)\n",
      "  Added 1 rows for 'Calculation and quotation of casualty insurance;' (out of 1 available)\n",
      "  Added 1 rows for 'Management of selling conditions to society;' (out of 1 available)\n",
      "  Added 1 rows for 'Document management;Financial transaction process/accounting;Personal productivity (e.g. spreadsheet);Workflow support & management;Complex process control;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 3 rows for 'Logistic or supply planning & control;Management or performance reporting;' (out of 4 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Financial transaction process/accounting;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 3 rows for 'Selling Organisation;' (out of 3 available)\n",
      "  Added 1 rows for 'Client Server and Mainframe;' (out of 1 available)\n",
      "  Added 1 rows for 'Hospital Information System;' (out of 1 available)\n",
      "  Added 1 rows for 'European homologation management;' (out of 1 available)\n",
      "  Added 3 rows for 'GEO Information Management;' (out of 10 available)\n",
      "  Added 1 rows for 'Selling programming;' (out of 1 available)\n",
      "  Added 2 rows for 'Factory follow up;' (out of 2 available)\n",
      "  Added 1 rows for 'Electronic Data Interchange;Reusable component;' (out of 1 available)\n",
      "  Added 1 rows for 'Device or interface driver;Financial transaction process/accounting;Online analysis and reporting;Complex process control;' (out of 1 available)\n",
      "  Added 1 rows for 'Factory change programming;' (out of 1 available)\n",
      "  Added 1 rows for 'Quality Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Algorithmic + DB;' (out of 1 available)\n",
      "  Added 1 rows for 'Document management;Logistic or supply planning & control;Online analysis and reporting;Personal productivity (e.g. spreadsheet);' (out of 1 available)\n",
      "  Added 1 rows for 'Online analysis and reporting;Personal productivity (e.g. spreadsheet);' (out of 1 available)\n",
      "  Added 1 rows for 'Parts requirement's calculation (DRP);' (out of 1 available)\n",
      "  Added 2 rows for 'Selling reporting;' (out of 2 available)\n",
      "  Added 1 rows for 'Network Management;Migration tool;' (out of 1 available)\n",
      "  Added 3 rows for 'Stock Management;' (out of 3 available)\n",
      "  Added 3 rows for 'Document management;Job, case, incident, project management;' (out of 3 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Management or performance reporting;Online analysis and reporting;Telecom & network management;' (out of 1 available)\n",
      "  Added 1 rows for 'Provider Management;' (out of 1 available)\n",
      "  Added 3 rows for 'Providing Management;' (out of 5 available)\n",
      "  Added 1 rows for 'Vendors management;' (out of 1 available)\n",
      "  Added 2 rows for 'Decision Support System;Management Information System;' (out of 2 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Processing application for public subsidies;' (out of 1 available)\n",
      "  Added 2 rows for 'Simulation of the behaviour of vehicles on the road;' (out of 2 available)\n",
      "  Added 1 rows for 'Protocol in Building automation;Protocol Enhancement;' (out of 1 available)\n",
      "  Added 1 rows for 'Job, case, incident, project management;Software for communities to support administration;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Management or performance reporting;' (out of 1 available)\n",
      "  Added 1 rows for 'Factory process follow up;' (out of 1 available)\n",
      "  Added 1 rows for 'Chemical Risks Information System;' (out of 1 available)\n",
      "  Added 1 rows for 'Dynamic calculation accessory drive and distribution;' (out of 1 available)\n",
      "  Added 1 rows for 'Job, case, incident, project management;Online analysis and reporting;' (out of 1 available)\n",
      "  Added 3 rows for 'Factory's process management;' (out of 6 available)\n",
      "  Added 3 rows for 'Purchasing;' (out of 4 available)\n",
      "  Added 1 rows for 'ERP;' (out of 1 available)\n",
      "  Added 3 rows for 'Reporting;' (out of 15 available)\n",
      "  Added 1 rows for 'Document management;Management or performance reporting;Online analysis and reporting;Workflow support & management;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Document management;Online analysis and reporting;Workflow support & management;Complex process control;' (out of 1 available)\n",
      "  Added 1 rows for 'Dealer management;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Job, case, incident, project management;' (out of 1 available)\n",
      "  Added 1 rows for 'Data Provisioning;' (out of 1 available)\n",
      "  Added 1 rows for 'Company car management;' (out of 1 available)\n",
      "  Added 3 rows for 'Car Database for factory;' (out of 3 available)\n",
      "  Added 1 rows for 'Spare parts management;' (out of 1 available)\n",
      "  Added 2 rows for 'After Sales management Contract service;' (out of 2 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Document management;Workflow support & management;' (out of 1 available)\n",
      "  Added 3 rows for 'Business;Network Management;' (out of 8 available)\n",
      "  Added 1 rows for 'Warranty Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Switching;' (out of 1 available)\n",
      "  Added 1 rows for 'Mathematical modelling (finance or engineering);' (out of 1 available)\n",
      "  Added 1 rows for 'Interactive Voice Response;' (out of 1 available)\n",
      "  Added 2 rows for 'Retailler sells reporting;' (out of 2 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Online analysis and reporting;Electronic Data Interchange;' (out of 3 available)\n",
      "  Added 1 rows for 'POS;' (out of 1 available)\n",
      "  Added 3 rows for 'Real-time System;' (out of 8 available)\n",
      "  Added 2 rows for 'Parts Selling website;' (out of 2 available)\n",
      "  Added 3 rows for 'Financial;' (out of 4 available)\n",
      "  Added 3 rows for 'Car logistic management;' (out of 6 available)\n",
      "  Added 1 rows for 'web;' (out of 1 available)\n",
      "  Added 3 rows for 'Engineering Software;' (out of 3 available)\n",
      "  Added 1 rows for 'Car electronic design;' (out of 1 available)\n",
      "  Added 1 rows for 'Rules documentation;' (out of 1 available)\n",
      "  Added 1 rows for 'training Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Proposal Builder;' (out of 1 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Customer relationship management;' (out of 5 available)\n",
      "  Added 2 rows for 'Knowledge-based App. w/ Interactive & Batch dbs;' (out of 2 available)\n",
      "  Added 2 rows for 'Strategic planning;' (out of 2 available)\n",
      "  Added 3 rows for 'Accounting;' (out of 4 available)\n",
      "  Added 1 rows for 'Datawarehouse/ Business Intelligence;' (out of 1 available)\n",
      "  Added 1 rows for 'Technical support for diagnostic and repair;' (out of 1 available)\n",
      "  Added 1 rows for 'Data Warehouse;' (out of 1 available)\n",
      "  Added 1 rows for 'Call Center Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Type 1 Function Point Counting Tool;' (out of 1 available)\n",
      "  Added 1 rows for 'Workflow support & management;Precedents System;' (out of 1 available)\n",
      "  Added 1 rows for 'Tax Legislative;' (out of 1 available)\n",
      "  Added 2 rows for 'Business;Catalogue/register of things or events;' (out of 2 available)\n",
      "  Added 3 rows for 'Data or database management;' (out of 5 available)\n",
      "  Added 3 rows for 'Web-based application;' (out of 4 available)\n",
      "  Added 1 rows for 'Immobility & Facilities Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Interface;' (out of 1 available)\n",
      "  Added 3 rows for 'IT management;' (out of 3 available)\n",
      "  Added 3 rows for 'Production management system;' (out of 10 available)\n",
      "  Added 1 rows for 'Transaction/Production System;Office Automation System;Decision Support System;' (out of 1 available)\n",
      "  Added 1 rows for 'Student & Tests Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Salaries Reporting;' (out of 1 available)\n",
      "  Added 3 rows for 'Calculation, quotation, insurance policy issue;' (out of 7 available)\n",
      "  Added 2 rows for 'Printing Documentation Design;' (out of 2 available)\n",
      "  Added 1 rows for 'eCommerce;' (out of 1 available)\n",
      "  Added 2 rows for 'European Warranty Management;' (out of 2 available)\n",
      "  Added 2 rows for 'Commercial Web site;' (out of 2 available)\n",
      "  Added 1 rows for 'Robot;' (out of 1 available)\n",
      "  Added 2 rows for 'Parts catalogue management;' (out of 2 available)\n",
      "  Added 1 rows for 'Human Ressources;' (out of 1 available)\n",
      "  Added 2 rows for 'Quality Factory Reporting;' (out of 2 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;Financial transaction process/accounting;Online analysis and reporting;Trading;Workflow support & management;Complex process control;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 2 rows for 'Factory reporting;' (out of 2 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Customer billing/relationship management;' (out of 4 available)\n",
      "  Added 1 rows for 'VIrtual Synthesis for Acoustic;' (out of 1 available)\n",
      "  Added 2 rows for 'Production programming;' (out of 2 available)\n",
      "  Added 1 rows for 'Production process documentation;' (out of 1 available)\n",
      "  Added 3 rows for 'Utility;' (out of 8 available)\n",
      "  Added 2 rows for 'Management Information System;EDI;' (out of 2 available)\n",
      "  Added 1 rows for 'Analysis Management;' (out of 1 available)\n",
      "  Added 3 rows for 'Government;' (out of 11 available)\n",
      "  Added 2 rows for 'Workflow support & management;Complex process control;' (out of 2 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Document management;Financial transaction process/accounting;Job, case, incident, project management;Logistic or supply planning & control;Management or performance reporting;Online analysis and reporting;Stock contr' (out of 1 available)\n",
      "  Added 3 rows for 'Cars selling;' (out of 25 available)\n",
      "  Added 2 rows for 'After sales Follow up;' (out of 2 available)\n",
      "  Added 1 rows for 'Shrink-wrap;' (out of 1 available)\n",
      "  Added 3 rows for 'Parts documentation;' (out of 9 available)\n",
      "  Added 1 rows for 'Cost Computing;' (out of 1 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Job, case, incident, project management;Management or performance reporting;Online analysis and reporting;Workflow support & management;' (out of 1 available)\n",
      "  Added 1 rows for 'Clinical Archive;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Electronic Data Interchange;Online analysis and reporting;Legislation and consideration of building cases;' (out of 1 available)\n",
      "  Added 1 rows for 'Workflow support & management;Ordering tool enhancements for telecom components;' (out of 1 available)\n",
      "  Added 1 rows for 'Geographic or spatial information system;Complex process control;' (out of 1 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Customer billing;Customer relationship management;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Customer billing/relationship management;Document management;Administrative system for daycare;' (out of 1 available)\n",
      "  Added 1 rows for 'Geographic or spatial information system;Management or performance reporting;Telecom & network management;' (out of 1 available)\n",
      "  Added 1 rows for 'Project Risk management;' (out of 1 available)\n",
      "  Added 1 rows for 'Sales calculation (DRP);' (out of 1 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;Financial transaction process/accounting;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Geographic or spatial information system;Online analysis and reporting;Stock control & order processing;Workflow support & management;' (out of 1 available)\n",
      "  Added 1 rows for 'insurance quotation;' (out of 1 available)\n",
      "  Added 3 rows for 'Business;' (out of 3 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Operating system or software utility;' (out of 1 available)\n",
      "  Added 1 rows for 'Geographic Information System;' (out of 1 available)\n",
      "  Added 3 rows for 'Embedded system/real-time application;' (out of 91 available)\n",
      "  Added 2 rows for 'Inventory gathering and Managing;' (out of 2 available)\n",
      "  Added 1 rows for 'Internal Telecom Ordering Application;' (out of 1 available)\n",
      "  Added 3 rows for 'Service Order & Activation Management;' (out of 4 available)\n",
      "  Added 3 rows for 'Software development tool;' (out of 6 available)\n",
      "  Added 2 rows for 'GUI for Protocol;Protocol Enhancement;' (out of 2 available)\n",
      "  Added 3 rows for 'Document management;Financial transaction process/accounting;Image, video or sound processing;' (out of 26 available)\n",
      "  Added 1 rows for 'Interface database;' (out of 1 available)\n",
      "  Added 1 rows for 'Office Information System;Functional Specification System;' (out of 1 available)\n",
      "  Added 2 rows for 'Catalogue/register of things or events;Customer billing/relationship management;Document management;Geographic or spatial information system;Mathematical modelling (finance or eng.);Electronic Data Interchange;' (out of 2 available)\n",
      "  Added 3 rows for 'Operating system or software utility;(Re-usable component);' (out of 7 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;Billing management - Batch processing;' (out of 1 available)\n",
      "  Added 1 rows for 'Automated Data Acquisition;' (out of 1 available)\n",
      "  Added 1 rows for 'Sales and Logistics Standard Application;' (out of 1 available)\n",
      "  Added 1 rows for 'Card Administration  INCAS & Fault Assurance CAPRA;' (out of 1 available)\n",
      "  Added 1 rows for 'Defect Tracking System;' (out of 1 available)\n",
      "  Added 1 rows for 'Automate exchange between two IT Systems;' (out of 1 available)\n",
      "  Added 1 rows for 'Office Information System;Case Management System;' (out of 1 available)\n",
      "  Added 3 rows for 'Ordering & provisioning system;' (out of 6 available)\n",
      "  Added 3 rows for 'Internet Banking;' (out of 3 available)\n",
      "  Added 3 rows for 'Customisation (Add-ons) to a Product Data Management System;' (out of 14 available)\n",
      "  Added 2 rows for 'Electronic Banking;' (out of 2 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Logistic or supply planning & control;' (out of 1 available)\n",
      "  Added 2 rows for 'Project's management;' (out of 2 available)\n",
      "  Added 1 rows for 'Document management;Financial transaction process/accounting;' (out of 1 available)\n",
      "  Added 3 rows for 'Remote Banking;' (out of 3 available)\n",
      "  Added 1 rows for 'Decision Support System;Management Information System;Office Information System;' (out of 1 available)\n",
      "  Added 3 rows for 'Management Information System;Linguistic Software;' (out of 15 available)\n",
      "  Added 3 rows for 'Unknown;' (out of 272 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Online analysis and reporting;' (out of 1 available)\n",
      "  Added 2 rows for 'web EC site;' (out of 2 available)\n",
      "  Added 1 rows for 'Document management;Job, case, incident, project management;Management or performance reporting;Online analysis and reporting;Operating system or software utility;Workflow support & management;Telecom & network management;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Document management;Online analysis and reporting;Workflow support & management;' (out of 1 available)\n",
      "  Added 2 rows for 'CIS;' (out of 2 available)\n",
      "  Added 1 rows for 'Online Insurance product comparision tool;' (out of 1 available)\n",
      "  Added 1 rows for 'Extranet application;' (out of 1 available)\n",
      "  Added 1 rows for 'resources Management;' (out of 1 available)\n",
      "  Added 3 rows for 'Logistic or supply planning & control;Management or performance reporting;Personal productivity (e.g. spreadsheet);Workflow support & management;' (out of 3 available)\n",
      "  Added 3 rows for 'Complex process control;' (out of 30 available)\n",
      "  Added 1 rows for 'Identity Card Emission;Data or database management;' (out of 1 available)\n",
      "  Added 2 rows for 'Mathematical modelling (finance or eng.);Online analysis and reporting;' (out of 2 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Customer billing;' (out of 1 available)\n",
      "  Added 1 rows for 'Online analysis and reporting;Software development tool;' (out of 1 available)\n",
      "  Added 1 rows for 'Reconciliation;' (out of 1 available)\n",
      "  Added 1 rows for 'Trading;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'For credit collection;' (out of 1 available)\n",
      "  Added 1 rows for 'Management of registration number;' (out of 1 available)\n",
      "  Added 2 rows for 'Logistic or supply planning & control;Stock control & order processing;' (out of 2 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;Document management;Trading;' (out of 1 available)\n",
      "  Added 1 rows for 'Parts database for conception;' (out of 1 available)\n",
      "  Added 1 rows for 'Scientific;' (out of 1 available)\n",
      "  Added 1 rows for 'Business system;' (out of 1 available)\n",
      "  Added 1 rows for 'Security Controls;' (out of 1 available)\n",
      "  Added 1 rows for 'Other;' (out of 1 available)\n",
      "  Added 3 rows for 'Capacity management;' (out of 7 available)\n",
      "  Added 1 rows for 'Optimisation of the production;' (out of 1 available)\n",
      "  Added 3 rows for 'Design management;' (out of 5 available)\n",
      "  Added 3 rows for 'Cost analysis;' (out of 3 available)\n",
      "  Added 1 rows for 'Marketing Info System;' (out of 1 available)\n",
      "  Added 3 rows for 'Marketing management;' (out of 3 available)\n",
      "  Added 1 rows for 'Handling payment of social pensions in government;' (out of 1 available)\n",
      "  Added 3 rows for 'Car selling;' (out of 3 available)\n",
      "  Added 1 rows for 'Process management;' (out of 1 available)\n",
      "  Added 1 rows for 'Promotions;' (out of 1 available)\n",
      "  Added 1 rows for 'Packaged software;' (out of 1 available)\n",
      "  Added 1 rows for 'Reparation management;' (out of 1 available)\n",
      "  Added 3 rows for 'Content management system;Dynamic website;' (out of 6 available)\n",
      "  Added 1 rows for 'Process Control;Workflow support & management;The tool is Used By Employees of this Organization;' (out of 1 available)\n",
      "  Added 2 rows for 'Network Management;' (out of 2 available)\n",
      "  Added 2 rows for 'Healthcare;' (out of 2 available)\n",
      "  Added 1 rows for 'Providing management;' (out of 1 available)\n",
      "  Added 1 rows for 'Access Control;' (out of 1 available)\n",
      "  Added 1 rows for 'Central cmd./ctl of sensors;' (out of 1 available)\n",
      "  Added 1 rows for 'Support for parts documentation;' (out of 1 available)\n",
      "  Added 1 rows for 'Web based fullfilment tool for Advertising;' (out of 1 available)\n",
      "  Added 1 rows for 'Part management in factory;' (out of 1 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Workflow support & management;' (out of 5 available)\n",
      "  Added 2 rows for 'After Sales Management Contract service;' (out of 2 available)\n",
      "  Added 1 rows for 'Tax system;' (out of 1 available)\n",
      "  Added 3 rows for 'relatively complex application;' (out of 154 available)\n",
      "  Added 2 rows for 'diagnostic tools;' (out of 2 available)\n",
      "  Added 1 rows for 'Job, case, incident, project management;Management or performance reporting;' (out of 1 available)\n",
      "  Added 1 rows for 'Rules documentation management;' (out of 1 available)\n",
      "  Added 3 rows for 'Geometric design;' (out of 7 available)\n",
      "  Added 2 rows for 'Back-Office;' (out of 2 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Customer billing;Financial transaction process/accounting;Job, case, incident, project management;Management or performance reporting;Online analysis and reporting;Workflow support & management;Mathematical modelling' (out of 1 available)\n",
      "  Added 1 rows for 'IP Contact Centers;' (out of 1 available)\n",
      "  Added 1 rows for 'Optimisation for Industrial Scenarios;' (out of 1 available)\n",
      "  Added 1 rows for 'Factory Reporting;' (out of 1 available)\n",
      "  Added 2 rows for 'Provider management;' (out of 2 available)\n",
      "  Added 1 rows for 'Services Selling;' (out of 1 available)\n",
      "  Added 3 rows for 'Parts management;' (out of 7 available)\n",
      "  Added 3 rows for 'Document management;Financial transaction process/accounting;Online analysis and reporting;Stock control & order processing;Workflow support & management;Customer billing;Reservation system (eg. Airline, hotel);' (out of 3 available)\n",
      "  Added 1 rows for 'Gaming & Wagering;' (out of 1 available)\n",
      "  Added 1 rows for 'Sales;' (out of 1 available)\n",
      "  Added 1 rows for 'Management or performance reporting;Workflow support & management;' (out of 1 available)\n",
      "  Added 1 rows for 'Exchange system;' (out of 1 available)\n",
      "  Added 3 rows for 'Network Switch Provisioning;' (out of 7 available)\n",
      "  Added 1 rows for 'Accounting of stock;' (out of 1 available)\n",
      "  Added 1 rows for 'Job, case, incident, project management;Management or performance reporting;Operating system or software utility;Workflow support & management;Telecom & network management;' (out of 1 available)\n",
      "  Added 2 rows for 'Handling payment of social pensions within government;' (out of 2 available)\n",
      "  Added 1 rows for 'Equipment Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Document management;Job, case, incident, project management;Logistic or supply planning & control;Online analysis and reporting;Personal productivity (e.g. spreadsheet);Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 1 rows for 'Video Game;' (out of 1 available)\n",
      "  Added 1 rows for 'Translation;' (out of 1 available)\n",
      "  Added 1 rows for 'Security;' (out of 1 available)\n",
      "  Added 1 rows for 'Customer billing/relationship management;Trading;' (out of 1 available)\n",
      "  Added 3 rows for 'Human Resources;' (out of 5 available)\n",
      "  Added 3 rows for 'Job, case, incident, project management;Workflow support & management;' (out of 3 available)\n",
      "  Added 1 rows for 'Training;' (out of 1 available)\n",
      "  Added 3 rows for 'Knowledge Based;' (out of 11 available)\n",
      "  Added 1 rows for 'Monitoring of the factoring process;' (out of 1 available)\n",
      "  Added 1 rows for 'Case management;' (out of 1 available)\n",
      "  Added 2 rows for 'Quality of purchasing;' (out of 2 available)\n",
      "  Added 1 rows for 'Device or interface driver;Financial transaction process/accounting;Complex process control;' (out of 1 available)\n",
      "  Added 1 rows for 'Knowledge Based Multimedia;' (out of 1 available)\n",
      "  Added 1 rows for 'Network Management;Telecom and Networking;' (out of 1 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Workflow support & management;Electronic Data Interchange;' (out of 4 available)\n",
      "  Added 1 rows for 'Sensor Ctl. + presentation;' (out of 1 available)\n",
      "  Added 2 rows for 'Order Processing System;' (out of 2 available)\n",
      "  Added 1 rows for 'Document management;Image, video or sound processing;' (out of 1 available)\n",
      "  Added 1 rows for 'Project management;' (out of 1 available)\n",
      "  Added 1 rows for 'Customer Management;' (out of 1 available)\n",
      "  Added 1 rows for 'DSP;' (out of 1 available)\n",
      "  Added 1 rows for 'Management of car distribution;' (out of 1 available)\n",
      "  Added 1 rows for 'Technical Information System;' (out of 1 available)\n",
      "  Added 1 rows for 'Follow up of the production in  factories;' (out of 1 available)\n",
      "  Added 3 rows for 'Company hierarchy and staff directory;' (out of 3 available)\n",
      "  Added 1 rows for 'Class Management;' (out of 1 available)\n",
      "  Added 3 rows for 'Car Design;' (out of 9 available)\n",
      "  Added 2 rows for 'website;' (out of 2 available)\n",
      "  Added 3 rows for 'Catalogue/register of things or events;Document management;Online analysis and reporting;' (out of 4 available)\n",
      "  Added 1 rows for 'Airport Management;' (out of 1 available)\n",
      "  Added 3 rows for 'Business;Stock control & order processing;' (out of 8 available)\n",
      "  Added 1 rows for 'Parts Database;' (out of 1 available)\n",
      "  Added 2 rows for 'Airport Weather Observation Systems;Meteorological  events detection;' (out of 2 available)\n",
      "  Added 1 rows for 'Document Management & Catalogue;' (out of 1 available)\n",
      "  Added 3 rows for 'Enterprise Management;' (out of 7 available)\n",
      "  Added 1 rows for 'University Admission Application Portal;' (out of 1 available)\n",
      "  Added 3 rows for 'Course management system;Dynamic website;' (out of 5 available)\n",
      "  Added 3 rows for 'Cars documentation;' (out of 3 available)\n",
      "  Added 1 rows for 'Supplier Warranty Charge Back;' (out of 1 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Online analysis and reporting;Space management of schools;' (out of 1 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Logistic or supply planning & control;' (out of 1 available)\n",
      "  Added 1 rows for 'Management of parts buying;' (out of 1 available)\n",
      "  Added 1 rows for 'Inventory Control;' (out of 1 available)\n",
      "  Added 3 rows for 'Office Automation System;' (out of 4 available)\n",
      "  Added 1 rows for 'Logistic or supply planning & control;Stock control & order processing;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 3 rows for 'Broadband application;' (out of 3 available)\n",
      "  Added 1 rows for 'IT cost project management;' (out of 1 available)\n",
      "  Added 1 rows for 'Suppliers Follow up;' (out of 1 available)\n",
      "  Added 1 rows for 'Computing of the thermodynamic process;' (out of 1 available)\n",
      "  Added 2 rows for 'Car design;' (out of 2 available)\n",
      "  Added 1 rows for 'IT project Management;' (out of 1 available)\n",
      "  Added 1 rows for 'Contract management After Sales;' (out of 1 available)\n",
      "  Added 1 rows for 'Car renting;' (out of 1 available)\n",
      "  Added 1 rows for 'Dealer network management;' (out of 1 available)\n",
      "  Added 3 rows for 'not recorded;' (out of 477 available)\n",
      "  Added 3 rows for 'Team Management;' (out of 6 available)\n",
      "  Added 1 rows for 'Document management;Logistic or supply planning & control;' (out of 1 available)\n",
      "  Added 1 rows for 'Logistic or supply planning & control;Workflow support & management;' (out of 1 available)\n",
      "  Added 3 rows for 'Data Warehouse system;' (out of 41 available)\n",
      "  Added 1 rows for 'Marketing systems;' (out of 1 available)\n",
      "  Added 3 rows for 'Online analysis and reporting;Workflow support & management;' (out of 3 available)\n",
      "  Added 1 rows for 'CAD;' (out of 1 available)\n",
      "  Added 1 rows for 'Telecom Data Circuits and Revenue;' (out of 1 available)\n",
      "  Added 1 rows for 'Printing Document Design;' (out of 1 available)\n",
      "  Added 3 rows for 'Production management;' (out of 12 available)\n",
      "  Added 1 rows for 'Stock factory management;' (out of 1 available)\n",
      "  Added 3 rows for 'Quality of factory;' (out of 3 available)\n",
      "  Added 3 rows for 'Logistic indicators;' (out of 3 available)\n",
      "  Added 1 rows for 'Catalogue/register of things or events;Customer billing/relationship management;Electronic Data Interchange;' (out of 1 available)\n",
      "  Added 3 rows for 'Voice Provisioning;' (out of 17 available)\n",
      "  Added 1 rows for 'Online analysis and reporting;Embedded software - simple device control;Telecom & network management;' (out of 1 available)\n",
      "  Added 1 rows for 'Financial transaction process/accounting;Management or performance reporting;Customer billing;' (out of 1 available)\n",
      "  Added 1 rows for 'Management of manufacturing needs additional;' (out of 1 available)\n",
      "\n",
      "Sampling for column 'project_prf_development type'...\n",
      "  Added 1 rows for 'Porting' (out of 1 available)\n",
      "  Added 3 rows for 'Other' (out of 4 available)\n",
      "\n",
      "Sampling for column 'tech_tf_development platform'...\n",
      "  Added 1 rows for 'Hand Held' (out of 1 available)\n",
      "\n",
      "Sampling for column 'tech_tf_language type'...\n",
      "  Added 1 rows for 'APG' (out of 1 available)\n",
      "\n",
      "Sampling for column 'tech_tf_primary programming language'...\n",
      "  Added 1 rows for 'gcc' (out of 1 available)\n",
      "  Added 3 rows for 'MATLAB' (out of 8 available)\n",
      "  Added 3 rows for 'PHP' (out of 36 available)\n",
      "  Added 1 rows for 'Azure' (out of 1 available)\n",
      "  Added 1 rows for 'Delphi' (out of 1 available)\n",
      "  Added 3 rows for 'PASCAL' (out of 8 available)\n",
      "  Added 1 rows for 'IEF' (out of 1 available)\n",
      "  Added 1 rows for 'ARBOR/BP' (out of 1 available)\n",
      "  Added 3 rows for 'BASIC' (out of 4 available)\n",
      "  Added 1 rows for 'Pega Workflows' (out of 1 available)\n",
      "  Added 1 rows for 'Express' (out of 1 available)\n",
      "  Added 1 rows for 'Caa' (out of 1 available)\n",
      "  Added 1 rows for 'Doc1 Designer (Entorno visual)' (out of 1 available)\n",
      "  Added 2 rows for 'PYTHON' (out of 2 available)\n",
      "  Added 1 rows for 'NCR teradata scripting' (out of 1 available)\n",
      "  Added 3 rows for 'Upfront' (out of 5 available)\n",
      "  Added 3 rows for 'SAS' (out of 6 available)\n",
      "  Added 1 rows for 'SLEL' (out of 1 available)\n",
      "  Added 1 rows for 'LEX' (out of 1 available)\n",
      "  Added 3 rows for 'RPL' (out of 5 available)\n",
      "  Added 1 rows for 'PowerPlay' (out of 1 available)\n",
      "  Added 3 rows for 'Formspath' (out of 3 available)\n",
      "  Added 1 rows for 'Magic' (out of 1 available)\n",
      "  Added 1 rows for 'REXX' (out of 1 available)\n",
      "  Added 3 rows for 'Object oriented language' (out of 3 available)\n",
      "  Added 3 rows for 'Adobe Flex' (out of 8 available)\n",
      "  Added 3 rows for 'CICS' (out of 4 available)\n",
      "  Added 3 rows for 'Visual Studio .Net' (out of 3 available)\n",
      "  Added 1 rows for 'EJB' (out of 1 available)\n",
      "  Added 3 rows for 'FORTRAN' (out of 6 available)\n",
      "  Added 3 rows for 'Centura' (out of 3 available)\n",
      "  Added 1 rows for 'BRE' (out of 1 available)\n",
      "  Added 3 rows for 'PERIPHONICS' (out of 6 available)\n",
      "  Added 1 rows for 'A:G' (out of 1 available)\n",
      "  Added 1 rows for 'LISP' (out of 1 available)\n",
      "  Added 2 rows for 'DRIFT' (out of 2 available)\n",
      "  Added 1 rows for 'Jdeveloper' (out of 1 available)\n",
      "  Added 1 rows for 'Brightware proprietary' (out of 1 available)\n",
      "  Added 2 rows for 'iPlanet Netscape Application Server' (out of 2 available)\n",
      "  Added 3 rows for 'Ada' (out of 3 available)\n",
      "  Added 1 rows for 'MANTIS' (out of 1 available)\n",
      "  Added 3 rows for 'ColdFusion' (out of 8 available)\n",
      "  Added 3 rows for 'Datastage' (out of 9 available)\n",
      "  Added 1 rows for 'Huron/Object Star' (out of 1 available)\n",
      "  Added 1 rows for 'ADO.Net' (out of 1 available)\n",
      "  Added 1 rows for 'AB INITIO' (out of 1 available)\n",
      "  Added 3 rows for 'COOL:Gen' (out of 109 available)\n",
      "  Added 3 rows for 'IIS' (out of 6 available)\n",
      "  Added 1 rows for 'Must Modeller' (out of 1 available)\n",
      "  Added 2 rows for 'Data base language' (out of 2 available)\n",
      "  Added 1 rows for 'COGNOS' (out of 1 available)\n",
      "  Added 3 rows for 'UNIFACE' (out of 5 available)\n",
      "  Added 3 rows for 'SLOGAN' (out of 7 available)\n",
      "  Added 3 rows for 'OutlookVBA' (out of 4 available)\n",
      "  Added 1 rows for 'MS-Navision Properitory Language' (out of 1 available)\n",
      "  Added 3 rows for 'INGRES' (out of 6 available)\n",
      "  Added 1 rows for 'BEA Weblogic' (out of 1 available)\n",
      "  Added 3 rows for 'Siebel' (out of 37 available)\n",
      "  Added 1 rows for 'IBM WTX' (out of 1 available)\n",
      "  Added 1 rows for 'ACCEL' (out of 1 available)\n",
      "  Added 3 rows for 'ADS/Online' (out of 7 available)\n",
      "  Added 3 rows for 'HPS' (out of 14 available)\n",
      "  Added 2 rows for 'STAFFWARE' (out of 2 available)\n",
      "  Added 3 rows for 'BPM' (out of 7 available)\n",
      "  Added 3 rows for 'Perl' (out of 3 available)\n",
      "  Added 1 rows for 'Informatica PowerCenter' (out of 1 available)\n",
      "  Added 1 rows for 'J2EE' (out of 1 available)\n",
      "  Added 2 rows for 'ABF' (out of 2 available)\n",
      "  Added 3 rows for 'IDEAL' (out of 6 available)\n",
      "  Added 1 rows for 'TNSDL' (out of 1 available)\n",
      "  Added 3 rows for 'APPS' (out of 4 available)\n",
      "  Added 1 rows for 'BO' (out of 1 available)\n",
      "  Added 1 rows for 'Spreadsheet' (out of 1 available)\n",
      "  Added 1 rows for 'XGML' (out of 1 available)\n",
      "  Added 2 rows for 'Periproducer' (out of 2 available)\n",
      "  Added 1 rows for 'Enablon' (out of 1 available)\n",
      "  Added 3 rows for 'C/AL' (out of 3 available)\n",
      "  Added 3 rows for 'VisualFoxPro' (out of 3 available)\n",
      "  Added 3 rows for 'ASAP' (out of 4 available)\n",
      "  Added 1 rows for 'Mendix' (out of 1 available)\n",
      "\n",
      "Sampling for column 'project_prf_relative size'...\n",
      "  Added 2 rows for 'XXXL' (out of 2 available)\n",
      "\n",
      "Sampling for column 'project_prf_team size group'...\n",
      "  Added 3 rows for '101+' (out of 54 available)\n",
      "  Added 3 rows for '71-80' (out of 24 available)\n",
      "  Added 3 rows for '51-60' (out of 39 available)\n",
      "  Added 3 rows for '91-100' (out of 14 available)\n",
      "\n",
      "Sampling for column 'tech_tf_architecture'...\n",
      "  Added 3 rows for 'Multi-tier with web interface' (out of 25 available)\n",
      "  Added 3 rows for 'Stand-alone' (out of 14 available)\n",
      "\n",
      "Sampling for column 'tech_tf_client_roles'...\n",
      "  Added 3 rows for 'Data entry & validation;Device/equipment interface;Web/HTML browser;' (out of 12 available)\n",
      "  Added 3 rows for 'Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;' (out of 6 available)\n",
      "  Added 3 rows for 'Web/HTML browser;Web public interface;' (out of 9 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Data retrieval & presentation;Web/HTML browser;Security;' (out of 3 available)\n",
      "  Added 2 rows for 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Device/equipment interface;Web/HTML browser;' (out of 2 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Device/equipment interface;Web/HTML browser;' (out of 1 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Data entry & validation;' (out of 7 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Device/equipment interface;' (out of 1 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Device/equipment interface;Terminal emulation;Provide some calculations;' (out of 1 available)\n",
      "  Added 1 rows for 'Business logic or rule processing;Data retrieval & presentation;Web public interface;' (out of 1 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Business logic or rule processing;Web/HTML browser;' (out of 3 available)\n",
      "  Added 1 rows for 'Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Data extraction, transformation and loading;' (out of 1 available)\n",
      "  Added 1 rows for 'Business logic or rule processing;Data entry & validation;Device/equipment interface;Terminal emulation;' (out of 1 available)\n",
      "  Added 1 rows for 'Data entry & validation;Data retrieval & presentation;Web/HTML browser;Web public interface;' (out of 1 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Data retrieval & presentation;Web/HTML browser;Web public interface;' (out of 1 available)\n",
      "  Added 3 rows for 'Business logic or rule processing;Data entry & validation;' (out of 3 available)\n",
      "  Added 3 rows for 'Data retrieval & presentation;Web/HTML browser;' (out of 6 available)\n",
      "  Added 3 rows for 'Data entry & validation;Data retrieval & presentation;' (out of 11 available)\n",
      "  Added 1 rows for 'HandHeld Device;' (out of 1 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Web/HTML browser;' (out of 6 available)\n",
      "  Added 1 rows for 'Data entry & validation;Data retrieval & presentation;Device/equipment interface;' (out of 1 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;Web public interface;' (out of 1 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;' (out of 3 available)\n",
      "  Added 3 rows for 'front-end;' (out of 3 available)\n",
      "  Added 1 rows for 'Data entry & validation;' (out of 1 available)\n",
      "  Added 3 rows for 'Web public interface;' (out of 3 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Data entry & validation;Web public interface;' (out of 1 available)\n",
      "  Added 1 rows for 'Business logic or rule processing;Data entry & validation;Device/equipment interface;Web/HTML browser;' (out of 1 available)\n",
      "  Added 1 rows for 'Query and update data;' (out of 1 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Business logic or rule processing;Data retrieval & presentation;' (out of 1 available)\n",
      "  Added 3 rows for 'Data entry & validation;Web/HTML browser;' (out of 3 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Data entry & validation;Web/HTML browser;' (out of 3 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;Security;' (out of 1 available)\n",
      "  Added 1 rows for 'Business logic or rule processing;Data retrieval & presentation;Web/HTML browser;Web public interface;' (out of 1 available)\n",
      "  Added 1 rows for 'Device/equipment interface;' (out of 1 available)\n",
      "  Added 3 rows for 'Data entry & validation;Data retrieval & presentation;Web/HTML browser;' (out of 8 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Business logic or rule processing;' (out of 1 available)\n",
      "  Added 1 rows for 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;Web public interface;Security;' (out of 1 available)\n",
      "  Added 1 rows for 'Business logic or rule processing;Data retrieval & presentation;Device/equipment interface;Security;' (out of 1 available)\n",
      "  Added 1 rows for 'Business logic or rule processing;Data retrieval & presentation;Web/HTML browser;' (out of 1 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Web/HTML browser;Security;' (out of 5 available)\n",
      "  Added 3 rows for 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;' (out of 6 available)\n",
      "  Added 3 rows for 'Data retrieval & presentation;Web/HTML browser;Security;' (out of 3 available)\n",
      "\n",
      "Sampling for column 'tech_tf_server_roles'...\n",
      "  Added 2 rows for 'Database server;FTP server;Messaging server;' (out of 2 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;HTML/web server;Mail server;Messaging server;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;HTML/web server;Mail server;Messaging server;Object/component server;Security/authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;FTP server;Multi-user legacy application;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;Multi-user legacy application;Object/component server;' (out of 3 available)\n",
      "  Added 1 rows for 'Database server;Security/authentication;Delivery server for end products, f.e.Cognos Cubes;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Multi-user legacy application;Object/component server;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;Security/authentication;Law-based business logic;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;File &/or print server;Security/authentication;' (out of 6 available)\n",
      "  Added 2 rows for 'Object/component server;' (out of 2 available)\n",
      "  Added 3 rows for 'Messaging server;' (out of 3 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Messaging server;Object/component server;Security/authentication;DR;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Multi-user legacy application;Security/authentication;' (out of 1 available)\n",
      "  Added 2 rows for 'Database server;HTML/web server;Mail server;Object/component server;Security/authentication;' (out of 2 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Object/component server;Security/authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'HTML/web server;virtualisation server API;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Security/authentication;Exchange Server;' (out of 1 available)\n",
      "  Added 2 rows for 'Mail server;Messaging server;' (out of 2 available)\n",
      "  Added 3 rows for 'Database server;HTML/web server;Mail server;Security/authentication;' (out of 6 available)\n",
      "  Added 2 rows for 'Database server;File &/or print server;HTML/web server;Security/authentication;' (out of 2 available)\n",
      "  Added 1 rows for 'FTP server;Messaging server;Object/component server;' (out of 1 available)\n",
      "  Added 3 rows for 'Multi-user legacy application;' (out of 10 available)\n",
      "  Added 3 rows for 'Database server;HTML/web server;Security/authentication;ETL Server;' (out of 3 available)\n",
      "  Added 2 rows for 'Database server;FTP server;HTML/web server;Object/component server;' (out of 2 available)\n",
      "  Added 1 rows for 'data acquisation;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;File &/or print server;HTML/web server;Messaging server;Multi-user legacy application;' (out of 7 available)\n",
      "  Added 1 rows for 'Database server;FTP server;Messaging server;Security/authentication;' (out of 1 available)\n",
      "  Added 2 rows for 'Database server;FTP server;HTML/web server;Mail server;' (out of 2 available)\n",
      "  Added 3 rows for 'webserver;' (out of 3 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;Mail server;Messaging server;Security/authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;Mail server;Security/authentication;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;File &/or print server;' (out of 4 available)\n",
      "  Added 2 rows for 'Database server;File &/or print server;HTML/web server;Object/component server;Security/authentication;' (out of 2 available)\n",
      "  Added 3 rows for 'Database server;FTP server;Messaging server;Object/component server;' (out of 5 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Mail server;WAS Server;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Object/component server;Business logic;' (out of 1 available)\n",
      "  Added 2 rows for 'HTML/web server;Multi-user legacy application;' (out of 2 available)\n",
      "  Added 1 rows for 'Database server;FTP server;HTML/web server;Object/component server;Security/authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;HTML/web server;' (out of 1 available)\n",
      "  Added 2 rows for 'Database server;HTML/web server;Mail server;' (out of 2 available)\n",
      "  Added 1 rows for 'HTML/web server;Mail server;Security/authentication;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;File &/or print server;HTML/web server;Multi-user legacy application;' (out of 5 available)\n",
      "  Added 3 rows for 'HTML/web server;' (out of 3 available)\n",
      "  Added 3 rows for 'Database server;FTP server;HTML/web server;Mail server;Messaging server;Object/component server;Security/authentication;' (out of 3 available)\n",
      "  Added 3 rows for 'Database server;Object/component server;Security/authentication;' (out of 4 available)\n",
      "  Added 1 rows for 'Database server;FTP server;HTML/web server;Messaging server;Object/component server;Security/authentication;Business logic + Integration to 30 other systems;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;FTP server;HTML/web server;Mail server;Security/authentication;' (out of 14 available)\n",
      "  Added 3 rows for 'Database server;File &/or print server;Object/component server;Security/authentication;' (out of 8 available)\n",
      "  Added 1 rows for 'Database server;FTP server;Security/authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'Multi-user legacy application;Security/authentication;' (out of 1 available)\n",
      "  Added 3 rows for 'Security/authentication;' (out of 6 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;Security/authentication;Data entry & validation, business logic;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;Object/component server;Security/authentication;Business logic;' (out of 1 available)\n",
      "  Added 3 rows for 'HTML/web server;Security/authentication;' (out of 3 available)\n",
      "  Added 1 rows for 'Database server;Security/authentication;Business logic;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;FTP server;HTML/web server;' (out of 1 available)\n",
      "  Added 2 rows for 'Database server;HTML/web server;Multi-user legacy application;Object/component server;Security/authentication;' (out of 2 available)\n",
      "  Added 3 rows for 'Database server;FTP server;HTML/web server;Security/authentication;' (out of 3 available)\n",
      "  Added 1 rows for 'HTML/web server;Object/component server;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;Mail server;' (out of 1 available)\n",
      "  Added 1 rows for 'HTML/web server;Messaging server;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;HTML/web server;Mail server;' (out of 1 available)\n",
      "  Added 1 rows for 'FTP server;HTML/web server;Multi-user legacy application;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Messaging server;Object/component server;Security/authentication;Application Server;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;Object/component server;' (out of 7 available)\n",
      "  Added 1 rows for 'Mail server;Multi-user legacy application;' (out of 1 available)\n",
      "  Added 1 rows for 'FTP server;HTML/web server;Multi-user legacy application;Security/authentication;' (out of 1 available)\n",
      "  Added 1 rows for 'Database server;File &/or print server;FTP server;Mail server;Security/authentication;' (out of 1 available)\n",
      "  Added 3 rows for 'Database server;HTML/web server;Messaging server;Security/authentication;' (out of 3 available)\n",
      "  Added 1 rows for 'Database server;HTML/web server;Mail server;Object/component server;' (out of 1 available)\n",
      "\n",
      "Sampling for column 'tech_tf_type_of_server'...\n",
      "  Added 3 rows for 'Stand alone;' (out of 21 available)\n",
      "  Added 3 rows for 'Client server;' (out of 294 available)\n",
      "  Added 3 rows for 'Multi-tier with web public interface;' (out of 24 available)\n",
      "  Added 3 rows for 'webserver;' (out of 3 available)\n",
      "\n",
      "Sampling for column 'tech_tf_client/server_description'...\n",
      "  Added 1 rows for 'not assessed;' (out of 1 available)\n",
      "  Added 3 rows for 'Stand-alone;' (out of 9 available)\n",
      "  Added 2 rows for '25%;' (out of 2 available)\n",
      "  Added 3 rows for 'Presentation & Logic on server;' (out of 6 available)\n",
      "  Added 1 rows for 'Client-server Architecture/P2P;' (out of 1 available)\n",
      "  Added 3 rows for 'Unknown;' (out of 3 available)\n",
      "  Added 2 rows for '30%;' (out of 2 available)\n",
      "  Added 1 rows for '50%;' (out of 1 available)\n",
      "  Added 1 rows for 'Dynamic Link Library;' (out of 1 available)\n",
      "  Added 1 rows for 'Presentation and logic on client;' (out of 1 available)\n",
      "  Added 2 rows for '20%;' (out of 2 available)\n",
      "  Added 1 rows for '90%;' (out of 1 available)\n",
      "  Added 3 rows for '100%;' (out of 3 available)\n",
      "  Added 2 rows for '10%;' (out of 2 available)\n",
      "  Added 1 rows for 'Client-server Architecture;Browser-server Architecture;' (out of 1 available)\n",
      "  Added 3 rows for 'Embedded;' (out of 3 available)\n",
      "\n",
      "Sampling for column 'people_prf_project_user_involvement'...\n",
      "  Added 2 rows for 'Best' (out of 2 available)\n",
      "  Added 1 rows for 'Low' (out of 1 available)\n",
      "\n",
      "Sampling for column 'people_prf_ba_team_experience_less_than_1_yr'...\n",
      "  Added 3 rows for '5.0' (out of 14 available)\n",
      "  Added 3 rows for '7.0' (out of 8 available)\n",
      "  Added 3 rows for '8.0' (out of 4 available)\n",
      "  Added 3 rows for '9.0' (out of 5 available)\n",
      "  Added 1 rows for '10.0' (out of 1 available)\n",
      "  Added 3 rows for '11.0' (out of 3 available)\n",
      "  Added 2 rows for '13.0' (out of 2 available)\n",
      "  Added 3 rows for '15.0' (out of 3 available)\n",
      "  Added 1 rows for '16.0' (out of 1 available)\n",
      "  Added 2 rows for '19.0' (out of 2 available)\n",
      "  Added 1 rows for '23.0' (out of 1 available)\n",
      "  Added 1 rows for '27.0' (out of 1 available)\n",
      "  Added 1 rows for '30.0' (out of 1 available)\n",
      "  Added 1 rows for '31.0' (out of 1 available)\n",
      "\n",
      "Sampling for column 'people_prf_it_experience_less_than_1_yr'...\n",
      "  Added 1 rows for '16.0' (out of 1 available)\n",
      "  Added 1 rows for '9.0' (out of 1 available)\n",
      "  Added 1 rows for '10.0' (out of 1 available)\n",
      "  Added 1 rows for '24.0' (out of 1 available)\n",
      "\n",
      "Sampling for column 'people_prf_it_experience_less_than_3_yr'...\n",
      "  Added 1 rows for '33.0' (out of 1 available)\n",
      "  Added 1 rows for '36.0' (out of 1 available)\n",
      "  Added 3 rows for '7.0' (out of 6 available)\n",
      "  Added 1 rows for '8.0' (out of 1 available)\n",
      "  Added 3 rows for '9.0' (out of 5 available)\n",
      "  Added 1 rows for '42.0' (out of 1 available)\n",
      "  Added 3 rows for '15.0' (out of 3 available)\n",
      "  Added 1 rows for '17.0' (out of 1 available)\n",
      "  Added 1 rows for '20.0' (out of 1 available)\n",
      "  Added 1 rows for '22.0' (out of 1 available)\n",
      "  Added 3 rows for '24.0' (out of 3 available)\n",
      "\n",
      "Sampling for column 'people_prf_it_experience_great_than_9_yr'...\n",
      "  Added 3 rows for '5.0' (out of 24 available)\n",
      "  Added 3 rows for '6.0' (out of 18 available)\n",
      "  Added 3 rows for '9.0' (out of 12 available)\n",
      "  Added 3 rows for '10.0' (out of 11 available)\n",
      "  Added 2 rows for '11.0' (out of 2 available)\n",
      "  Added 3 rows for '12.0' (out of 3 available)\n",
      "  Added 3 rows for '13.0' (out of 4 available)\n",
      "  Added 3 rows for '14.0' (out of 4 available)\n",
      "  Added 3 rows for '15.0' (out of 8 available)\n",
      "  Added 1 rows for '17.0' (out of 1 available)\n",
      "  Added 3 rows for '18.0' (out of 3 available)\n",
      "  Added 3 rows for '20.0' (out of 3 available)\n",
      "  Added 1 rows for '21.0' (out of 1 available)\n",
      "  Added 1 rows for '24.0' (out of 1 available)\n",
      "  Added 1 rows for '25.0' (out of 1 available)\n",
      "\n",
      "Sampling for column 'people_prf_project_manage_changes'...\n",
      "  Added 3 rows for '4.0' (out of 5 available)\n",
      "\n",
      "Sampling for column 'people_prf_personnel_changes'...\n",
      "  Added 3 rows for '4.0' (out of 11 available)\n",
      "  Added 3 rows for '5.0' (out of 8 available)\n",
      "  Added 3 rows for '6.0' (out of 3 available)\n",
      "  Added 2 rows for '7.0' (out of 2 available)\n",
      "  Added 2 rows for '8.0' (out of 2 available)\n",
      "  Added 2 rows for '10.0' (out of 2 available)\n",
      "  Added 3 rows for '11.0' (out of 3 available)\n",
      "  Added 3 rows for '12.0' (out of 3 available)\n",
      "  Added 1 rows for '15.0' (out of 1 available)\n",
      "  Added 1 rows for '16.0' (out of 1 available)\n",
      "  Added 1 rows for '21.0' (out of 1 available)\n",
      "\n",
      "Sampling for column 'project_prf_cost_currency'...\n",
      "  Added 1 rows for 'South Africa, rand' (out of 1 available)\n",
      "  Added 1 rows for 'New Zealand, dollar' (out of 1 available)\n",
      "  Added 1 rows for 'India, Rupees' (out of 1 available)\n",
      "  Added 3 rows for 'Germany, Mark' (out of 3 available)\n",
      "  Added 3 rows for 'India, rupee' (out of 3 available)\n",
      "  Added 1 rows for 'Malaysia, Renggette' (out of 1 available)\n",
      "  Added 1 rows for 'Ecuador' (out of 1 available)\n",
      "  Added 1 rows for 'TRL' (out of 1 available)\n",
      "  Added 2 rows for 'Brazil, real' (out of 2 available)\n",
      "  Added 1 rows for 'Switzerland, franc' (out of 1 available)\n",
      "  Added 3 rows for 'United Kingdom, pound sterling' (out of 43 available)\n",
      "\n",
      "Sampling for column 'project_prf_currency_multiple'...\n",
      "  Added 3 rows for 'Yes 1,000' (out of 4 available)\n",
      "  Added 2 rows for 'Yes 10,000' (out of 2 available)\n",
      "\n",
      "Removed 451 duplicate rows\n",
      "\n",
      "=== SUMMARY ===\n",
      "Original sample size: 939\n",
      "Additional rows added: 1338\n",
      "Final dataset size: 2277\n",
      "Size increase: 142.5%\n",
      "Enhanced dataset shape: (2277, 52)\n",
      "\n",
      "7. Verifying categories coverage...\n",
      "\n",
      "=== CATEGORY COVERAGE VERIFICATION ===\n",
      "\n",
      "Column 'external_eef_data quality rating':\n",
      "  Before: 4 categories\n",
      "  After:  4 categories\n",
      "\n",
      "Column 'external_eef_industry sector':\n",
      "  Before: 2 categories\n",
      "  After:  17 categories\n",
      "  New categories added: ['Education', 'Wholesale & Retail', 'Communication', 'Logistics', 'Service Industry', 'Utilities', 'Electronics & Computers', 'Insurance', 'Manufacturing', 'Medical & Health Care', 'Professional Services', 'Government', 'Construction', 'Defence', 'Mining']\n",
      "\n",
      "Column 'external_eef_organisation type':\n",
      "  Before: 15 categories\n",
      "  After:  193 categories\n",
      "  New categories added: ['Medical and Health Care;Professional Services;', 'Computers & Software;Citizens of DK;', 'Content Management;', 'Wholesale & Retail Trade;Oil;', 'Wholesale & Retail Trade;Financial, Property & Business Services;', 'Electronics;', 'Engineering;', 'Manufacturing;Consumer Goods;', 'Ordering;', 'Manufacturing;Wholesale & Retail Trade;', 'Travel;', 'Community Services;', 'Service;Recreation, Personnel & Other Services;', 'Electricity, Gas, Water;', 'Art , Events , Ticketing;', 'Telecommunication;', 'E-Business;', 'High Tech;', 'Recreation & Personnel Services;Professional Services;Computers & Software;', 'Professional Services;Computers & Software;', 'Government;Municipal;', 'Wholesale & Retail Trade;Computers & Software;', 'Government;Professional Services;', 'Aerospace / Automotive;', 'Computer Systems Consultant;Public Administration;', 'Government;Electricity, Gas, Water;Communications;Community Services;Professional Services;Electronics;', 'general public (mobile phone end user);', 'Real Estate & Property;Community Services;', 'Telecommunications;', 'Public Administration;Aerospace / Automotive;Computers & Software;Insurance;', 'Chemicals;Community Services;Electricity, Gas, Water;Government;', 'Transport & Storage;Public Administration;', 'Local;', 'Citizens and the Municipalities;', 'Chemicals;Energy;', 'Surveillance & Security;', 'Manufacturing;Oil;', 'Manufacturing;Manufacture of steel products;', 'Computers & Software;Consumer Goods;Electronics;', 'Construction;Financial, Property & Business Services;Government;Real Estate & Property;Transport & Storage;Housing;', 'Oil;', 'Transport & Storage;Aerospace / Automotive;', 'Restaurant;', 'Food Processing;', 'Coronial Services;', 'Car Rental;', 'Government;Public Administration (Revenue);', 'Publishing;', 'Software products;', 'Sales;', 'Manufacturing;Professional Services;', 'Public Administration;Community Services;', 'Air Traffic Management;', 'Consumer Goods;', 'Agriculture, Forestry, Fishing, Hunting;Government;', 'Professional Services;Environmental Consulting;', 'Energy;', 'Information Technology;', 'Marketing;', 'Community Services;Institutions eg. Kindergartens;', 'Utilities;', 'Government, Public Administration (Revenue);', 'Mining;Manufacturing;Chemicals;', 'Retail;', 'Developing global software solutions;', 'Chemicals;', 'Transport & Storage;', 'Security;', 'Education;', 'Transport & Storage;Media;', 'Research & development;', 'Government;Danish citizens;', 'Any organization which counts function points;', 'Government;Defence;Aerospace / Automotive;', 'Public Administration;', 'Manufacturing;', 'Wholesale & Retail Trade;', 'Manufacturing;Computers;Diversified Corp;', 'Government;Real Estate & Property;Education Institution;Manufacturing;Construction;Wholesale & Retail Trade;Transport & Storage;Communications;Medical and Health Care;Community Services;Defence;Financial, Property & Business Services;Banking;Professional', 'Communications;', 'Defence;', 'Wholesale & Retail Trade;Transport & Storage;', 'Government;Local administration and counties;', 'Agriculture, Forestry, Fishing, Hunting;Manufacturing;', 'Telecom;', 'Professional Services;', 'Business Services;', 'Government;', 'All industry organization types;', 'Energy Sources (Oil & Petroleum/Electricity etc);', 'Education Institution;Research;', 'Medical and Health Care;Public Administration;Insurance;', 'Communications;Financial (Banking, Insurance, Stock);Government;Public Administration (Revenue);Manufacturing;Medical and Health Care;Post;Traffic (Aerospace/railway/Automotive);Transport;Logistic (Wholesale & Retail/Storage);Research & Development;Energy', 'Distribution;', 'Logistics;', 'Communications;Telecom;', 'Information Technology Services Provider;', 'Government;Community Services;', 'Post/mail services;', 'Occupational Health and Safety;', 'Agriculture, Forestry, Fishing, Hunting;', 'IT Services;', 'Biotech;', 'Community Services;Municipality;', 'UniversityEvent Management-involves external users;', 'Government;Defence;', 'Public Sector;', 'Engineering;Research & Development;Software Development;Client/Server architecture for Language Services;', 'Real Estate & Property;', 'Government;Public Administration;', 'Communications;Electronics;', 'General;', 'Information Technology;Human Resource (HR) Domain;', 'Computers and IT business;', 'Airport;', 'Internet;', 'Oil & Petroleum;', 'Logistic (Wholesale & Retail/Storage);', 'Warehouse Management;', 'Media;', 'Insurance;', 'Computer Consultants;', 'Education Institution;', 'Medical and Health Care;', 'Manufacturing;Transport & Storage;', 'Transit Corporation;', 'Computers & Software;Human Ressources;', 'Community Services;Invoice-handling;', 'IS-Metrics collection system;', 'Government;Municipality;', 'Manufacturing;Wholesale & Retail Trade;Transport & Storage;', 'Billing;', 'Construction;', 'Agriculture, Forestry, Fishing, Hunting;Transport & Storage;', 'Communications;Telecom & Networking;', 'Aerospace / Automotive;Chemicals;Defence;Electronics;Food Processing;Government;Manufacturing;Medical and Health Care;Mining;Oil & Petroleum;Transport & Storage;Generic application;', 'All-purpose;', 'Mining;', 'Building Automation;', 'Government;Real Estate & Property;', 'Tax administration;', 'Government;Medical and Health Care;', 'Sales & Marketing;', 'Exhibition Management;', 'Consultancy;', 'Virtual Assistants (Lingubots);', 'Imaging;', 'Government;Public administration;', 'Human Resource (HR) Domain;', 'Communications;Computers & Software;', 'Service;', 'Manufacturing;Computers;Diversified corporation;', 'Services;', 'Recreation & Personnel Services;', 'Transport & Storage;Professional Services;', 'Public Administration;Insurance;', 'Aerospace / Automotive;Computers & Software;', 'Universal;', 'Education Institution;Electricity, Gas, Water;University;', 'Government;Electricity, Gas, Water;', 'Government;Health Sciences;', 'Education Institution;Electricity, Gas, Water;IEEE;', 'Computers & Software;', 'Public Administration;Community Services;Insurance;', 'Community Services;Government;Public administration;', 'Post;', 'Traffic (Aerospace/Railway/Automotive);Transport;', 'Wholesale & Retail Trade;Consumer Goods;', 'Environmental Monitoring;Public Administration;', 'Defence;Aerospace / Automotive;', 'Maintenance;', 'Commercial services;', 'Data Provisioning;', 'Government;Municipal Services;', 'Advertising;', 'Agriculture, Forestry, Fishing, Hunting;Chemicals;Computers & Software;Construction;Defence;Electricity, Gas, Water;Electronics;Food Processing;Government;generic application;', 'Voice Provisioning;', 'Manufacturing;Computers & Software;']\n",
      "\n",
      "Column 'project_prf_application group':\n",
      "  Before: 4 categories\n",
      "  After:  6 categories\n",
      "  New categories added: ['Mathematically intensive application', 'Business Application; Infrastructure Software;']\n",
      "\n",
      "Column 'project_prf_application type':\n",
      "  Before: 50 categories\n",
      "  After:  568 categories\n",
      "  New categories added: ['Stock control & order processing;Workflow support & management;Electronic Data Interchange;', 'MiddleWare Telecom Switching;', 'Car test management;', 'Management or performance reporting;Electronic Data Interchange;', 'Device or interface driver;', 'Micro Marketing;', 'Web-based App. J2EE;', 'After sales Documentation;', 'Fault Tolerance;Management Information System;Fault Management;', 'Personal productivity (e.g. spreadsheet);', 'Car Sales;', 'Document management;Workflow support & management;', 'Data protection;', 'Computer Integrated Manufactuaring system;', 'Car embedded Computer Management;', 'Manufacturing process management;', 'Fault Tolerance;Process Control;Call Centre;', 'Telecom Data Circuits;', 'Financial transaction process/accounting;Job, case, incident, project management;Personal productivity (e.g. spreadsheet);Workflow support & management;', 'Management and follow up of the parts;', 'Network management;', 'Diagnostic distribution  management;', 'MS Business Platform;', 'Vehicle Systems Software;', 'Tools or system;', 'Financial transaction process/accounting;Management or performance reporting;Data Warehouse system;', 'Financial application area;', 'Operating system or software utility;Electronic Data Interchange;', 'Client-Server Application;', 'e-commerce;', 'Local;', 'Financial transaction processing & Accounting;', 'Operating system or software utility;Workflow support & management;', 'Car pricing;', 'Taxation;', 'Qualty Factory Reporting;', 'Web;', 'Customer billing/relationship management;CRM;', 'Pollution statistics;', 'Catalogue/register of things or events;Document management;Electronic Data Interchange;', 'Post exchange;', 'Air Traffic Management;', 'Network Management;Telecom & Networking;', 'Insurance annities;Online user interface;', 'Workflow support & management;Management Information System;', 'Military;', 'Document management;Logistic or supply planning & control;Online analysis and reporting;Personal productivity (e.g. spreadsheet);Electronic Data Interchange;', 'Scientific/Math;', 'Test Equipment;', 'Technical administrative system;', 'Pay;', 'HR;', 'Business;Workflow support & management;', 'Premium Paid Certificate;', 'Customer management;', 'Image, video or sound processing;', 'Communication systrem;', 'Template for data-exchange;', 'Software for machine control;Complex process control;', 'Idea/Patent Information System;', 'Document management;Operating system or software utility;', 'Parts selling;', 'Selling application;', 'Logistic tracking;', 'Insurance quotation;', 'Test vehicles Reporting;', 'Number of Hosting Solution;', 'Financial transaction process/accounting;Management or performance reporting;', 'Catalogue/register of things or events;Document management;', 'Website;', 'MultiMedia;', 'Sales promotion tool;', 'Integration;', 'Mathematical modelling (finance or eng.);Software development tool;', 'Information systems;', 'Online. eSales;', 'Mixed;', 'Central database;', 'Graphical Modeling;', 'Tools management;', 'Corporate Taxation;', 'Embedded Systems;', 'Administrative Support System;', 'suppliers management;', 'Technical Support  Information System;', 'Document management;Management or performance reporting;', 'After sales parts contract management;', 'IdM;', 'Supply Management;', 'IT projet Management;', 'Artifical Intelligence based engine;', 'Directory Assistance;', 'Database customers for Parts;', 'GUI Interface Application;', 'Customer Resource Management;', 'Car Documentation management;', 'Catalogue/register of things or events;Online analysis and reporting;', 'human resources organisation in the factories;', 'Billing;', 'Customs Informations management;', 'Management of customs activities;', 'Supporting of the commercial network;', 'Simulator;', 'Graphics & publishing tools or system;', 'Retailler sells follow up;', 'Customer billing/relationship management;Logistic or supply planning & control;', 'Geographic or spatial information system;Image, video or sound processing;Job, case, incident, project management;Online analysis and reporting;Electronic Data Interchange;', 'Management Information System;Office Information System;Transaction/Production System;', 'Change Management Tool;', 'Energy Reporting;', 'Infrastructure;', 'Car design tool;', 'Financial transaction process/accounting;Graphics & publishing tools or system;Management or performance reporting;Online analysis and reporting;Personal productivity (e.g. spreadsheet);', 'Motor simulator;', 'Logistic or supply planning & control;Stock control & order processing;Complex process control;', 'Parts reporting IS;', 'After sales Parts documentation;', 'New Screen Design;', 'Customer billing;', 'Building Automation;Embedded software - simple device control;Protocol Linux ARM9;Device or interface driver;', 'Job, case, incident, project management;Online analysis and reporting;Personal productivity (e.g. spreadsheet);', 'Maintenance;', 'Workplace Savings;', 'Catalogue/register of things or events;Data or database management;', 'To determine which IVR credit card refresh used;', 'Stock factory manegement;', 'Fixed asset;', 'Process documentation;', 'Purchaser performance management;', 'Cost logistic Computing;', 'Packaging Visibility System;', 'Customer Billing;', 'DB Serch system;', 'Executive Information System;Management Information System;', 'GPS Portal;', 'Trading? (procurement management);', 'Database  Parts;', 'Software for machine control;Mathematical modelling (finance or eng.);', 'Transaction/Production System;Artificial Intelligence;', 'Forecastselling;', 'Ordering;', 'Customer billing/relationship management;Stock control & order processing;', 'Inventory Management;', 'Operating system or software utility;Synchronization of Outlook and Application;', 'Geographic or spatial information system;', 'Products management;', 'Spec/Document Management;', 'Online System for University fraternities;', 'Analysis and Environmental Risk Assessment;', 'Reporting on factoring process;', 'Geographic or spatial information system;Online analysis and reporting;', 'Retailer sales reporting;', 'E-Business;', 'International;', 'Msg.Switch/cel phone;', 'MS Billing;', 'Customer billing/relationship management;Contact Management;', 'Condemnation proceedings;', 'Factory parts follow up;', 'Customer Data repository with applicatin interface;', 'Management of Licences and Permits;', 'Parts logistic management;', 'Car Database;', 'Suppliers Management;', 'After selling reporting;', 'Business;Customer billing/relationship management;', 'Billing and ERP;', 'Telecommunications;', 'Business enabling service;', 'Process of factory management;', 'Follow up of car failure;', 'Customer relationship management;', 'Human ressources management;', 'website for Parts selling;', 'Performance monitoring;', 'Track test management;', 'Project Management;', 'Workflow support & management;Proposal creation and submission;', 'Sales statistics;', 'Cost Tools Computing;', 'Catalogue for IT products and IT services;', 'Health Management;', 'Employee self-service system;', 'Management or performance reporting;Complex process control;', 'Transaction/Production System;EDI front-end for order processing system;', 'Management of the centre activities;', 'Course Management;', 'Product Order management;', 'Catalogue/register of things or events;Document management;Customer relationship management;', 'Case Management Study;', 'MiddleWare;', 'Logistic or supply planning & control;', 'Trading;', 'Instant Messaging client;', 'Stock control & order processing;', 'Quality management;', 'Document management;Online analysis and reporting;Workflow support & management;Complex process control;', 'Transportation;', 'Information systems (Web);', 'Car production;', 'Distribution;', 'Customer billing;e-commerce;', 'Telecom;Network Management;', 'Financial transaction process/accounting;Logistic or supply planning & control;Complex process control;', 'Protocols;', 'Security/Authentication;', 'Scheduling of work orders assembly lines;', 'Calculation and quotation of casualty insurance;', 'Management of selling conditions to society;', 'Document management;Financial transaction process/accounting;Personal productivity (e.g. spreadsheet);Workflow support & management;Complex process control;Electronic Data Interchange;', 'Logistic or supply planning & control;Management or performance reporting;', 'Catalogue/register of things or events;Financial transaction process/accounting;Electronic Data Interchange;', 'Selling Organisation;', 'Client Server and Mainframe;', 'Hospital Information System;', 'European homologation management;', 'GEO Information Management;', 'Selling programming;', 'Factory follow up;', 'Electronic Data Interchange;Reusable component;', 'Device or interface driver;Financial transaction process/accounting;Online analysis and reporting;Complex process control;', 'Factory change programming;', 'Quality Management;', 'Algorithmic + DB;', 'Document management;Logistic or supply planning & control;Online analysis and reporting;Personal productivity (e.g. spreadsheet);', 'Online analysis and reporting;Personal productivity (e.g. spreadsheet);', \"Parts requirement's calculation (DRP);\", 'Selling reporting;', 'Network Management;Migration tool;', 'Stock Management;', 'Document management;Job, case, incident, project management;', 'Financial transaction process/accounting;Electronic Data Interchange;', 'Management or performance reporting;Online analysis and reporting;Telecom & network management;', 'Provider Management;', 'Providing Management;', 'Vendors management;', 'Decision Support System;Management Information System;', 'Catalogue/register of things or events;Processing application for public subsidies;', 'Protocol in Building automation;Protocol Enhancement;', 'Simulation of the behaviour of vehicles on the road;', 'Job, case, incident, project management;Software for communities to support administration;', 'Catalogue/register of things or events;Management or performance reporting;', 'Factory process follow up;', 'Chemical Risks Information System;', 'Dynamic calculation accessory drive and distribution;', 'Job, case, incident, project management;Online analysis and reporting;', \"Factory's process management;\", 'Purchasing;', 'ERP;', 'Reporting;', 'Document management;Management or performance reporting;Online analysis and reporting;Workflow support & management;', 'Catalogue/register of things or events;Document management;Online analysis and reporting;Workflow support & management;Complex process control;', 'Dealer management;', 'Catalogue/register of things or events;Job, case, incident, project management;', 'Data Provisioning;', 'Company car management;', 'Car Database for factory;', 'Spare parts management;', 'After Sales management Contract service;', 'Catalogue/register of things or events;Document management;Workflow support & management;', 'Business;Network Management;', 'Warranty Management;', 'Switching;', 'Mathematical modelling (finance or engineering);', 'Interactive Voice Response;', 'POS;', 'Retailler sells reporting;', 'Catalogue/register of things or events;Online analysis and reporting;Electronic Data Interchange;', 'Real-time System;', 'Parts Selling website;', 'Financial;', 'Car logistic management;', 'web;', 'Engineering Software;', 'Car electronic design;', 'Rules documentation;', 'training Management;', 'Proposal Builder;', 'Catalogue/register of things or events;Customer relationship management;', 'Knowledge-based App. w/ Interactive & Batch dbs;', 'Strategic planning;', 'Accounting;', 'Datawarehouse/ Business Intelligence;', 'Technical support for diagnostic and repair;', 'Data Warehouse;', 'Type 1 Function Point Counting Tool;', 'Call Center Management;', 'Workflow support & management;Precedents System;', 'Tax Legislative;', 'Business;Catalogue/register of things or events;', 'Data or database management;', 'Web-based application;', 'Immobility & Facilities Management;', 'Interface;', 'IT management;', 'Production management system;', 'Transaction/Production System;Office Automation System;Decision Support System;', 'Student & Tests Management;', 'Salaries Reporting;', 'Calculation, quotation, insurance policy issue;', 'Printing Documentation Design;', 'eCommerce;', 'European Warranty Management;', 'Commercial Web site;', 'Robot;', 'Parts catalogue management;', 'Human Ressources;', 'Quality Factory Reporting;', 'Customer billing/relationship management;Financial transaction process/accounting;Online analysis and reporting;Trading;Workflow support & management;Complex process control;Electronic Data Interchange;', 'Factory reporting;', 'Catalogue/register of things or events;Customer billing/relationship management;', 'VIrtual Synthesis for Acoustic;', 'Production programming;', 'Production process documentation;', 'Utility;', 'Analysis Management;', 'Management Information System;EDI;', 'Government;', 'Workflow support & management;Complex process control;', 'Catalogue/register of things or events;Document management;Financial transaction process/accounting;Job, case, incident, project management;Logistic or supply planning & control;Management or performance reporting;Online analysis and reporting;Stock contr', 'Cars selling;', 'After sales Follow up;', 'Shrink-wrap;', 'Parts documentation;', 'Cost Computing;', 'Financial transaction process/accounting;Job, case, incident, project management;Management or performance reporting;Online analysis and reporting;Workflow support & management;', 'Clinical Archive;', 'Catalogue/register of things or events;Electronic Data Interchange;Online analysis and reporting;Legislation and consideration of building cases;', 'Workflow support & management;Ordering tool enhancements for telecom components;', 'Geographic or spatial information system;Complex process control;', 'Financial transaction process/accounting;Customer billing;Customer relationship management;', 'Catalogue/register of things or events;Customer billing/relationship management;Document management;Administrative system for daycare;', 'Geographic or spatial information system;Management or performance reporting;Telecom & network management;', 'Project Risk management;', 'Sales calculation (DRP);', 'Customer billing/relationship management;Financial transaction process/accounting;Electronic Data Interchange;', 'Financial transaction process/accounting;Geographic or spatial information system;Online analysis and reporting;Stock control & order processing;Workflow support & management;', 'insurance quotation;', 'Business;', 'Catalogue/register of things or events;Operating system or software utility;', 'Geographic Information System;', 'Embedded system/real-time application;', 'Inventory gathering and Managing;', 'Internal Telecom Ordering Application;', 'Service Order & Activation Management;', 'Software development tool;', 'GUI for Protocol;Protocol Enhancement;', 'Document management;Financial transaction process/accounting;Image, video or sound processing;', 'Interface database;', 'Office Information System;Functional Specification System;', 'Catalogue/register of things or events;Customer billing/relationship management;Document management;Geographic or spatial information system;Mathematical modelling (finance or eng.);Electronic Data Interchange;', 'Operating system or software utility;(Re-usable component);', 'Customer billing/relationship management;Billing management - Batch processing;', 'Automated Data Acquisition;', 'Sales and Logistics Standard Application;', 'Card Administration  INCAS & Fault Assurance CAPRA;', 'Defect Tracking System;', 'Automate exchange between two IT Systems;', 'Office Information System;Case Management System;', 'Ordering & provisioning system;', 'Internet Banking;', 'Customisation (Add-ons) to a Product Data Management System;', 'Electronic Banking;', 'Financial transaction process/accounting;Logistic or supply planning & control;', \"Project's management;\", 'Document management;Financial transaction process/accounting;', 'Remote Banking;', 'Decision Support System;Management Information System;Office Information System;', 'Management Information System;Linguistic Software;', 'Unknown;', 'Financial transaction process/accounting;Online analysis and reporting;', 'web EC site;', 'Document management;Job, case, incident, project management;Management or performance reporting;Online analysis and reporting;Operating system or software utility;Workflow support & management;Telecom & network management;', 'Catalogue/register of things or events;Document management;Online analysis and reporting;Workflow support & management;', 'CIS;', 'Online Insurance product comparision tool;', 'Extranet application;', 'resources Management;', 'Logistic or supply planning & control;Management or performance reporting;Personal productivity (e.g. spreadsheet);Workflow support & management;', 'Complex process control;', 'Identity Card Emission;Data or database management;', 'Mathematical modelling (finance or eng.);Online analysis and reporting;', 'Online analysis and reporting;Software development tool;', 'Financial transaction process/accounting;Customer billing;', 'Reconciliation;', 'Trading;Electronic Data Interchange;', 'For credit collection;', 'Management of registration number;', 'Logistic or supply planning & control;Stock control & order processing;', 'Customer billing/relationship management;Document management;Trading;', 'Parts database for conception;', 'Scientific;', 'Business system;', 'Security Controls;', 'Other;', 'Capacity management;', 'Optimisation of the production;', 'Design management;', 'Cost analysis;', 'Marketing Info System;', 'Marketing management;', 'Handling payment of social pensions in government;', 'Car selling;', 'Process management;', 'Promotions;', 'Packaged software;', 'Reparation management;', 'Content management system;Dynamic website;', 'Process Control;Workflow support & management;The tool is Used By Employees of this Organization;', 'Network Management;', 'Healthcare;', 'Providing management;', 'Access Control;', 'Central cmd./ctl of sensors;', 'Support for parts documentation;', 'Web based fullfilment tool for Advertising;', 'Part management in factory;', 'Catalogue/register of things or events;Workflow support & management;', 'Tax system;', 'After Sales Management Contract service;', 'relatively complex application;', 'diagnostic tools;', 'Job, case, incident, project management;Management or performance reporting;', 'Rules documentation management;', 'Geometric design;', 'Back-Office;', 'Catalogue/register of things or events;Electronic Data Interchange;', 'Catalogue/register of things or events;Customer billing;Financial transaction process/accounting;Job, case, incident, project management;Management or performance reporting;Online analysis and reporting;Workflow support & management;Mathematical modelling', 'IP Contact Centers;', 'Optimisation for Industrial Scenarios;', 'Factory Reporting;', 'Provider management;', 'Services Selling;', 'Parts management;', 'Document management;Financial transaction process/accounting;Online analysis and reporting;Stock control & order processing;Workflow support & management;Customer billing;Reservation system (eg. Airline, hotel);', 'Gaming & Wagering;', 'Sales;', 'Management or performance reporting;Workflow support & management;', 'Exchange system;', 'Network Switch Provisioning;', 'Accounting of stock;', 'Job, case, incident, project management;Management or performance reporting;Operating system or software utility;Workflow support & management;Telecom & network management;', 'Handling payment of social pensions within government;', 'Equipment Management;', 'Catalogue/register of things or events;Document management;Job, case, incident, project management;Logistic or supply planning & control;Online analysis and reporting;Personal productivity (e.g. spreadsheet);Electronic Data Interchange;', 'Video Game;', 'Translation;', 'Security;', 'Customer billing/relationship management;Trading;', 'Human Resources;', 'Job, case, incident, project management;Workflow support & management;', 'Training;', 'Knowledge Based;', 'Monitoring of the factoring process;', 'Case management;', 'Quality of purchasing;', 'Device or interface driver;Financial transaction process/accounting;Complex process control;', 'Knowledge Based Multimedia;', 'Network Management;Telecom and Networking;', 'Catalogue/register of things or events;Workflow support & management;Electronic Data Interchange;', 'Sensor Ctl. + presentation;', 'Order Processing System;', 'Document management;Image, video or sound processing;', 'Project management;', 'Customer Management;', 'DSP;', 'Management of car distribution;', 'Technical Information System;', 'Follow up of the production in  factories;', 'Company hierarchy and staff directory;', 'Class Management;', 'Car Design;', 'website;', 'Catalogue/register of things or events;Document management;Online analysis and reporting;', 'Airport Management;', 'Business;Stock control & order processing;', 'Parts Database;', 'Airport Weather Observation Systems;Meteorological  events detection;', 'Document Management & Catalogue;', 'Enterprise Management;', 'University Admission Application Portal;', 'Course management system;Dynamic website;', 'Financial transaction process/accounting;Online analysis and reporting;Space management of schools;', 'Cars documentation;', 'Supplier Warranty Charge Back;', 'Catalogue/register of things or events;Logistic or supply planning & control;', 'Management of parts buying;', 'Inventory Control;', 'Office Automation System;', 'Logistic or supply planning & control;Stock control & order processing;Electronic Data Interchange;', 'Broadband application;', 'IT cost project management;', 'Suppliers Follow up;', 'Computing of the thermodynamic process;', 'Car design;', 'IT project Management;', 'Contract management After Sales;', 'Car renting;', 'Dealer network management;', 'not recorded;', 'Team Management;', 'Document management;Logistic or supply planning & control;', 'Logistic or supply planning & control;Workflow support & management;', 'Data Warehouse system;', 'Marketing systems;', 'Online analysis and reporting;Workflow support & management;', 'CAD;', 'Telecom Data Circuits and Revenue;', 'Printing Document Design;', 'Production management;', 'Stock factory management;', 'Quality of factory;', 'Logistic indicators;', 'Catalogue/register of things or events;Customer billing/relationship management;Electronic Data Interchange;', 'Voice Provisioning;', 'Online analysis and reporting;Embedded software - simple device control;Telecom & network management;', 'Financial transaction process/accounting;Management or performance reporting;Customer billing;', 'Management of manufacturing needs additional;']\n",
      "\n",
      "Column 'project_prf_development type':\n",
      "  Before: 5 categories\n",
      "  After:  7 categories\n",
      "  New categories added: ['Porting', 'Other']\n",
      "\n",
      "Column 'tech_tf_development platform':\n",
      "  Before: 5 categories\n",
      "  After:  6 categories\n",
      "  New categories added: ['Hand Held']\n",
      "\n",
      "Column 'tech_tf_language type':\n",
      "  Before: 5 categories\n",
      "  After:  6 categories\n",
      "  New categories added: ['APG']\n",
      "\n",
      "Column 'tech_tf_primary programming language':\n",
      "  Before: 48 categories\n",
      "  After:  128 categories\n",
      "  New categories added: ['gcc', 'MATLAB', 'PHP', 'Azure', 'Delphi', 'PASCAL', 'IEF', 'ARBOR/BP', 'BASIC', 'Pega Workflows', 'Express', 'Caa', 'Doc1 Designer (Entorno visual)', 'PYTHON', 'NCR teradata scripting', 'Upfront', 'SAS', 'SLEL', 'LEX', 'RPL', 'PowerPlay', 'Formspath', 'Magic', 'REXX', 'Object oriented language', 'Adobe Flex', 'CICS', 'Visual Studio .Net', 'EJB', 'Centura', 'FORTRAN', 'BRE', 'PERIPHONICS', 'A:G', 'LISP', 'DRIFT', 'Jdeveloper', 'Brightware proprietary', 'iPlanet Netscape Application Server', 'Ada', 'MANTIS', 'ColdFusion', 'Datastage', 'Huron/Object Star', 'ADO.Net', 'AB INITIO', 'COOL:Gen', 'IIS', 'Must Modeller', 'Data base language', 'COGNOS', 'UNIFACE', 'SLOGAN', 'OutlookVBA', 'MS-Navision Properitory Language', 'INGRES', 'BEA Weblogic', 'Siebel', 'IBM WTX', 'ACCEL', 'ADS/Online', 'HPS', 'STAFFWARE', 'BPM', 'Perl', 'Informatica PowerCenter', 'J2EE', 'ABF', 'IDEAL', 'TNSDL', 'APPS', 'BO', 'Spreadsheet', 'XGML', 'Periproducer', 'Enablon', 'C/AL', 'VisualFoxPro', 'ASAP', 'Mendix']\n",
      "\n",
      "Column 'project_prf_relative size':\n",
      "  Before: 8 categories\n",
      "  After:  9 categories\n",
      "  New categories added: ['XXXL']\n",
      "\n",
      "Column 'project_prf_team size group':\n",
      "  Before: 11 categories\n",
      "  After:  15 categories\n",
      "  New categories added: ['101+', '71-80', '51-60', '91-100']\n",
      "\n",
      "Column 'project_prf_case tool used':\n",
      "  Before: 3 categories\n",
      "  After:  3 categories\n",
      "\n",
      "Column 'process_pmf_prototyping used':\n",
      "  Before: 1 categories\n",
      "  After:  1 categories\n",
      "\n",
      "Column 'tech_tf_architecture':\n",
      "  Before: 5 categories\n",
      "  After:  7 categories\n",
      "  New categories added: ['Multi-tier with web interface', 'Stand-alone']\n",
      "\n",
      "Column 'tech_tf_client_server':\n",
      "  Before: 4 categories\n",
      "  After:  4 categories\n",
      "\n",
      "Column 'tech_tf_client_roles':\n",
      "  Before: 18 categories\n",
      "  After:  61 categories\n",
      "  New categories added: ['Data entry & validation;Device/equipment interface;Web/HTML browser;', 'Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;', 'Web/HTML browser;Web public interface;', 'Run a computer-human interface;Data retrieval & presentation;Web/HTML browser;Security;', 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Device/equipment interface;Web/HTML browser;', 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Device/equipment interface;Web/HTML browser;', 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Device/equipment interface;Terminal emulation;Provide some calculations;', 'Run a computer-human interface;Data entry & validation;', 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Device/equipment interface;', 'Business logic or rule processing;Data retrieval & presentation;Web public interface;', 'Run a computer-human interface;Business logic or rule processing;Web/HTML browser;', 'Business logic or rule processing;Data entry & validation;Device/equipment interface;Terminal emulation;', 'Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Data extraction, transformation and loading;', 'Data entry & validation;Data retrieval & presentation;Web/HTML browser;Web public interface;', 'Run a computer-human interface;Data retrieval & presentation;Web/HTML browser;Web public interface;', 'Business logic or rule processing;Data entry & validation;', 'Data retrieval & presentation;Web/HTML browser;', 'Data entry & validation;Data retrieval & presentation;', 'HandHeld Device;', 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Web/HTML browser;', 'Data entry & validation;Data retrieval & presentation;Device/equipment interface;', 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;Web public interface;', 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;', 'front-end;', 'Data entry & validation;', 'Business logic or rule processing;Data entry & validation;Device/equipment interface;Web/HTML browser;', 'Run a computer-human interface;Data entry & validation;Web public interface;', 'Web public interface;', 'Query and update data;', 'Run a computer-human interface;Business logic or rule processing;Data retrieval & presentation;', 'Data entry & validation;Web/HTML browser;', 'Run a computer-human interface;Data entry & validation;Web/HTML browser;', 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;Security;', 'Business logic or rule processing;Data retrieval & presentation;Web/HTML browser;Web public interface;', 'Device/equipment interface;', 'Data entry & validation;Data retrieval & presentation;Web/HTML browser;', 'Run a computer-human interface;Business logic or rule processing;', 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;Web public interface;Security;', 'Business logic or rule processing;Data retrieval & presentation;Device/equipment interface;Security;', 'Business logic or rule processing;Data retrieval & presentation;Web/HTML browser;', 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Web/HTML browser;Security;', 'Run a computer-human interface;Business logic or rule processing;Data entry & validation;Data retrieval & presentation;Web/HTML browser;', 'Data retrieval & presentation;Web/HTML browser;Security;']\n",
      "\n",
      "Column 'tech_tf_server_roles':\n",
      "  Before: 15 categories\n",
      "  After:  85 categories\n",
      "  New categories added: ['Database server;FTP server;Messaging server;', 'Database server;File &/or print server;HTML/web server;Mail server;Messaging server;', 'Database server;File &/or print server;HTML/web server;Mail server;Messaging server;Object/component server;Security/authentication;', 'Database server;File &/or print server;FTP server;Multi-user legacy application;', 'Database server;Multi-user legacy application;Object/component server;', 'Database server;Security/authentication;Delivery server for end products, f.e.Cognos Cubes;', 'Database server;HTML/web server;Multi-user legacy application;Object/component server;', 'Database server;Security/authentication;Law-based business logic;', 'Database server;File &/or print server;Security/authentication;', 'Object/component server;', 'Messaging server;', 'Database server;HTML/web server;Messaging server;Object/component server;Security/authentication;DR;', 'Database server;HTML/web server;Multi-user legacy application;Security/authentication;', 'Database server;HTML/web server;Mail server;Object/component server;Security/authentication;', 'Database server;HTML/web server;Object/component server;Security/authentication;', 'Database server;File &/or print server;FTP server;Mail server;Security/authentication;', 'HTML/web server;virtualisation server API;', 'Database server;HTML/web server;Security/authentication;Exchange Server;', 'Mail server;Messaging server;', 'Database server;HTML/web server;Mail server;Security/authentication;', 'Database server;File &/or print server;HTML/web server;Security/authentication;', 'FTP server;Messaging server;Object/component server;', 'Database server;HTML/web server;Security/authentication;ETL Server;', 'Multi-user legacy application;', 'Database server;FTP server;HTML/web server;Object/component server;', 'data acquisation;', 'Database server;File &/or print server;HTML/web server;Messaging server;Multi-user legacy application;', 'Database server;FTP server;Messaging server;Security/authentication;', 'Database server;FTP server;HTML/web server;Mail server;', 'webserver;', 'Database server;File &/or print server;Mail server;Messaging server;Security/authentication;', 'Database server;Mail server;Security/authentication;', 'Database server;File &/or print server;', 'Database server;File &/or print server;HTML/web server;Object/component server;Security/authentication;', 'Database server;FTP server;Messaging server;Object/component server;', 'Database server;HTML/web server;Mail server;WAS Server;', 'Database server;HTML/web server;Object/component server;Business logic;', 'HTML/web server;Multi-user legacy application;', 'Database server;FTP server;HTML/web server;Object/component server;Security/authentication;', 'Database server;File &/or print server;HTML/web server;', 'Database server;HTML/web server;Mail server;', 'HTML/web server;', 'Database server;File &/or print server;HTML/web server;Multi-user legacy application;', 'HTML/web server;Mail server;Security/authentication;', 'Database server;FTP server;HTML/web server;Mail server;Messaging server;Object/component server;Security/authentication;', 'Database server;Object/component server;Security/authentication;', 'Database server;FTP server;HTML/web server;Messaging server;Object/component server;Security/authentication;Business logic + Integration to 30 other systems;', 'Database server;FTP server;HTML/web server;Mail server;Security/authentication;', 'Database server;FTP server;Security/authentication;', 'Multi-user legacy application;Security/authentication;', 'Security/authentication;', 'Database server;File &/or print server;Security/authentication;Data entry & validation, business logic;', 'Database server;Object/component server;Security/authentication;Business logic;', 'HTML/web server;Security/authentication;', 'Database server;Security/authentication;Business logic;', 'Database server;File &/or print server;FTP server;HTML/web server;', 'Database server;HTML/web server;Multi-user legacy application;Object/component server;Security/authentication;', 'Database server;FTP server;HTML/web server;Security/authentication;', 'HTML/web server;Object/component server;', 'Database server;Mail server;', 'HTML/web server;Messaging server;', 'Database server;File &/or print server;HTML/web server;Mail server;', 'Database server;HTML/web server;Messaging server;Object/component server;Security/authentication;Application Server;', 'FTP server;HTML/web server;Multi-user legacy application;', 'Database server;Object/component server;', 'Database server;File &/or print server;Object/component server;Security/authentication;', 'FTP server;HTML/web server;Multi-user legacy application;Security/authentication;', 'Mail server;Multi-user legacy application;', 'Database server;HTML/web server;Messaging server;Security/authentication;', 'Database server;HTML/web server;Mail server;Object/component server;']\n",
      "\n",
      "Column 'tech_tf_type_of_server':\n",
      "  Before: 5 categories\n",
      "  After:  9 categories\n",
      "  New categories added: ['Stand alone;', 'Client server;', 'Multi-tier with web public interface;', 'webserver;']\n",
      "\n",
      "Column 'tech_tf_client/server_description':\n",
      "  Before: 10 categories\n",
      "  After:  26 categories\n",
      "  New categories added: ['not assessed;', 'Stand-alone;', '25%;', 'Presentation & Logic on server;', 'Client-server Architecture/P2P;', 'Unknown;', '30%;', '50%;', 'Dynamic Link Library;', 'Presentation and logic on client;', '20%;', '90%;', '100%;', '10%;', 'Client-server Architecture;Browser-server Architecture;', 'Embedded;']\n",
      "\n",
      "Column 'tech_tf_web_development':\n",
      "  Before: 2 categories\n",
      "  After:  2 categories\n",
      "\n",
      "Column 'tech_tf_dbms_used':\n",
      "  Before: 2 categories\n",
      "  After:  2 categories\n",
      "\n",
      "Column 'people_prf_project_user_involvement':\n",
      "  Before: 3 categories\n",
      "  After:  5 categories\n",
      "  New categories added: ['Best', 'Low']\n",
      "\n",
      "Column 'people_prf_ba_team_experience_less_than_1_yr':\n",
      "  Before: 8 categories\n",
      "  After:  22 categories\n",
      "  New categories added: [5.0, 7.0, 8.0, 9.0, 10.0, 11.0, 13.0, 15.0, 16.0, 19.0, 23.0, 27.0, 30.0, 31.0]\n",
      "\n",
      "Column 'people_prf_it_experience_less_than_1_yr':\n",
      "  Before: 8 categories\n",
      "  After:  12 categories\n",
      "  New categories added: [16.0, 9.0, 10.0, 24.0]\n",
      "\n",
      "Column 'people_prf_it_experience_less_than_3_yr':\n",
      "  Before: 9 categories\n",
      "  After:  20 categories\n",
      "  New categories added: [33.0, 36.0, 7.0, 8.0, 9.0, 42.0, 15.0, 17.0, 20.0, 22.0, 24.0]\n",
      "\n",
      "Column 'people_prf_it_experience_great_than_9_yr':\n",
      "  Before: 7 categories\n",
      "  After:  22 categories\n",
      "  New categories added: [5.0, 6.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 17.0, 18.0, 20.0, 21.0, 24.0, 25.0]\n",
      "\n",
      "Column 'people_prf_project_manage_changes':\n",
      "  Before: 4 categories\n",
      "  After:  5 categories\n",
      "  New categories added: [4.0]\n",
      "\n",
      "Column 'people_prf_personnel_changes':\n",
      "  Before: 5 categories\n",
      "  After:  16 categories\n",
      "  New categories added: [4.0, 5.0, 6.0, 7.0, 8.0, 10.0, 11.0, 12.0, 15.0, 16.0, 21.0]\n",
      "\n",
      "Column 'project_prf_cost_currency':\n",
      "  Before: 8 categories\n",
      "  After:  19 categories\n",
      "  New categories added: ['South Africa, rand', 'New Zealand, dollar', 'India, Rupees', 'Germany, Mark', 'India, rupee', 'Malaysia, Renggette', 'Ecuador', 'TRL', 'Brazil, real', 'Switzerland, franc', 'United Kingdom, pound sterling']\n",
      "\n",
      "Column 'project_prf_currency_multiple':\n",
      "  Before: 1 categories\n",
      "  After:  3 categories\n",
      "  New categories added: ['Yes 1,000', 'Yes 10,000']\n",
      "\n",
      "8. Checking for duplicate columns...\n",
      "\n",
      "9. Applying final preprocessing...\n",
      "============================================================\n",
      "ISBSG Data Preprocessing Pipeline\n",
      "============================================================\n",
      "Processing file: ../data\\temp_enhanced_sample.xlsx\n",
      "Target column (standardized): project_prf_normalised_work_effort\n",
      "Timestamp: 2025-06-12 11:17:57.572762\n",
      "Loading data from: ../data\\temp_enhanced_sample.xlsx\n",
      "Loaded data with shape: (2277, 52)\n",
      "Target column found: 'project_prf_normalised work effort' -> will be standardized to 'project_prf_normalised_work_effort'\n",
      "Target column 'project_prf_normalised work effort' -> 'project_prf_normalised_work_effort'\n",
      "Standardized 27 column names\n",
      "\n",
      "Missing value analysis:\n",
      "Columns with >50% missing: 28\n",
      "Columns with >70% missing: 23\n",
      "Dropping 23 columns with >70.0% missing values\n",
      "Filled project_prf_functional_size missing values with median: 174.0\n",
      "Filled project_prf_normalised_work_effort_level_1 missing values with median: 1927.5\n",
      "Filled project_prf_normalised_work_effort missing values with median: 1930.5\n",
      "Filled project_prf_normalised_level_1_pdr_ufp missing values with median: 11.0\n",
      "Filled project_prf_normalised_pdr_ufp missing values with median: 11.3\n",
      "Filled project_prf_defect_density missing values with median: 0.8500000000000001\n",
      "Filled project_prf_speed_of_delivery missing values with median: 28.6\n",
      "Filled project_prf_manpower_delivery_rate missing values with median: 4.8\n",
      "Filled project_prf_project_elapsed_time missing values with median: 6.7\n",
      "Filled project_prf_max_team_size missing values with median: 7.0\n",
      "Data shape after missing value handling: (2277, 29)\n",
      "Found 3 columns with semicolons: ['external_eef_organisation_type', 'project_prf_application_group', 'project_prf_application_type']\n",
      "Encoding 1 multi-value columns: ['project_prf_application_group']\n",
      "Encoded project_prf_application_group into 6 binary columns\n",
      "One-hot encoding 9 categorical columns: ['external_eef_data_quality_rating', 'project_prf_development_type', 'tech_tf_development_platform', 'tech_tf_language_type', 'project_prf_relative_size', 'project_prf_case_tool_used', 'tech_tf_architecture', 'tech_tf_client_server', 'tech_tf_dbms_used']\n",
      "No duplicate column names after fixing\n",
      "Fixed 16 column names for PyCaret compatibility\n",
      "\n",
      "=== Final Data Validation ===\n",
      "Final shape: (2277, 71)\n",
      "Target column: project_prf_normalised_work_effort\n",
      "Total missing values: 0\n",
      "Total infinite values: 0\n",
      "\n",
      "Data types:\n",
      "  Numeric columns: 20\n",
      "  Categorical columns: 5\n",
      "\n",
      "Target variable 'project_prf_normalised_work_effort' statistics:\n",
      "  Mean: 5133.69\n",
      "  Std: 11778.10\n",
      "  Min: 6.00\n",
      "  Max: 230514.00\n",
      "  Missing: 0\n",
      "\n",
      "Processed data saved to: ../data\\temp_enhanced_sample_preprocessed.csv\n",
      "Pipeline saved to: ../data\\temp_enhanced_sample_preprocessing_pipeline.pkl\n",
      "Metadata saved to: ../data\\temp_enhanced_sample_preprocessing_metadata.txt\n",
      "\n",
      "============================================================\n",
      "Preprocessing completed successfully!\n",
      "============================================================\n",
      "\n",
      "10. Final validation and duplicate check...\n",
      "Original sample shape: (939, 51)\n",
      "Final processed shape: (2277, 71)\n",
      "Columns added: 20\n",
      "Rows added: 1338\n",
      "\n",
      "Warning: Found potentially duplicate columns:\n",
      "  - 'project_prf_application_group_mathematically_intensive_application' and 'project_prf_application_group_mathematically_intensive_application_1'\n",
      "  - 'tech_tf_architecture_Stand_alone' and 'tech_tf_architecture_Stand_alone_1'\n",
      "Consider reviewing your preprocessing functions to avoid double processing.\n",
      "\n",
      "============================================================\n",
      "PIPELINE COMPLETED SUCCESSFULLY!\n",
      "============================================================\n",
      "Final dataset saved to: ../data\\enhanced_sample_final.csv\n",
      "Final shape: (2277, 71)\n",
      "Ready for PyCaret setup!\n",
      "\n",
      "SUMMARY:\n",
      "- Original sample rows: 939\n",
      "- Rows added from full dataset: 1338\n",
      "- Final rows: 2277\n",
      "- Original columns: 51\n",
      "- Final columns: 71\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Optional: Run the main function when script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    final_df, metadata = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ac3a9-bc0e-41c9-9124-3dd2be13e40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520c646-d7cf-483f-aa5c-659eb3e8fbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb563e26-7450-4f38-9221-912aecd07190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c8b117-c932-418a-b982-44c989db2612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61685304-5a54-4daf-9872-1e33ba246218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0966f-dd74-4d16-9b63-f3af45b43ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad9699-f16e-489e-9725-d38f2f22417d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262c7f6-cc14-442e-9fe8-7079e36344f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71847fde-1fe0-4d2f-83b3-2d2ba389dea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f02c95-8a89-4f2c-adfd-21894c2692ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c18ad0-d0a0-41b1-89e7-f459e5cc956d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead2007-b5c9-4e98-8ebe-640698dc3f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd6291-dd67-4a80-8851-a751e261a45e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
