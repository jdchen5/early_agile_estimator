{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e7795e-2a7a-4a33-b741-e6cb1e55684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37373c75-ca19-4f7d-940a-3ffbb2fe46ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the foler path\n",
    "models_folder = '../models'\n",
    "plots_folder = '../plots'\n",
    "temp_folder = '../temp'\n",
    "data_folder = '../data'\n",
    "logs_folder = '../logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a30b9b-f803-4261-a18d-c95980369988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp printing activated.\n",
      "Cell executed at: 2025-05-25 10:48:49.565215\n"
     ]
    }
   ],
   "source": [
    "# Sets up an automatic timestamp printout after each Jupyter cell execution \n",
    "# and configures the default visualization style.\n",
    "from IPython import get_ipython\n",
    "\n",
    "def setup_timestamp_callback():\n",
    "    \"\"\"Setup a timestamp callback for Jupyter cells without clearing existing callbacks.\"\"\"\n",
    "    ip = get_ipython()\n",
    "    if ip is not None:\n",
    "        # Define timestamp function\n",
    "        def print_timestamp(*args, **kwargs):\n",
    "            \"\"\"Print timestamp after cell execution.\"\"\"\n",
    "            print(f\"Cell executed at: {datetime.now()}\")\n",
    "        \n",
    "        # Check if our callback is already registered\n",
    "        callbacks = ip.events.callbacks.get('post_run_cell', [])\n",
    "        for cb in callbacks:\n",
    "            if hasattr(cb, '__name__') and cb.__name__ == 'print_timestamp':\n",
    "                # Already registered\n",
    "                return\n",
    "                \n",
    "        # Register new callback if not already present\n",
    "        ip.events.register('post_run_cell', print_timestamp)\n",
    "        print(\"Timestamp printing activated.\")\n",
    "    else:\n",
    "        print(\"Not running in IPython/Jupyter environment.\")\n",
    "\n",
    "# Setup timestamp callback\n",
    "setup_timestamp_callback()\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc45b413-775a-45b7-8d16-c0ef95c83cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "ISBSG2016R1.1_Formatted4CSVAgileOnly\n",
      "Cell executed at: 2025-05-25 10:48:49.935422\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "file_path = f\"{data_folder}/ISBSG2016R1.1_Formatted4CSVAgileOnly.xlsx\"\n",
    "file_name_no_ext = Path(file_path).stem                # 'ISBSG2016R1.1 - FormattedForCSV'\n",
    "print(file_name_no_ext)\n",
    "\n",
    "\n",
    "df = pd.read_excel(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb1617d-2715-4890-8d46-d81457477b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-05-25 10:48:49.957952\n"
     ]
    }
   ],
   "source": [
    "# Cleans and standardizes string columns and column names by removing spaces, \n",
    "# converting to lowercase, and normalizing formatting.\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_category(val):\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    # Lowercase, strip spaces, remove trailing punctuation\n",
    "    val = val.strip().lower()\n",
    "    val = re.sub(r'\\s+', ' ', val)  # collapse multiple spaces\n",
    "    val = val.rstrip(';,.')\n",
    "    val = val.replace('(', '').replace(')', '')\n",
    "    # Remove duplicate semicolons and extra spaces between separated values\n",
    "    val = re.sub(r';\\s*;', ';', val)\n",
    "    val = re.sub(r';\\s+', '; ', val)\n",
    "    return val\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].map(clean_category)\n",
    "\n",
    "# Clean column names: lowercase, replace spaces with underscores, strip\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.strip()                # remove leading/trailing spaces\n",
    "    .str.lower()                # make lowercase\n",
    "    .str.replace(' ', '_')      # replace spaces with underscores\n",
    "    .str.replace('-', '_')      # optional: replace hyphens with underscores\n",
    "    .str.replace('__', '_')      \n",
    "    .str.replace('(', '')     \n",
    "    .str.replace(')', '')      \n",
    "    .str.replace('<', 'less_than_')     \n",
    "    .str.replace('>', 'great_than_')\n",
    "    .str.replace('?', '')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e678e4-1c43-40dc-a912-55b4cdc52d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current columns: ['isbsg_project_id', 'external_eef_data_quality_rating', 'project_prf_year_of_project', 'external_eef_industry_sector', 'external_eef_organisation_type', 'project_prf_application_group', 'project_prf_application_type', 'project_prf_development_type', 'tech_tf_development_platform', 'tech_tf_language_type', 'tech_tf_primary_programming_language', 'project_prf_functional_size', 'project_prf_relative_size', 'project_prf_normalised_work_effort', 'project_prf_normalised_level_1_pdr_ufp', 'project_prf_normalised_pdr_ufp', 'project_prf_defect_density', 'project_prf_speed_of_delivery', 'project_prf_manpower_delivery_rate', 'project_prf_project_elapsed_time', 'project_prf_team_size_group', 'project_prf_max_team_size', 'project_prf_case_tool_used', 'process_pmf_development_methodologies', 'process_pmf_prototyping_used', 'process_pmf_docs', 'tech_tf_architecture', 'tech_tf_client_server', 'tech_tf_client_roles', 'tech_tf_server_roles', 'tech_tf_type_of_server', 'tech_tf_web_development', 'tech_tf_dbms_used', 'tech_tf_tools_used', 'people_prf_project_user_involvement', 'people_prf_ba_team_experience_less_than_1_yr', 'people_prf_ba_team_experience_1_to_3_yr', 'people_prf_ba_team_experience_great_than_3_yr', 'people_prf_it_experience_less_than_1_yr', 'people_prf_it_experience_1_to_3_yr', 'people_prf_it_experience_great_than_3_yr', 'people_prf_it_experience_less_than_3_yr', 'people_prf_it_experience_3_to_9_yr', 'people_prf_it_experience_great_than_9_yr', 'people_prf_project_manage_experience', 'people_prf_project_manage_changes', 'people_prf_personnel_changes', 'project_prf_total_project_cost', 'project_prf_cost_currency', 'project_prf_currency_multiple']\n",
      "Cell executed at: 2025-05-25 10:48:49.964049\n"
     ]
    }
   ],
   "source": [
    "print(\"Current columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0bf28be-58f2-401d-9cd9-2616596d3770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-05-25 10:48:49.973626\n"
     ]
    }
   ],
   "source": [
    "# Save the entire cleaned DataFrame (not just the column names) to CSV\n",
    "df.to_csv(f'../data/{file_name_no_ext}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19db0f42-f7e1-4aaf-beb2-38303b2627ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-05-25 10:48:49.987212\n"
     ]
    }
   ],
   "source": [
    "# Clean data\n",
    "# Cleans, de-duplicates, and sorts semicolon-separated categorical values in specified columns.\n",
    "\n",
    "def clean_and_sort_semicolon(val):\n",
    "    \"\"\"Clean and standardise a semicolon-separated categorical string.\"\"\"\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    \n",
    "    # Split, strip, lower, remove trailing punctuation\n",
    "    parts = []\n",
    "    for p in val.split(';'):\n",
    "        stripped_p = p.strip()\n",
    "        if stripped_p: # Only process non-empty parts after stripping\n",
    "            # Normalize internal multiple spaces to a single space\n",
    "            cleaned_p = re.sub(r'\\s+', ' ', stripped_p)\n",
    "            cleaned_p = cleaned_p.lower().rstrip(';,.')\n",
    "            parts.append(cleaned_p)\n",
    "    \n",
    "    # Remove duplicates, sort\n",
    "    parts = sorted(set(parts))\n",
    "    return '; '.join(parts)\n",
    "\n",
    "cols_with_semicolons = [\n",
    "    'project_prf_application_group',\n",
    "    'external_eef_organisation_type',\n",
    "    'project_prf_application_group',\n",
    "    'project_prf_application_type',\n",
    "    'project_prf_development_type',\n",
    "    'process_pmf_development_methodologies',\n",
    "    'tech_tf_client_server',\n",
    "    'tech_tf_client_roles',\n",
    "    'tech_tf_server_roles'\n",
    "]\n",
    "for col in cols_with_semicolons:\n",
    "    df[col] = df[col].map(clean_and_sort_semicolon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "268f3861-a909-4941-933d-ce553bc35da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-05-25 10:48:50.000737\n"
     ]
    }
   ],
   "source": [
    "# Standardizes specific categorical columns by normalizing case and correcting inconsistent formatting.\n",
    "\n",
    "def standardize_value(val):\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    val = val.strip().lower()\n",
    "    if val in ['stand alone', 'stand-alone']:\n",
    "        return 'stand-alone'\n",
    "    if val == 'client server':\n",
    "        return 'client-server'\n",
    "    if val == 'mathematically intensive':\n",
    "        return 'mathematically-intensive'\n",
    "\n",
    "    # Remove question mark from web dev\n",
    "    if val.replace('?', '').strip() == 'web':\n",
    "        return 'web'\n",
    "    # You can add more cases as needed\n",
    "    return val\n",
    "\n",
    "df['tech_tf_architecture'] = df['tech_tf_architecture'].map(standardize_value)\n",
    "df['tech_tf_web_development'] = df['tech_tf_web_development'].map(standardize_value)\n",
    "df['project_prf_application_group'] = df['project_prf_application_group'].map(standardize_value)\n",
    "df['tech_tf_language_type'] = df['tech_tf_language_type'].str.upper().str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a9c17-1557-490a-acef-12190a59742d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea001aed-6c12-440d-ae68-ae3d948a4115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Dropping: Unique values for categorical columns saved to '../temp/all_categorical_unique_values_beforeDropping.txt'\n",
      "Cell executed at: 2025-05-25 10:48:50.021628\n"
     ]
    }
   ],
   "source": [
    "# Writes the unique values of all categorical columns to a text file for reference or auditing.\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "with open(f\"{temp_folder}/all_categorical_unique_values_beforeDropping.txt\", 'w') as f:\n",
    "    for col in cat_cols:\n",
    "        f.write(f\"Column: {col} (n_unique = {df[col].nunique()})\\n\")\n",
    "        f.write(f\"{df[col].unique()}\\n\")\n",
    "        f.write('-' * 40 + '\\n')\n",
    "\n",
    "print(f\"Before Dropping: Unique values for categorical columns saved to '{temp_folder}/all_categorical_unique_values_beforeDropping.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31086bd0-d2c5-4a61-bd38-4358f4303656",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-05-24 19:08:06.763176\n"
     ]
    }
   ],
   "source": [
    "# Save the entire cleaned DataFrame (not just the column names) to CSV\n",
    "df.to_csv(f\"{data_folder}/{file_name_no_ext}_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd70455-798a-49a2-b564-2765c63cdcc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf3df8f-1004-4c7e-a548-fe22b8847afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
