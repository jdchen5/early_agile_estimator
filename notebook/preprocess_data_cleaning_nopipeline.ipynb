{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2357f1b-af76-4167-a430-47b638fe170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 1. Import libraries\n",
    "# ================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9870432b-77fa-4d57-8937-849dfc0df262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp printing activated.\n",
      "Cell executed at: 2025-05-30 20:22:28.553065\n"
     ]
    }
   ],
   "source": [
    "# Sets up an automatic timestamp printout after each Jupyter cell execution \n",
    "# and configures the default visualization style.\n",
    "from IPython import get_ipython\n",
    "\n",
    "def setup_timestamp_callback():\n",
    "    \"\"\"Setup a timestamp callback for Jupyter cells without clearing existing callbacks.\"\"\"\n",
    "    ip = get_ipython()\n",
    "    if ip is not None:\n",
    "        # Define timestamp function\n",
    "        def print_timestamp(*args, **kwargs):\n",
    "            \"\"\"Print timestamp after cell execution.\"\"\"\n",
    "            print(f\"Cell executed at: {datetime.now()}\")\n",
    "        \n",
    "        # Check if our callback is already registered\n",
    "        callbacks = ip.events.callbacks.get('post_run_cell', [])\n",
    "        for cb in callbacks:\n",
    "            if hasattr(cb, '__name__') and cb.__name__ == 'print_timestamp':\n",
    "                # Already registered\n",
    "                return\n",
    "                \n",
    "        # Register new callback if not already present\n",
    "        ip.events.register('post_run_cell', print_timestamp)\n",
    "        print(\"Timestamp printing activated.\")\n",
    "    else:\n",
    "        print(\"Not running in IPython/Jupyter environment.\")\n",
    "\n",
    "# Setup timestamp callback\n",
    "setup_timestamp_callback()\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47f8248d-57fc-4864-ac21-99a0ae6fb2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "sample_clean_a_agile_only\n",
      "Cell executed at: 2025-05-30 20:22:28.873662\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 2. Set file paths and load data\n",
    "# ================================\n",
    "data_folder = Path(\"../data\")\n",
    "sample_file = \"sample_clean_a_agile_only.xlsx\"\n",
    "data_file = \"\"\n",
    "\n",
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "\n",
    "file_path = f\"{data_folder}/{sample_file}\"  # should use data_file for model training\n",
    "file_name_no_ext = Path(file_path).stem                # 'ISBSG2016R1.1 - FormattedForCSV'\n",
    "print(file_name_no_ext)\n",
    "\n",
    "\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67245df2-2ae3-4d9e-8b7c-ccabb9c21615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-05-30 20:22:28.888761\n"
     ]
    }
   ],
   "source": [
    "# functions to standardise column names\n",
    "\n",
    "def standardize_columns(df):\n",
    "    return df.rename(columns=lambda x: x.strip().lower().replace(' ', '_'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf7417b-144c-422a-8006-24d5a59f7093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with semicolons: ['External_EEF_Organisation Type', 'Project_PRF_Application Type', 'Process_PMF_Development Methodologies', 'Tech_TF_Client_Roles', 'Tech_TF_Server_Roles']\n",
      "Cell executed at: 2025-05-30 20:22:28.922372\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 3. Identify columns with semicolons\n",
    "# ================================\n",
    "semicolon_cols = [\n",
    "    col for col in df.columns\n",
    "    if df[col].dropna().astype(str).str.contains(';').any()\n",
    "]\n",
    "\n",
    "print(\"Columns with semicolons:\", semicolon_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d746320-e6cc-4c4e-8358-0e640bdfaba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-05-30 20:22:28.927074\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 4. Cleaning function for semicolon-separated columns\n",
    "# ================================\n",
    "def clean_and_sort_semicolon(val, apply_standardization=False, mapping=None):\n",
    "    \"\"\"\n",
    "    Clean, deduplicate, sort, and (optionally) standardize semicolon-separated values.\n",
    "    \"\"\"\n",
    "    if pd.isnull(val) or val == '':\n",
    "        return val\n",
    "    parts = [x.strip().lower() for x in str(val).split(';') if x.strip()]\n",
    "    if apply_standardization and mapping is not None:\n",
    "        parts = [mapping.get(part, part) for part in parts]\n",
    "    unique_cleaned = sorted(set(parts))\n",
    "    return '; '.join(unique_cleaned)\n",
    "\n",
    "# Optionally: a mapping dictionary for extra standardization\n",
    "standardization_mapping = {\n",
    "    \"scrum\": \"agile development\",\n",
    "    \"file &/or print server\": \"file/print server\",\n",
    "    # Add more business-specific mappings here!\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1fdfaee-cd13-4b88-85fb-efa9ddca0a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-05-30 20:22:28.942482\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 5. Apply cleaning to each semicolon column\n",
    "# ================================\n",
    "for col in semicolon_cols:\n",
    "    # Choose whether to apply mapping (you can edit logic below per column)\n",
    "    apply_mapping = col in ['Process_PMF_Development Methodologies', 'Tech_TF_Server_Roles']\n",
    "    mapping = standardization_mapping if apply_mapping else None\n",
    "    df[col + \"_cleaned\"] = df[col].map(lambda x: clean_and_sort_semicolon(x, apply_standardization=apply_mapping, mapping=mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c0851d1-08f0-4963-9305-58ef60fd2688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: External_EEF_Organisation Type\n",
      "BEFORE: ['Government;Education Institution;Wholesale & Retail Trade;Transport & Storage;Communications;Medical and Health Care;Banking;', 'Government;', 'Community Services;']\n",
      "AFTER: ['banking; communications; education institution; government; medical and health care; transport & storage; wholesale & retail trade', 'government', 'community services']\n",
      "\n",
      "Column: Project_PRF_Application Type\n",
      "BEFORE: ['Surveillance and security;', 'Business Application;', 'Workflow support & management;Complex process control;']\n",
      "AFTER: ['surveillance and security', 'business application', 'complex process control; workflow support & management']\n",
      "\n",
      "Column: Process_PMF_Development Methodologies\n",
      "BEFORE: ['Agile Development;', 'Agile Development;Unified Process;', 'Agile Development;Personal Software Process (PSP);Unified Process;']\n",
      "AFTER: ['agile development', 'agile development; unified process', 'agile development; personal software process (psp); unified process']\n",
      "\n",
      "Column: Tech_TF_Client_Roles\n",
      "BEFORE: ['Data entry & validation;Data retrieval & presentation;Web/HTML browser;', 'Web public interface;', 'Run a computer-human interface;Data entry & validation;Data retrieval & presentation;Web/HTML browser;Security;']\n",
      "AFTER: ['data entry & validation; data retrieval & presentation; web/html browser', 'web public interface', 'data entry & validation; data retrieval & presentation; run a computer-human interface; security; web/html browser']\n",
      "\n",
      "Column: Tech_TF_Server_Roles\n",
      "BEFORE: ['HTML/web server;Security/authentication;', 'Multi-user legacy application;', 'Database server;File &/or print server;HTML/web server;Multi-user legacy application;']\n",
      "AFTER: ['html/web server; security/authentication', 'multi-user legacy application', 'database server; file/print server; html/web server; multi-user legacy application']\n",
      "Cell executed at: 2025-05-30 20:22:28.957553\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 6. Show before/after for each column (first 3 examples)\n",
    "# ================================\n",
    "for col in semicolon_cols:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(\"BEFORE:\", list(df[col].dropna().astype(str).unique()[:3]))\n",
    "    print(\"AFTER:\", list(df[col + \"_cleaned\"].dropna().astype(str).unique()[:3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74358779-d3f1-4dcf-813d-37b2691f8ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique categories in 'External_EEF_Organisation Type':\n",
      " ['aerospace / automotive' 'all industry organization types' 'banking'\n",
      " 'biotech' 'communications' 'community services' 'construction'\n",
      " 'consumer goods' 'defence' 'education institution'\n",
      " 'electricity, gas, water' 'energy'\n",
      " 'financial, property & business services' 'food processing' 'government'\n",
      " 'high tech' 'ieee' 'information technology'\n",
      " 'institutions eg. kindergartens' 'manufacturing'\n",
      " 'medical and health care' 'professional' 'public administration'\n",
      " 'public sector' 'real estate & property' 'surveillance & security'\n",
      " 'transport & storage' 'wholesale & retail trade']\n",
      "\n",
      "Unique categories in 'Project_PRF_Application Type':\n",
      " ['airport management' 'analysis management' 'auditing management'\n",
      " 'automated data acquisition' 'business application'\n",
      " 'catalogue/register of things or events' 'clinical archive'\n",
      " 'complex process control' 'content management system' 'course management'\n",
      " 'customer billing' 'customer billing/relationship management'\n",
      " 'customer relationship management' 'data or database management'\n",
      " 'data warehouse system' 'dynamic website' 'electronic data interchange'\n",
      " 'financial transaction process/accounting' 'hospital information system'\n",
      " 'idm' 'job, case, incident, project management'\n",
      " 'logistic or supply planning & control' 'management information system'\n",
      " 'management or performance reporting' 'mathematical modelling'\n",
      " 'mathematical modelling (finance or eng.)'\n",
      " 'online analysis and reporting' 'project management' 'promotions'\n",
      " 'proposal builder' 'security controls' 'security/authentication'\n",
      " 'software development tool' 'student & tests management'\n",
      " 'surveillance and security' 'web-based application'\n",
      " 'workflow support & management']\n",
      "\n",
      "Unique categories in 'Process_PMF_Development Methodologies':\n",
      " ['agile development' 'extreme programming (xp)' 'imes oom' 'iterative'\n",
      " 'joint application development (jad)' 'multifunctional teams'\n",
      " 'personal software process (psp)' 'rapid application development (rad)'\n",
      " 'timeboxing' 'unified process']\n",
      "\n",
      "Unique categories in 'Tech_TF_Client_Roles':\n",
      " ['business logic or rule processing' 'data entry & validation'\n",
      " 'data retrieval & presentation' 'database server'\n",
      " 'device/equipment interface' 'run a computer-human interface' 'security'\n",
      " 'web public interface' 'web/html browser']\n",
      "\n",
      "Unique categories in 'Tech_TF_Server_Roles':\n",
      " ['business logic + integration to 30 other systems' 'data acquisation'\n",
      " 'database server' 'file/print server' 'ftp server' 'html/web server'\n",
      " 'mail server' 'messaging server' 'multi-user legacy application'\n",
      " 'object/component server' 'security/authentication']\n",
      "Cell executed at: 2025-05-30 20:22:28.975279\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 7. One-hot encode cleaned columns & show unique categories\n",
    "# ================================\n",
    "unique_values = {}\n",
    "mlb_results = {}\n",
    "\n",
    "for col in semicolon_cols:\n",
    "    cleaned_col = col + \"_cleaned\"\n",
    "    values = df[cleaned_col].dropna().astype(str).apply(lambda x: [item.strip() for item in x.split(';') if item.strip()])\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    onehot = pd.DataFrame(\n",
    "        mlb.fit_transform(values),\n",
    "        columns=[f\"{cleaned_col}__{cat}\" for cat in mlb.classes_],\n",
    "        index=values.index\n",
    "    )\n",
    "    # Merge one-hot with main df if needed: df = df.join(onehot)\n",
    "    mlb_results[cleaned_col] = onehot\n",
    "    unique_values[col] = list(mlb.classes_)\n",
    "    print(f\"\\nUnique categories in '{col}':\\n\", mlb.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "286be073-3a4a-44fe-8416-566f782b1a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-05-30 20:22:29.002007\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 8. (Optional) Export cleaned data & one-hot encoded columns\n",
    "# ================================\n",
    "df.to_csv(data_folder / (file_name_no_ext + \"_cleaned_data.csv\"), index=False)\n",
    "\n",
    "# For one-hot: \n",
    "pd.concat([df, onehot], axis=1).to_csv(data_folder / (file_name_no_ext + \"_cleaned_data_with_onehot.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77552be4-afea-4e95-a814-138fe49566a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed at: 2025-05-30 20:22:29.020968\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Replace original columns with cleaned versions\n",
    "for col in semicolon_cols:\n",
    "    cleaned_col = col + \"_cleaned\"\n",
    "    if cleaned_col in df.columns:\n",
    "        df[col] = df[cleaned_col]\n",
    "\n",
    "# Step 2: Drop the now-redundant _cleaned columns\n",
    "df = df.drop([col + \"_cleaned\" for col in semicolon_cols if col + \"_cleaned\" in df.columns], axis=1)\n",
    "\n",
    "df_cleaned = standardize_columns(df)\n",
    "\n",
    "# Step 3: Save the cleaned DataFrame to CSV\n",
    "df_cleaned.to_csv(data_folder / (file_name_no_ext + \"_cleaned_no_add.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85b952e9-d568-4c90-8690-2d829f97687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current columns: ['isbsg_project_id', 'external_eef_data_quality_rating', 'project_prf_year_of_project', 'external_eef_industry_sector', 'external_eef_organisation_type', 'project_prf_application_group', 'project_prf_application_type', 'project_prf_development_type', 'tech_tf_development_platform', 'tech_tf_language_type', 'tech_tf_primary_programming_language', 'project_prf_functional_size', 'project_prf_relative_size', 'project_prf_normalised_work_effort_level_1', 'project_prf_normalised_work_effort', 'project_prf_normalised_level_1_pdr_ufp', 'project_prf_normalised_pdr_ufp', 'project_prf_defect_density', 'project_prf_speed_of_delivery', 'project_prf_manpower_delivery_rate', 'project_prf_project_elapsed_time', 'project_prf_team_size_group', 'project_prf_max_team_size', 'project_prf_case_tool_used', 'process_pmf_development_methodologies', 'process_pmf_prototyping_used', 'process_pmf_docs', 'tech_tf_architecture', 'tech_tf_client_server', 'tech_tf_client_roles', 'tech_tf_server_roles', 'tech_tf_type_of_server', 'tech_tf_client/server_description', 'tech_tf_web_development', 'tech_tf_dbms_used', 'tech_tf_tools_used', 'people_prf_project_user_involvement', 'people_prf_ba_team_experience_less_than_1_yr', 'people_prf_ba_team_experience_1_to_3_yr', 'people_prf_ba_team_experience_great_than_3_yr', 'people_prf_it_experience_less_than_1_yr', 'people_prf_it_experience_1_to_3_yr', 'people_prf_it_experience_great_than_3_yr', 'people_prf_it_experience_less_than_3_yr', 'people_prf_it_experience_3_to_9_yr', 'people_prf_it_experience_great_than_9_yr', 'people_prf_project_manage_experience', 'people_prf_project_manage_changes', 'people_prf_personnel_changes', 'project_prf_total_project_cost', 'project_prf_cost_currency', 'project_prf_currency_multiple']\n",
      "Cell executed at: 2025-05-30 20:22:29.025520\n"
     ]
    }
   ],
   "source": [
    "print(\"Current columns:\", df_cleaned.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28c3887-d6c5-4541-b462-2c1583aa3da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42432048-29a0-4e2e-b29c-da4450d454fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9e79ec-ef09-4d64-ab5d-bd58697484b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
